{"cells":[{"cell_type":"markdown","metadata":{"id":"y1von-1uFPIV"},"source":["# SSD (Scratch)\n","\n","Github repo:\n","https://github.com/FurkanOM/tf-ssd/tree/master"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20695,"status":"ok","timestamp":1708177883989,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"h4KJ9uuJF4sO","outputId":"d7c80efd-9d08-400f-e137-2675df7fd101"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":4262,"status":"ok","timestamp":1708189684477,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"5FT4SzeFBG7l"},"outputs":[],"source":["import tensorflow as tf\n","import tensorflow_datasets as tfds\n","from PIL import Image, ImageDraw\n","import matplotlib.pyplot as plt\n","import math\n","import numpy as np\n","from datetime import datetime\n","import os\n","import pathlib\n","import argparse"]},{"cell_type":"markdown","metadata":{"id":"jCX-6w4_BG7u"},"source":["# anchor_utils"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1708189684479,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"D9N9T9kpDwjD"},"outputs":[],"source":["\"\"\"Generate Anchor Boxes.\n","\"\"\"\n","\n","def get_scale_for_nth_feature_map(k, m=6, scale_min=0.2, scale_max=0.9):\n","    \"\"\"Calculating scale value for nth feature map using the given method in the paper.\n","    inputs:\n","        k = nth feature map for scale calculation\n","        m = length of all using feature maps for detections, 6 for ssd300\n","\n","    outputs:\n","        scale = calculated scale value for given index\n","    \"\"\"\n","    # [0.2, 0.34, 0.48, 0.62, 0.76, 0.9, 1.04]\n","    return scale_min + ((scale_max - scale_min) / (m - 1)) * (k - 1)\n","\n","def generate_base_prior_boxes(aspect_ratios, feature_map_index, total_feature_map, hyper_params):\n","    \"\"\"Generating top left prior boxes for given stride, height and width pairs of different aspect ratios.\n","    These prior boxes same with the anchors in Faster-RCNN.\n","    inputs:\n","        aspect_ratios = for all feature map shapes + 1 for ratio 1\n","        feature_map_index = nth feature maps for scale calculation\n","        total_feature_map = length of all using feature map for detections, 6 for ssd300\n","\n","    outputs:\n","        base_prior_boxes = (prior_box_count, [y1, x1, y2, x2])\n","    \"\"\"\n","    # print(feature_map_index)\n","    if hyper_params[\"use_custom_scale\"]:\n","        current_scale = hyper_params[\"scale\"][feature_map_index-1]\n","        next_scale = hyper_params[\"scale\"][feature_map_index]\n","    else:\n","        current_scale = get_scale_for_nth_feature_map(feature_map_index, m=total_feature_map,\n","                                                      scale_min=hyper_params[\"scale_min\"], scale_max=hyper_params[\"scale_max\"])\n","        next_scale = get_scale_for_nth_feature_map(feature_map_index + 1, m=total_feature_map,\n","                                                   scale_min=hyper_params[\"scale_min\"], scale_max=hyper_params[\"scale_max\"])\n","    print(current_scale, next_scale)\n","    base_prior_boxes = []\n","    for aspect_ratio in aspect_ratios:\n","        height = current_scale / tf.sqrt(aspect_ratio)\n","        width = current_scale * tf.sqrt(aspect_ratio)\n","        base_prior_boxes.append([-height/2, -width/2, height/2, width/2])\n","#         print(height, width)\n","    # 1 extra pair for ratio 1\n","    height = width = tf.sqrt(current_scale * next_scale)\n","#     print(height, width)\n","    base_prior_boxes.append([-height/2, -width/2, height/2, width/2])\n","    return tf.cast(base_prior_boxes, dtype=tf.float32)\n","\n","def generate_prior_boxes(feature_map_shapes, aspect_ratios, hyper_params):\n","    \"\"\"Generating top left prior boxes for given stride, height and width pairs of different aspect ratios.\n","    These prior boxes same with the anchors in Faster-RCNN.\n","    Aspect ratio is the width to height ratio.\n","    inputs:\n","        feature_map_shapes = for all feature map output size\n","        aspect_ratios = for all feature map shapes + 1 for ratio 1\n","\n","    outputs:\n","        prior_boxes = (total_prior_boxes, [y1, x1, y2, x2])\n","            these values in normalized format between [0, 1]\n","    \"\"\"\n","    prior_boxes = []\n","    for i, feature_map_shape in enumerate(feature_map_shapes):\n","        print(feature_map_shape)\n","        base_prior_boxes = generate_base_prior_boxes(aspect_ratios[i], i+1, len(feature_map_shapes), hyper_params)\n","        print(base_prior_boxes)\n","\n","        stride = 1 / feature_map_shape\n","        # Create linearly spaced arrays of x and y coordinates\n","        grid_coords = tf.cast(tf.range(0, feature_map_shape) / feature_map_shape + stride / 2, dtype=tf.float32)\n","        grid_x, grid_y = tf.meshgrid(grid_coords, grid_coords)\n","        flat_grid_x, flat_grid_y = tf.reshape(grid_x, (-1, )), tf.reshape(grid_y, (-1, ))\n","\n","        grid_map = tf.stack([flat_grid_y, flat_grid_x, flat_grid_y, flat_grid_x], -1)\n","\n","        prior_boxes_for_feature_map = tf.reshape(base_prior_boxes, (1, -1, 4)) + tf.reshape(grid_map, (-1, 1, 4))\n","        prior_boxes_for_feature_map = tf.reshape(prior_boxes_for_feature_map, (-1, 4))\n","        prior_boxes.append(prior_boxes_for_feature_map)\n","\n","    prior_boxes = tf.concat(prior_boxes, axis=0)\n","    # print(prior_boxes)\n","    return tf.clip_by_value(prior_boxes, 0, 1)"]},{"cell_type":"markdown","metadata":{"id":"Stm5EzBc79ca"},"source":["# parameters"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1708189684481,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"RUJfTzYkBG76"},"outputs":[],"source":["backbone = \"mobilenet_v2\""]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":5109,"status":"ok","timestamp":1708189691738,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"AE1YUdJu7_HW","outputId":"357cdf7c-6acd-47fd-e739-405a9f10d4e6"},"outputs":[{"data":{"text/plain":["{'img_size': 640,\n"," 'feature_map_shapes': [80, 40, 20, 10, 5, 3],\n"," 'aspect_ratios': [[1.0, 2.0, 0.5, 5.0, 0.2],\n","  [1.0, 2.0, 0.5, 5.0, 0.2],\n","  [1.0, 2.0, 0.5, 5.0, 0.2],\n","  [1.0, 2.0, 0.5, 5.0, 0.2],\n","  [1.0, 2.0, 0.5, 5.0, 0.2],\n","  [1.0, 2.0, 0.5, 5.0, 0.2]],\n"," 'use_custom_scale': False,\n"," 'scale_min': 0.05,\n"," 'scale_max': 0.5,\n"," 'scale': [0.05, 0.1, 0.2, 0.4, 0.7, 1, 1.5],\n"," 'trainable': True,\n"," 'num_trainable': None,\n"," 'detection': None,\n"," 'feature_fusion': 'elesum',\n"," 'dataset': 0,\n"," 'iou_threshold': 0.5,\n"," 'neg_pos_ratio': 3,\n"," 'loc_loss_alpha': 1,\n"," 'variances': [0.1, 0.1, 0.2, 0.2],\n"," 'use_focal': False,\n"," 'alpha': 2.0,\n"," 'gamma': 0.25,\n"," 'batch_size': 8,\n"," 'epochs': 200,\n"," 'lr': 1e-05,\n"," 'patience': 20}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["80\n","0.05 0.14\n","tf.Tensor(\n","[[-0.025      -0.025       0.025       0.025     ]\n"," [-0.01767767 -0.03535534  0.01767767  0.03535534]\n"," [-0.03535534 -0.01767767  0.03535534  0.01767767]\n"," [-0.01118034 -0.0559017   0.01118034  0.0559017 ]\n"," [-0.0559017  -0.01118034  0.0559017   0.01118034]\n"," [-0.041833   -0.041833    0.041833    0.041833  ]], shape=(6, 4), dtype=float32)\n","40\n","0.14 0.22999999999999998\n","tf.Tensor(\n","[[-0.07       -0.07        0.07        0.07      ]\n"," [-0.04949747 -0.09899495  0.04949747  0.09899495]\n"," [-0.09899495 -0.04949747  0.09899495  0.04949747]\n"," [-0.03130496 -0.15652475  0.03130496  0.15652475]\n"," [-0.15652476 -0.03130495  0.15652476  0.03130495]\n"," [-0.0897218  -0.0897218   0.0897218   0.0897218 ]], shape=(6, 4), dtype=float32)\n","20\n","0.22999999999999998 0.32\n","tf.Tensor(\n","[[-0.115      -0.115       0.115       0.115     ]\n"," [-0.08131728 -0.16263457  0.08131728  0.16263457]\n"," [-0.16263457 -0.08131728  0.16263457  0.08131728]\n"," [-0.05142957 -0.2571478   0.05142957  0.2571478 ]\n"," [-0.25714782 -0.05142956  0.25714782  0.05142956]\n"," [-0.1356466  -0.1356466   0.1356466   0.1356466 ]], shape=(6, 4), dtype=float32)\n","10\n","0.32 0.41\n","tf.Tensor(\n","[[-0.16       -0.16        0.16        0.16      ]\n"," [-0.11313708 -0.22627416  0.11313708  0.22627416]\n"," [-0.22627416 -0.11313708  0.22627416  0.11313708]\n"," [-0.07155418 -0.35777083  0.07155418  0.35777083]\n"," [-0.35777086 -0.07155418  0.35777086  0.07155418]\n"," [-0.1811077  -0.1811077   0.1811077   0.1811077 ]], shape=(6, 4), dtype=float32)\n","5\n","0.41 0.49999999999999994\n","tf.Tensor(\n","[[-0.205      -0.205       0.205       0.205     ]\n"," [-0.14495689 -0.28991377  0.14495689  0.28991377]\n"," [-0.28991377 -0.14495689  0.28991377  0.14495689]\n"," [-0.0916788  -0.4583939   0.0916788   0.4583939 ]\n"," [-0.45839393 -0.09167878  0.45839393  0.09167878]\n"," [-0.22638462 -0.22638462  0.22638462  0.22638462]], shape=(6, 4), dtype=float32)\n","3\n","0.49999999999999994 0.5900000000000001\n","tf.Tensor(\n","[[-0.25       -0.25        0.25        0.25      ]\n"," [-0.17677669 -0.35355338  0.17677669  0.35355338]\n"," [-0.35355338 -0.17677669  0.35355338  0.17677669]\n"," [-0.11180341 -0.55901694  0.11180341  0.55901694]\n"," [-0.559017   -0.1118034   0.559017    0.1118034 ]\n"," [-0.2715695  -0.2715695   0.2715695   0.2715695 ]], shape=(6, 4), dtype=float32)\n"]},{"data":{"text/plain":["<tf.Tensor: shape=(51204, 4), dtype=float32, numpy=\n","array([[0.        , 0.        , 0.03125   , 0.03125   ],\n","       [0.        , 0.        , 0.02392767, 0.04160534],\n","       [0.        , 0.        , 0.04160534, 0.02392767],\n","       ...,\n","       [0.7215299 , 0.27431637, 0.9451367 , 1.        ],\n","       [0.2743163 , 0.7215299 , 1.        , 0.9451367 ],\n","       [0.5617638 , 0.5617638 , 1.        , 1.        ]], dtype=float32)>"]},"metadata":{},"output_type":"display_data"}],"source":["SSD = {\n","    \"mobilenet_v2\": {\n","        \"img_size\": 640,\n","        \"feature_map_shapes\": [80, 40, 20, 10, 5, 3],\n","        \"aspect_ratios\": [[1., 2., 1./2., 5., 1./5.],\n","                          [1., 2., 1./2., 5., 1./5.],\n","                          [1., 2., 1./2., 5., 1./5.],\n","                          [1., 2., 1./2., 5., 1./5.],\n","                          [1., 2., 1./2., 5., 1./5.],\n","                          [1., 2., 1./2., 5., 1./5.]],\n","        \"use_custom_scale\": False,\n","        \"scale_min\": 0.05,\n","        \"scale_max\": 0.5,\n","        \"scale\": [0.05, 0.1, 0.2, 0.4, 0.7, 1, 1.5],\n","        \"trainable\": True,\n","        \"num_trainable\": None\n","    },\n","    # original\n","    # \"mobilenet_v2\": {\n","    #     \"img_size\": 300,\n","    #     \"feature_map_shapes\": [38, 19, 10, 5, 3, 2, 1],\n","    #     \"aspect_ratios\": [[1., 2., 1./2.],\n","    #                       [1., 2., 1./2.],\n","    #                      [1., 2., 1./2., 3., 1./3.],\n","    #                      [1., 2., 1./2., 3., 1./3.],\n","    #                      [1., 2., 1./2., 3., 1./3.],\n","    #                      [1., 2., 1./2.],\n","    #                      [1., 2., 1./2.]],\n","    # },\n","}\n","\n","def get_hyper_params(backbone, **kwargs):\n","    \"\"\"Generating hyper params in a dynamic way.\n","    inputs:\n","        **kwargs = any value could be updated in the hyper_params\n","\n","    outputs:\n","        hyper_params = dictionary\n","    \"\"\"\n","    hyper_params = SSD[backbone]\n","    hyper_params[\"detection\"] = None # None / \"FPN\" / \"BiFPN\" / \"PAFPN\" / \"NASFPN\"\n","    hyper_params[\"feature_fusion\"] = \"elesum\" # None / \"concat\" / \"elesum\"\n","    hyper_params[\"dataset\"] = 0 # dut, tilda, daffodil, thesis, combined\n","    hyper_params[\"iou_threshold\"] = 0.5\n","    hyper_params[\"neg_pos_ratio\"] = 3 # neg:pos 3:1 ratio\n","    hyper_params[\"loc_loss_alpha\"] = 1 # weight for the localization loss\n","    hyper_params[\"variances\"] = [0.1, 0.1, 0.2, 0.2]\n","    hyper_params[\"use_focal\"] = False\n","    hyper_params[\"alpha\"] = 2.0\n","    hyper_params[\"gamma\"] = 0.25\n","    hyper_params[\"batch_size\"] = 8\n","    hyper_params[\"epochs\"] = 200\n","    hyper_params[\"lr\"] = 1e-05\n","    hyper_params[\"patience\"] = 20\n","    # overwrite any parameters\n","    for key, value in kwargs.items():\n","        if key in hyper_params and value:\n","            hyper_params[key] = value\n","\n","    return hyper_params\n","\n","hyper_params = get_hyper_params(backbone)\n","display(hyper_params)\n","\n","# We calculate prior boxes for one time and use it for all operations because of the all images are the same sizes\n","prior_boxes = generate_prior_boxes(hyper_params[\"feature_map_shapes\"], hyper_params[\"aspect_ratios\"], hyper_params)\n","display(prior_boxes)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1708189691740,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"QNLznYpsBG8A"},"outputs":[],"source":["# Sanity Check\n","assert isinstance(hyper_params[\"dataset\"], int) and -1 < hyper_params[\"dataset\"] < 5"]},{"cell_type":"markdown","metadata":{"id":"nmkV2S7HGtZ8"},"source":["# MobileNetV2 SSD\n","\n","Specified backbone"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5963,"status":"ok","timestamp":1708189697683,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"oy32ZRGbcVlA","outputId":"0f6b8c68-c22e-4335-b7db-ebe59f88cb4c"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"]},{"name":"stdout","output_type":"stream","text":["Model: \"mobilenetv2_1.00_224\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_1 (InputLayer)        [(None, 640, 640, 3)]        0         []                            \n","                                                                                                  \n"," Conv1 (Conv2D)              (None, 320, 320, 32)         864       ['input_1[0][0]']             \n","                                                                                                  \n"," bn_Conv1 (BatchNormalizati  (None, 320, 320, 32)         128       ['Conv1[0][0]']               \n"," on)                                                                                              \n","                                                                                                  \n"," Conv1_relu (ReLU)           (None, 320, 320, 32)         0         ['bn_Conv1[0][0]']            \n","                                                                                                  \n"," expanded_conv_depthwise (D  (None, 320, 320, 32)         288       ['Conv1_relu[0][0]']          \n"," epthwiseConv2D)                                                                                  \n","                                                                                                  \n"," expanded_conv_depthwise_BN  (None, 320, 320, 32)         128       ['expanded_conv_depthwise[0][0\n","  (BatchNormalization)                                              ]']                           \n","                                                                                                  \n"," expanded_conv_depthwise_re  (None, 320, 320, 32)         0         ['expanded_conv_depthwise_BN[0\n"," lu (ReLU)                                                          ][0]']                        \n","                                                                                                  \n"," expanded_conv_project (Con  (None, 320, 320, 16)         512       ['expanded_conv_depthwise_relu\n"," v2D)                                                               [0][0]']                      \n","                                                                                                  \n"," expanded_conv_project_BN (  (None, 320, 320, 16)         64        ['expanded_conv_project[0][0]'\n"," BatchNormalization)                                                ]                             \n","                                                                                                  \n"," block_1_expand (Conv2D)     (None, 320, 320, 96)         1536      ['expanded_conv_project_BN[0][\n","                                                                    0]']                          \n","                                                                                                  \n"," block_1_expand_BN (BatchNo  (None, 320, 320, 96)         384       ['block_1_expand[0][0]']      \n"," rmalization)                                                                                     \n","                                                                                                  \n"," block_1_expand_relu (ReLU)  (None, 320, 320, 96)         0         ['block_1_expand_BN[0][0]']   \n","                                                                                                  \n"," block_1_pad (ZeroPadding2D  (None, 321, 321, 96)         0         ['block_1_expand_relu[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," block_1_depthwise (Depthwi  (None, 160, 160, 96)         864       ['block_1_pad[0][0]']         \n"," seConv2D)                                                                                        \n","                                                                                                  \n"," block_1_depthwise_BN (Batc  (None, 160, 160, 96)         384       ['block_1_depthwise[0][0]']   \n"," hNormalization)                                                                                  \n","                                                                                                  \n"," block_1_depthwise_relu (Re  (None, 160, 160, 96)         0         ['block_1_depthwise_BN[0][0]']\n"," LU)                                                                                              \n","                                                                                                  \n"," block_1_project (Conv2D)    (None, 160, 160, 24)         2304      ['block_1_depthwise_relu[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," block_1_project_BN (BatchN  (None, 160, 160, 24)         96        ['block_1_project[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_2_expand (Conv2D)     (None, 160, 160, 144)        3456      ['block_1_project_BN[0][0]']  \n","                                                                                                  \n"," block_2_expand_BN (BatchNo  (None, 160, 160, 144)        576       ['block_2_expand[0][0]']      \n"," rmalization)                                                                                     \n","                                                                                                  \n"," block_2_expand_relu (ReLU)  (None, 160, 160, 144)        0         ['block_2_expand_BN[0][0]']   \n","                                                                                                  \n"," block_2_depthwise (Depthwi  (None, 160, 160, 144)        1296      ['block_2_expand_relu[0][0]'] \n"," seConv2D)                                                                                        \n","                                                                                                  \n"," block_2_depthwise_BN (Batc  (None, 160, 160, 144)        576       ['block_2_depthwise[0][0]']   \n"," hNormalization)                                                                                  \n","                                                                                                  \n"," block_2_depthwise_relu (Re  (None, 160, 160, 144)        0         ['block_2_depthwise_BN[0][0]']\n"," LU)                                                                                              \n","                                                                                                  \n"," block_2_project (Conv2D)    (None, 160, 160, 24)         3456      ['block_2_depthwise_relu[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," block_2_project_BN (BatchN  (None, 160, 160, 24)         96        ['block_2_project[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_2_add (Add)           (None, 160, 160, 24)         0         ['block_1_project_BN[0][0]',  \n","                                                                     'block_2_project_BN[0][0]']  \n","                                                                                                  \n"," block_3_expand (Conv2D)     (None, 160, 160, 144)        3456      ['block_2_add[0][0]']         \n","                                                                                                  \n"," block_3_expand_BN (BatchNo  (None, 160, 160, 144)        576       ['block_3_expand[0][0]']      \n"," rmalization)                                                                                     \n","                                                                                                  \n"," block_3_expand_relu (ReLU)  (None, 160, 160, 144)        0         ['block_3_expand_BN[0][0]']   \n","                                                                                                  \n"," block_3_pad (ZeroPadding2D  (None, 161, 161, 144)        0         ['block_3_expand_relu[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," block_3_depthwise (Depthwi  (None, 80, 80, 144)          1296      ['block_3_pad[0][0]']         \n"," seConv2D)                                                                                        \n","                                                                                                  \n"," block_3_depthwise_BN (Batc  (None, 80, 80, 144)          576       ['block_3_depthwise[0][0]']   \n"," hNormalization)                                                                                  \n","                                                                                                  \n"," block_3_depthwise_relu (Re  (None, 80, 80, 144)          0         ['block_3_depthwise_BN[0][0]']\n"," LU)                                                                                              \n","                                                                                                  \n"," block_3_project (Conv2D)    (None, 80, 80, 32)           4608      ['block_3_depthwise_relu[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," block_3_project_BN (BatchN  (None, 80, 80, 32)           128       ['block_3_project[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_4_expand (Conv2D)     (None, 80, 80, 192)          6144      ['block_3_project_BN[0][0]']  \n","                                                                                                  \n"," block_4_expand_BN (BatchNo  (None, 80, 80, 192)          768       ['block_4_expand[0][0]']      \n"," rmalization)                                                                                     \n","                                                                                                  \n"," block_4_expand_relu (ReLU)  (None, 80, 80, 192)          0         ['block_4_expand_BN[0][0]']   \n","                                                                                                  \n"," block_4_depthwise (Depthwi  (None, 80, 80, 192)          1728      ['block_4_expand_relu[0][0]'] \n"," seConv2D)                                                                                        \n","                                                                                                  \n"," block_4_depthwise_BN (Batc  (None, 80, 80, 192)          768       ['block_4_depthwise[0][0]']   \n"," hNormalization)                                                                                  \n","                                                                                                  \n"," block_4_depthwise_relu (Re  (None, 80, 80, 192)          0         ['block_4_depthwise_BN[0][0]']\n"," LU)                                                                                              \n","                                                                                                  \n"," block_4_project (Conv2D)    (None, 80, 80, 32)           6144      ['block_4_depthwise_relu[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," block_4_project_BN (BatchN  (None, 80, 80, 32)           128       ['block_4_project[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_4_add (Add)           (None, 80, 80, 32)           0         ['block_3_project_BN[0][0]',  \n","                                                                     'block_4_project_BN[0][0]']  \n","                                                                                                  \n"," block_5_expand (Conv2D)     (None, 80, 80, 192)          6144      ['block_4_add[0][0]']         \n","                                                                                                  \n"," block_5_expand_BN (BatchNo  (None, 80, 80, 192)          768       ['block_5_expand[0][0]']      \n"," rmalization)                                                                                     \n","                                                                                                  \n"," block_5_expand_relu (ReLU)  (None, 80, 80, 192)          0         ['block_5_expand_BN[0][0]']   \n","                                                                                                  \n"," block_5_depthwise (Depthwi  (None, 80, 80, 192)          1728      ['block_5_expand_relu[0][0]'] \n"," seConv2D)                                                                                        \n","                                                                                                  \n"," block_5_depthwise_BN (Batc  (None, 80, 80, 192)          768       ['block_5_depthwise[0][0]']   \n"," hNormalization)                                                                                  \n","                                                                                                  \n"," block_5_depthwise_relu (Re  (None, 80, 80, 192)          0         ['block_5_depthwise_BN[0][0]']\n"," LU)                                                                                              \n","                                                                                                  \n"," block_5_project (Conv2D)    (None, 80, 80, 32)           6144      ['block_5_depthwise_relu[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," block_5_project_BN (BatchN  (None, 80, 80, 32)           128       ['block_5_project[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_5_add (Add)           (None, 80, 80, 32)           0         ['block_4_add[0][0]',         \n","                                                                     'block_5_project_BN[0][0]']  \n","                                                                                                  \n"," block_6_expand (Conv2D)     (None, 80, 80, 192)          6144      ['block_5_add[0][0]']         \n","                                                                                                  \n"," block_6_expand_BN (BatchNo  (None, 80, 80, 192)          768       ['block_6_expand[0][0]']      \n"," rmalization)                                                                                     \n","                                                                                                  \n"," block_6_expand_relu (ReLU)  (None, 80, 80, 192)          0         ['block_6_expand_BN[0][0]']   \n","                                                                                                  \n"," block_6_pad (ZeroPadding2D  (None, 81, 81, 192)          0         ['block_6_expand_relu[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," block_6_depthwise (Depthwi  (None, 40, 40, 192)          1728      ['block_6_pad[0][0]']         \n"," seConv2D)                                                                                        \n","                                                                                                  \n"," block_6_depthwise_BN (Batc  (None, 40, 40, 192)          768       ['block_6_depthwise[0][0]']   \n"," hNormalization)                                                                                  \n","                                                                                                  \n"," block_6_depthwise_relu (Re  (None, 40, 40, 192)          0         ['block_6_depthwise_BN[0][0]']\n"," LU)                                                                                              \n","                                                                                                  \n"," block_6_project (Conv2D)    (None, 40, 40, 64)           12288     ['block_6_depthwise_relu[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," block_6_project_BN (BatchN  (None, 40, 40, 64)           256       ['block_6_project[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_7_expand (Conv2D)     (None, 40, 40, 384)          24576     ['block_6_project_BN[0][0]']  \n","                                                                                                  \n"," block_7_expand_BN (BatchNo  (None, 40, 40, 384)          1536      ['block_7_expand[0][0]']      \n"," rmalization)                                                                                     \n","                                                                                                  \n"," block_7_expand_relu (ReLU)  (None, 40, 40, 384)          0         ['block_7_expand_BN[0][0]']   \n","                                                                                                  \n"," block_7_depthwise (Depthwi  (None, 40, 40, 384)          3456      ['block_7_expand_relu[0][0]'] \n"," seConv2D)                                                                                        \n","                                                                                                  \n"," block_7_depthwise_BN (Batc  (None, 40, 40, 384)          1536      ['block_7_depthwise[0][0]']   \n"," hNormalization)                                                                                  \n","                                                                                                  \n"," block_7_depthwise_relu (Re  (None, 40, 40, 384)          0         ['block_7_depthwise_BN[0][0]']\n"," LU)                                                                                              \n","                                                                                                  \n"," block_7_project (Conv2D)    (None, 40, 40, 64)           24576     ['block_7_depthwise_relu[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," block_7_project_BN (BatchN  (None, 40, 40, 64)           256       ['block_7_project[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_7_add (Add)           (None, 40, 40, 64)           0         ['block_6_project_BN[0][0]',  \n","                                                                     'block_7_project_BN[0][0]']  \n","                                                                                                  \n"," block_8_expand (Conv2D)     (None, 40, 40, 384)          24576     ['block_7_add[0][0]']         \n","                                                                                                  \n"," block_8_expand_BN (BatchNo  (None, 40, 40, 384)          1536      ['block_8_expand[0][0]']      \n"," rmalization)                                                                                     \n","                                                                                                  \n"," block_8_expand_relu (ReLU)  (None, 40, 40, 384)          0         ['block_8_expand_BN[0][0]']   \n","                                                                                                  \n"," block_8_depthwise (Depthwi  (None, 40, 40, 384)          3456      ['block_8_expand_relu[0][0]'] \n"," seConv2D)                                                                                        \n","                                                                                                  \n"," block_8_depthwise_BN (Batc  (None, 40, 40, 384)          1536      ['block_8_depthwise[0][0]']   \n"," hNormalization)                                                                                  \n","                                                                                                  \n"," block_8_depthwise_relu (Re  (None, 40, 40, 384)          0         ['block_8_depthwise_BN[0][0]']\n"," LU)                                                                                              \n","                                                                                                  \n"," block_8_project (Conv2D)    (None, 40, 40, 64)           24576     ['block_8_depthwise_relu[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," block_8_project_BN (BatchN  (None, 40, 40, 64)           256       ['block_8_project[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_8_add (Add)           (None, 40, 40, 64)           0         ['block_7_add[0][0]',         \n","                                                                     'block_8_project_BN[0][0]']  \n","                                                                                                  \n"," block_9_expand (Conv2D)     (None, 40, 40, 384)          24576     ['block_8_add[0][0]']         \n","                                                                                                  \n"," block_9_expand_BN (BatchNo  (None, 40, 40, 384)          1536      ['block_9_expand[0][0]']      \n"," rmalization)                                                                                     \n","                                                                                                  \n"," block_9_expand_relu (ReLU)  (None, 40, 40, 384)          0         ['block_9_expand_BN[0][0]']   \n","                                                                                                  \n"," block_9_depthwise (Depthwi  (None, 40, 40, 384)          3456      ['block_9_expand_relu[0][0]'] \n"," seConv2D)                                                                                        \n","                                                                                                  \n"," block_9_depthwise_BN (Batc  (None, 40, 40, 384)          1536      ['block_9_depthwise[0][0]']   \n"," hNormalization)                                                                                  \n","                                                                                                  \n"," block_9_depthwise_relu (Re  (None, 40, 40, 384)          0         ['block_9_depthwise_BN[0][0]']\n"," LU)                                                                                              \n","                                                                                                  \n"," block_9_project (Conv2D)    (None, 40, 40, 64)           24576     ['block_9_depthwise_relu[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," block_9_project_BN (BatchN  (None, 40, 40, 64)           256       ['block_9_project[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_9_add (Add)           (None, 40, 40, 64)           0         ['block_8_add[0][0]',         \n","                                                                     'block_9_project_BN[0][0]']  \n","                                                                                                  \n"," block_10_expand (Conv2D)    (None, 40, 40, 384)          24576     ['block_9_add[0][0]']         \n","                                                                                                  \n"," block_10_expand_BN (BatchN  (None, 40, 40, 384)          1536      ['block_10_expand[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_10_expand_relu (ReLU  (None, 40, 40, 384)          0         ['block_10_expand_BN[0][0]']  \n"," )                                                                                                \n","                                                                                                  \n"," block_10_depthwise (Depthw  (None, 40, 40, 384)          3456      ['block_10_expand_relu[0][0]']\n"," iseConv2D)                                                                                       \n","                                                                                                  \n"," block_10_depthwise_BN (Bat  (None, 40, 40, 384)          1536      ['block_10_depthwise[0][0]']  \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," block_10_depthwise_relu (R  (None, 40, 40, 384)          0         ['block_10_depthwise_BN[0][0]'\n"," eLU)                                                               ]                             \n","                                                                                                  \n"," block_10_project (Conv2D)   (None, 40, 40, 96)           36864     ['block_10_depthwise_relu[0][0\n","                                                                    ]']                           \n","                                                                                                  \n"," block_10_project_BN (Batch  (None, 40, 40, 96)           384       ['block_10_project[0][0]']    \n"," Normalization)                                                                                   \n","                                                                                                  \n"," block_11_expand (Conv2D)    (None, 40, 40, 576)          55296     ['block_10_project_BN[0][0]'] \n","                                                                                                  \n"," block_11_expand_BN (BatchN  (None, 40, 40, 576)          2304      ['block_11_expand[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_11_expand_relu (ReLU  (None, 40, 40, 576)          0         ['block_11_expand_BN[0][0]']  \n"," )                                                                                                \n","                                                                                                  \n"," block_11_depthwise (Depthw  (None, 40, 40, 576)          5184      ['block_11_expand_relu[0][0]']\n"," iseConv2D)                                                                                       \n","                                                                                                  \n"," block_11_depthwise_BN (Bat  (None, 40, 40, 576)          2304      ['block_11_depthwise[0][0]']  \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," block_11_depthwise_relu (R  (None, 40, 40, 576)          0         ['block_11_depthwise_BN[0][0]'\n"," eLU)                                                               ]                             \n","                                                                                                  \n"," block_11_project (Conv2D)   (None, 40, 40, 96)           55296     ['block_11_depthwise_relu[0][0\n","                                                                    ]']                           \n","                                                                                                  \n"," block_11_project_BN (Batch  (None, 40, 40, 96)           384       ['block_11_project[0][0]']    \n"," Normalization)                                                                                   \n","                                                                                                  \n"," block_11_add (Add)          (None, 40, 40, 96)           0         ['block_10_project_BN[0][0]', \n","                                                                     'block_11_project_BN[0][0]'] \n","                                                                                                  \n"," block_12_expand (Conv2D)    (None, 40, 40, 576)          55296     ['block_11_add[0][0]']        \n","                                                                                                  \n"," block_12_expand_BN (BatchN  (None, 40, 40, 576)          2304      ['block_12_expand[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_12_expand_relu (ReLU  (None, 40, 40, 576)          0         ['block_12_expand_BN[0][0]']  \n"," )                                                                                                \n","                                                                                                  \n"," block_12_depthwise (Depthw  (None, 40, 40, 576)          5184      ['block_12_expand_relu[0][0]']\n"," iseConv2D)                                                                                       \n","                                                                                                  \n"," block_12_depthwise_BN (Bat  (None, 40, 40, 576)          2304      ['block_12_depthwise[0][0]']  \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," block_12_depthwise_relu (R  (None, 40, 40, 576)          0         ['block_12_depthwise_BN[0][0]'\n"," eLU)                                                               ]                             \n","                                                                                                  \n"," block_12_project (Conv2D)   (None, 40, 40, 96)           55296     ['block_12_depthwise_relu[0][0\n","                                                                    ]']                           \n","                                                                                                  \n"," block_12_project_BN (Batch  (None, 40, 40, 96)           384       ['block_12_project[0][0]']    \n"," Normalization)                                                                                   \n","                                                                                                  \n"," block_12_add (Add)          (None, 40, 40, 96)           0         ['block_11_add[0][0]',        \n","                                                                     'block_12_project_BN[0][0]'] \n","                                                                                                  \n"," block_13_expand (Conv2D)    (None, 40, 40, 576)          55296     ['block_12_add[0][0]']        \n","                                                                                                  \n"," block_13_expand_BN (BatchN  (None, 40, 40, 576)          2304      ['block_13_expand[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_13_expand_relu (ReLU  (None, 40, 40, 576)          0         ['block_13_expand_BN[0][0]']  \n"," )                                                                                                \n","                                                                                                  \n"," block_13_pad (ZeroPadding2  (None, 41, 41, 576)          0         ['block_13_expand_relu[0][0]']\n"," D)                                                                                               \n","                                                                                                  \n"," block_13_depthwise (Depthw  (None, 20, 20, 576)          5184      ['block_13_pad[0][0]']        \n"," iseConv2D)                                                                                       \n","                                                                                                  \n"," block_13_depthwise_BN (Bat  (None, 20, 20, 576)          2304      ['block_13_depthwise[0][0]']  \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," block_13_depthwise_relu (R  (None, 20, 20, 576)          0         ['block_13_depthwise_BN[0][0]'\n"," eLU)                                                               ]                             \n","                                                                                                  \n"," block_13_project (Conv2D)   (None, 20, 20, 160)          92160     ['block_13_depthwise_relu[0][0\n","                                                                    ]']                           \n","                                                                                                  \n"," block_13_project_BN (Batch  (None, 20, 20, 160)          640       ['block_13_project[0][0]']    \n"," Normalization)                                                                                   \n","                                                                                                  \n"," block_14_expand (Conv2D)    (None, 20, 20, 960)          153600    ['block_13_project_BN[0][0]'] \n","                                                                                                  \n"," block_14_expand_BN (BatchN  (None, 20, 20, 960)          3840      ['block_14_expand[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_14_expand_relu (ReLU  (None, 20, 20, 960)          0         ['block_14_expand_BN[0][0]']  \n"," )                                                                                                \n","                                                                                                  \n"," block_14_depthwise (Depthw  (None, 20, 20, 960)          8640      ['block_14_expand_relu[0][0]']\n"," iseConv2D)                                                                                       \n","                                                                                                  \n"," block_14_depthwise_BN (Bat  (None, 20, 20, 960)          3840      ['block_14_depthwise[0][0]']  \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," block_14_depthwise_relu (R  (None, 20, 20, 960)          0         ['block_14_depthwise_BN[0][0]'\n"," eLU)                                                               ]                             \n","                                                                                                  \n"," block_14_project (Conv2D)   (None, 20, 20, 160)          153600    ['block_14_depthwise_relu[0][0\n","                                                                    ]']                           \n","                                                                                                  \n"," block_14_project_BN (Batch  (None, 20, 20, 160)          640       ['block_14_project[0][0]']    \n"," Normalization)                                                                                   \n","                                                                                                  \n"," block_14_add (Add)          (None, 20, 20, 160)          0         ['block_13_project_BN[0][0]', \n","                                                                     'block_14_project_BN[0][0]'] \n","                                                                                                  \n"," block_15_expand (Conv2D)    (None, 20, 20, 960)          153600    ['block_14_add[0][0]']        \n","                                                                                                  \n"," block_15_expand_BN (BatchN  (None, 20, 20, 960)          3840      ['block_15_expand[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_15_expand_relu (ReLU  (None, 20, 20, 960)          0         ['block_15_expand_BN[0][0]']  \n"," )                                                                                                \n","                                                                                                  \n"," block_15_depthwise (Depthw  (None, 20, 20, 960)          8640      ['block_15_expand_relu[0][0]']\n"," iseConv2D)                                                                                       \n","                                                                                                  \n"," block_15_depthwise_BN (Bat  (None, 20, 20, 960)          3840      ['block_15_depthwise[0][0]']  \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," block_15_depthwise_relu (R  (None, 20, 20, 960)          0         ['block_15_depthwise_BN[0][0]'\n"," eLU)                                                               ]                             \n","                                                                                                  \n"," block_15_project (Conv2D)   (None, 20, 20, 160)          153600    ['block_15_depthwise_relu[0][0\n","                                                                    ]']                           \n","                                                                                                  \n"," block_15_project_BN (Batch  (None, 20, 20, 160)          640       ['block_15_project[0][0]']    \n"," Normalization)                                                                                   \n","                                                                                                  \n"," block_15_add (Add)          (None, 20, 20, 160)          0         ['block_14_add[0][0]',        \n","                                                                     'block_15_project_BN[0][0]'] \n","                                                                                                  \n"," block_16_expand (Conv2D)    (None, 20, 20, 960)          153600    ['block_15_add[0][0]']        \n","                                                                                                  \n"," block_16_expand_BN (BatchN  (None, 20, 20, 960)          3840      ['block_16_expand[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_16_expand_relu (ReLU  (None, 20, 20, 960)          0         ['block_16_expand_BN[0][0]']  \n"," )                                                                                                \n","                                                                                                  \n"," block_16_depthwise (Depthw  (None, 20, 20, 960)          8640      ['block_16_expand_relu[0][0]']\n"," iseConv2D)                                                                                       \n","                                                                                                  \n"," block_16_depthwise_BN (Bat  (None, 20, 20, 960)          3840      ['block_16_depthwise[0][0]']  \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," block_16_depthwise_relu (R  (None, 20, 20, 960)          0         ['block_16_depthwise_BN[0][0]'\n"," eLU)                                                               ]                             \n","                                                                                                  \n"," block_16_project (Conv2D)   (None, 20, 20, 320)          307200    ['block_16_depthwise_relu[0][0\n","                                                                    ]']                           \n","                                                                                                  \n"," block_16_project_BN (Batch  (None, 20, 20, 320)          1280      ['block_16_project[0][0]']    \n"," Normalization)                                                                                   \n","                                                                                                  \n"," Conv_1 (Conv2D)             (None, 20, 20, 1280)         409600    ['block_16_project_BN[0][0]'] \n","                                                                                                  \n"," Conv_1_bn (BatchNormalizat  (None, 20, 20, 1280)         5120      ['Conv_1[0][0]']              \n"," ion)                                                                                             \n","                                                                                                  \n"," out_relu (ReLU)             (None, 20, 20, 1280)         0         ['Conv_1_bn[0][0]']           \n","                                                                                                  \n","==================================================================================================\n","Total params: 2257984 (8.61 MB)\n","Trainable params: 2223872 (8.48 MB)\n","Non-trainable params: 34112 (133.25 KB)\n","__________________________________________________________________________________________________\n"]}],"source":["from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n","base_model = MobileNetV2(include_top=False, input_shape=(640, 640, 3))\n","base_model.summary()"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1708189697684,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"qLVgx-fklhgd"},"outputs":[],"source":["def conv_layer(filter, kernel_size,\n","               layer, strides=1,\n","               padding='same',\n","               activation='linear',\n","               name='conv2d',pool=False,\n","               poolsize=2,poolstride=2,conv=True):\n","    if conv == True:\n","        layer = tf.keras.layers.Conv2D(filters=filter,\n","                                    kernel_size=kernel_size,\n","                                    strides=strides,\n","                                    activation=activation,\n","                                    padding=padding,\n","                                    name=name,\n","                                    kernel_initializer='he_normal')(layer)\n","        layer = tf.keras.layers.BatchNormalization()(layer)\n","        layer = tf.keras.layers.ReLU()(layer)\n","    elif pool == True:\n","        layer=tf.keras.layers.MaxPool2D(pool_size=(poolsize, poolsize),\n","                                        strides=poolstride, padding='same')(layer)\n","    return layer"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":312,"status":"ok","timestamp":1708190540833,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"yApDXEFhKhJb"},"outputs":[],"source":["from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n","from tensorflow.keras.layers import Conv2D, UpSampling2D, Concatenate\n","from tensorflow.keras.models import Model\n","\n","def get_model(hyper_params):\n","    \"\"\"Generating ssd model for hyper params.\n","    inputs:\n","        hyper_params = dictionary\n","\n","    outputs:\n","        ssd_model = tf.keras.model\n","    \"\"\"\n","    img_size = hyper_params[\"img_size\"]\n","    num_classes = hyper_params[\"total_labels\"]\n","    base_model = MobileNetV2(include_top=False, input_shape=(img_size, img_size, 3))\n","\n","    if hyper_params[\"trainable\"]:\n","        base_model.trainable = True\n","        if hyper_params[\"num_trainable\"] != None:\n","            for layer in base_model.layers[:-hyper_params[\"num_trainable\"]]:\n","                layer.trainable = False\n","    else: base_model.trainable = False\n","\n","    input = base_model.input\n","\n","    zero_conv = base_model.get_layer(\"block_6_expand_relu\").output # 128x128x192\n","    first_conv = base_model.get_layer(\"block_13_expand_relu\").output # 64x64x576\n","    second_conv = base_model.output # 32x32x1280\n","\n","    if hyper_params[\"feature_fusion\"] != None:\n","        first_conv_upsampled = UpSampling2D(size=(2, 2), interpolation='bilinear')(first_conv)\n","        # second_conv_upsampled = UpSampling2D(size=(4, 4), interpolation='bilinear')(second_conv)\n","        if hyper_params[\"feature_fusion\"] == \"concat\": # require same size\n","            zero_conv = Concatenate(axis=-1)([zero_conv, first_conv_upsampled])\n","            # zero_conv = Concatenate(axis=-1)([zero_conv, first_conv_upsampled, second_conv_upsampled])\n","        elif hyper_params[\"feature_fusion\"] == \"elesum\": # require same size and same number of channels\n","            zero_conv = conv_layer(256, (1, 1), strides=(1, 1), padding=\"valid\", activation=\"relu\", name=\"zero_conv\", layer=zero_conv)\n","            first_conv_upsampled = conv_layer(256, (1, 1), strides=(1, 1), padding=\"valid\", activation=\"relu\", name=\"first_conv\", layer=first_conv_upsampled)\n","            # second_conv_upsampled = conv_layer(256, (1, 1), strides=(1, 1), padding=\"valid\", activation=\"relu\", name=\"second_conv\", layer=second_conv_upsampled)\n","            zero_conv = tf.keras.layers.Add()([zero_conv, first_conv_upsampled])\n","            # zero_conv = tf.keras.layers.Add()([zero_conv, first_conv_upsampled, second_conv_upsampled])\n","        else:\n","            pass\n","\n","    # first_conv = base_model.get_layer(\"block_13_expand_relu\").output # 19 x 19 x 576\n","    # second_conv = base_model.output # 10 x 10 x 1280\n","\n","    ############################ Extra Feature Layers Start ############################\n","    extra1_1 = conv_layer(256, (1, 1), strides=(1, 1), padding=\"valid\", activation=\"relu\", name=\"extra1_1\", layer=second_conv)\n","    extra1_2 = conv_layer(512, (3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\", name=\"extra1_2\", layer=extra1_1)\n","\n","    extra2_1 = conv_layer(128, (1, 1), strides=(1, 1), padding=\"valid\", activation=\"relu\", name=\"extra2_1\", layer=extra1_2)\n","    extra2_2 = conv_layer(256, (3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\", name=\"extra2_2\", layer=extra2_1)\n","\n","    extra3_1 = conv_layer(128, (1, 1), strides=(1, 1), padding=\"valid\", activation=\"relu\", name=\"extra3_1\", layer=extra2_2)\n","    extra3_2 = conv_layer(256, (3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\", name=\"extra3_2\", layer=extra3_1)\n","\n","    # extra4_1 = conv_layer(128, (1, 1), strides=(1, 1), padding=\"valid\", activation=\"relu\", name=\"extra4_1\", layer=extra3_2)\n","    # extra4_2 = conv_layer(256, (3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\", name=\"extra4_2\", layer=extra4_1)\n","    ############################ Extra Feature Layers End ############################\n","\n","    pred_deltas, pred_labels = get_head_from_outputs(hyper_params, [zero_conv, first_conv, second_conv, extra1_2, extra2_2, extra3_2])\n","    # pred_deltas, pred_labels = get_head_from_outputs(hyper_params, [first_conv, second_conv, extra1_2, extra2_2, extra3_2, extra4_2])\n","    return Model(inputs=input, outputs=[pred_deltas, pred_labels])\n","\n","def init_model(model, img_size):\n","    \"\"\"Initializing model with dummy data for load weights with optimizer state and also graph construction.\n","    inputs:\n","        model = tf.keras.model\n","\n","    \"\"\"\n","    model(tf.random.uniform((1, img_size, img_size, 3)))"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1708190190217,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"Pkwb44x8ajPc","outputId":"d52660a4-1f8b-4f0b-b495-b180aa521949"},"outputs":[{"data":{"text/plain":["TensorShape([2, 64, 64, 256])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["from tensorflow.keras.layers import Conv2D, UpSampling2D, Concatenate, Add\n","ts1 = tf.random.normal((2, 64, 64, 256))\n","ts2 = tf.random.normal((2, 64, 64, 256))\n","ts = Add()([ts1, ts2])\n","ts.shape"]},{"cell_type":"markdown","metadata":{"id":"TTVGVeV8BG8P"},"source":["# Roboflow Setup"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":13369,"status":"ok","timestamp":1708183245514,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"vGmfrj73iUhb","outputId":"f20bf979-6a55-44ea-cfd8-869792a8370e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting roboflow\n","  Downloading roboflow-1.1.19-py3-none-any.whl (70 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.2/70.2 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting certifi==2023.7.22 (from roboflow)\n","  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting chardet==4.0.0 (from roboflow)\n","  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cycler==0.10.0 (from roboflow)\n","  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n","Collecting idna==2.10 (from roboflow)\n","  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.25.2)\n","Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n","  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n","Collecting python-dotenv (from roboflow)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n","Collecting supervision (from roboflow)\n","  Downloading supervision-0.18.0-py3-none-any.whl (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.2)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n","Collecting requests-toolbelt (from roboflow)\n","  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-magic (from roboflow)\n","  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.48.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n","Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (0.7.1)\n","Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (1.11.4)\n","Installing collected packages: python-magic, python-dotenv, opencv-python-headless, idna, cycler, chardet, certifi, supervision, requests-toolbelt, roboflow\n","  Attempting uninstall: opencv-python-headless\n","    Found existing installation: opencv-python-headless 4.9.0.80\n","    Uninstalling opencv-python-headless-4.9.0.80:\n","      Successfully uninstalled opencv-python-headless-4.9.0.80\n","  Attempting uninstall: idna\n","    Found existing installation: idna 3.6\n","    Uninstalling idna-3.6:\n","      Successfully uninstalled idna-3.6\n","  Attempting uninstall: cycler\n","    Found existing installation: cycler 0.12.1\n","    Uninstalling cycler-0.12.1:\n","      Successfully uninstalled cycler-0.12.1\n","  Attempting uninstall: chardet\n","    Found existing installation: chardet 5.2.0\n","    Uninstalling chardet-5.2.0:\n","      Successfully uninstalled chardet-5.2.0\n","  Attempting uninstall: certifi\n","    Found existing installation: certifi 2024.2.2\n","    Uninstalling certifi-2024.2.2:\n","      Successfully uninstalled certifi-2024.2.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires fastapi, which is not installed.\n","lida 0.0.10 requires kaleido, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed certifi-2023.7.22 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 python-dotenv-1.0.1 python-magic-0.4.27 requests-toolbelt-1.0.0 roboflow-1.1.19 supervision-0.18.0\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["certifi","chardet","cv2","cycler","idna"]}}},"metadata":{},"output_type":"display_data"}],"source":["!pip install roboflow\n","\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"YOUR API KEY\")"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2860,"status":"ok","timestamp":1708183248353,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"hszpdXFNv3zP","outputId":"8dd02b8b-e79e-453f-d70f-3d16036408df"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'models'...\n","remote: Enumerating objects: 4067, done.\u001b[K\n","remote: Counting objects: 100% (4067/4067), done.\u001b[K\n","remote: Compressing objects: 100% (3054/3054), done.\u001b[K\n","remote: Total 4067 (delta 1178), reused 2921 (delta 953), pack-reused 0\u001b[K\n","Receiving objects: 100% (4067/4067), 44.59 MiB | 29.84 MiB/s, done.\n","Resolving deltas: 100% (1178/1178), done.\n"]}],"source":["import os\n","import pathlib\n","\n","# Clone the tensorflow models repository if it doesn't already exist\n","if \"models\" in pathlib.Path.cwd().parts:\n","  while \"models\" in pathlib.Path.cwd().parts:\n","    os.chdir('..')\n","elif not pathlib.Path('models').exists():\n","  !git clone --depth 1 https://github.com/tensorflow/models"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":67370,"status":"ok","timestamp":1708183315706,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"qSmRA0scBmGu","outputId":"28caebef-a917-419b-d7c5-2e48b7fac3c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing /content/models/research\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Collecting avro-python3 (from object-detection==0.1)\n","  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Collecting apache-beam (from object-detection==0.1)\n","  Downloading apache_beam-2.54.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.8 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.8/14.8 MB 50.9 MB/s eta 0:00:00\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (9.4.0)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (4.9.4)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (3.7.1)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (3.0.8)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (21.6.0)\n","Requirement already satisfied: tf-slim in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.16.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.0.7)\n","Collecting lvis (from object-detection==0.1)\n","  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.11.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.5.3)\n","Collecting tf-models-official>=2.5.1 (from object-detection==0.1)\n","  Downloading tf_models_official-2.15.0-py2.py3-none-any.whl (2.7 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.7/2.7 MB 61.2 MB/s eta 0:00:00\n","Collecting tensorflow_io (from object-detection==0.1)\n","  Downloading tensorflow_io-0.36.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.4 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.4/49.4 MB 8.5 MB/s eta 0:00:00\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.15.0)\n","Collecting pyparsing==2.4.7 (from object-detection==0.1)\n","  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.8/67.8 kB 8.9 MB/s eta 0:00:00\n","Collecting sacrebleu<=2.2.0 (from object-detection==0.1)\n","  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 116.6/116.6 kB 14.8 MB/s eta 0:00:00\n","Collecting portalocker (from sacrebleu<=2.2.0->object-detection==0.1)\n","  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2023.12.25)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.9.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.25.2)\n","Collecting colorama (from sacrebleu<=2.2.0->object-detection==0.1)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.84.0)\n","Collecting immutabledict (from tf-models-official>=2.5.1->object-detection==0.1)\n","  Downloading immutabledict-4.1.0-py3-none-any.whl (4.5 kB)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.16)\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.8.0.74)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.9.5)\n","Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (9.0.0)\n","Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (6.0.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.1.99)\n","Collecting seqeval (from tf-models-official>=2.5.1->object-detection==0.1)\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 kB 5.7 MB/s eta 0:00:00\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.9.4)\n","Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.16.1)\n","Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official>=2.5.1->object-detection==0.1)\n","  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 242.5/242.5 kB 27.1 MB/s eta 0:00:00\n","Collecting tensorflow-text~=2.15.0 (from tf-models-official>=2.5.1->object-detection==0.1)\n","  Downloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.2/5.2 MB 44.9 MB/s eta 0:00:00\n","Requirement already satisfied: tensorflow~=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.15.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2023.4)\n","Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim->object-detection==0.1) (1.4.0)\n","Collecting crcmod<2.0,>=1.7 (from apache-beam->object-detection==0.1)\n","  Downloading crcmod-1.7.tar.gz (89 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 89.7/89.7 kB 11.9 MB/s eta 0:00:00\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Collecting orjson<4,>=3.9.7 (from apache-beam->object-detection==0.1)\n","  Downloading orjson-3.9.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 139.0/139.0 kB 10.9 MB/s eta 0:00:00\n","Collecting dill<0.3.2,>=0.3.1.1 (from apache-beam->object-detection==0.1)\n","  Downloading dill-0.3.1.1.tar.gz (151 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 152.0/152.0 kB 11.8 MB/s eta 0:00:00\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.2.1)\n","Collecting fastavro<2,>=0.23.6 (from apache-beam->object-detection==0.1)\n","  Downloading fastavro-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 35.1 MB/s eta 0:00:00\n","Collecting fasteners<1.0,>=0.3 (from apache-beam->object-detection==0.1)\n","  Downloading fasteners-0.19-py3-none-any.whl (18 kB)\n","Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.60.1)\n","Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam->object-detection==0.1)\n","  Downloading hdfs-2.7.3.tar.gz (43 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.5/43.5 kB 5.5 MB/s eta 0:00:00\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (0.22.0)\n","Collecting js2py<1,>=0.74 (from apache-beam->object-detection==0.1)\n","  Downloading Js2Py-0.74-py3-none-any.whl (1.0 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 36.0 MB/s eta 0:00:00\n","Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (4.19.2)\n","Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (3.0.2)\n","Collecting numpy>=1.17 (from sacrebleu<=2.2.0->object-detection==0.1)\n","  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.3/17.3 MB 36.9 MB/s eta 0:00:00\n","Collecting objsize<0.8.0,>=0.6.1 (from apache-beam->object-detection==0.1)\n","  Downloading objsize-0.7.0-py3-none-any.whl (11 kB)\n","Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (23.2)\n","Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam->object-detection==0.1)\n","  Downloading pymongo-4.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (677 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 677.1/677.1 kB 30.3 MB/s eta 0:00:00\n","Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.23.0)\n","Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<4.26.0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (3.20.3)\n","Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.4.2)\n","Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.31.0)\n","Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (4.9.0)\n","Collecting zstandard<1,>=0.18.0 (from apache-beam->object-detection==0.1)\n","  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.4/5.4 MB 48.6 MB/s eta 0:00:00\n","Requirement already satisfied: pyarrow<15.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (10.0.1)\n","Requirement already satisfied: pyarrow-hotfix<1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (0.6)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (1.4.5)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (4.8.0.76)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (1.2.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (4.48.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem==0.36.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io->object-detection==0.1) (0.36.0)\n","Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.27.0)\n","Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.1)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.11.1)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n","Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1)\n","  Downloading docopt-0.6.2.tar.gz (25 kB)\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from js2py<1,>=0.74->apache-beam->object-detection==0.1) (5.2)\n","Collecting pyjsparser>=2.5.1 (from js2py<1,>=0.74->apache-beam->object-detection==0.1)\n","  Downloading pyjsparser-2.7.1.tar.gz (24 kB)\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (0.33.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (0.17.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2023.7.22)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.66.2)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (8.0.4)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.0.7)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.0)\n","Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam->object-detection==0.1)\n","  Downloading dnspython-2.6.0-py3-none-any.whl (307 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 307.4/307.4 kB 30.7 MB/s eta 0:00:00\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (16.0.6)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (67.7.2)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (2.4.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (2.15.0)\n","Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub>=0.6.0->tf-models-official>=2.5.1->object-detection==0.1) (2.15.0)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.8)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.5.1)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.3.0)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (8.1.7)\n","Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.6.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.14.0)\n","Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n","Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (0.42.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2023.6.0)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (6.1.1)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.17.0)\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.62.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.3.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (3.5.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (0.5.1)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (2.1.5)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\n","Building wheels for collected packages: object-detection, avro-python3, crcmod, dill, hdfs, seqeval, pyjsparser, docopt\n","  Building wheel for object-detection (setup.py): started\n","  Building wheel for object-detection (setup.py): finished with status 'done'\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1697356 sha256=981932277bac709c42ebe8ac97ebb33a1064038438a8f898067e5484d74c439b\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-mh34pj61/wheels/53/dd/70/2de274d6c443c69d367bd6a5606f95e5a6df61aacf1435ec0d\n","  Building wheel for avro-python3 (setup.py): started\n","  Building wheel for avro-python3 (setup.py): finished with status 'done'\n","  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43992 sha256=400a72f4686904980d01e2009b70a695ca5f9ffcf9c643b1e117d3de23450471\n","  Stored in directory: /root/.cache/pip/wheels/bc/85/62/6cdd81c56f923946b401cecff38055b94c9b766927f7d8ca82\n","  Building wheel for crcmod (setup.py): started\n","  Building wheel for crcmod (setup.py): finished with status 'done'\n","  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31409 sha256=8a46506f5ed7d9c02c5299a8108475bfafe931e02d54a258046fafa0605971bf\n","  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n","  Building wheel for dill (setup.py): started\n","  Building wheel for dill (setup.py): finished with status 'done'\n","  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78540 sha256=4656751d4ff3181f8c58d898dd4055c772a324f5c956df8a615432dd5180e939\n","  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n","  Building wheel for hdfs (setup.py): started\n","  Building wheel for hdfs (setup.py): finished with status 'done'\n","  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34325 sha256=f5eba77c96f51613ff928719fbe229ee5fafce90bc5c654850b164899e92a3c9\n","  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n","  Building wheel for seqeval (setup.py): started\n","  Building wheel for seqeval (setup.py): finished with status 'done'\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=326b51131dda85d864b07cbe2f9da2427f13e37bdf7f2c2089df7ab658dc5997\n","  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n","  Building wheel for pyjsparser (setup.py): started\n","  Building wheel for pyjsparser (setup.py): finished with status 'done'\n","  Created wheel for pyjsparser: filename=pyjsparser-2.7.1-py3-none-any.whl size=25984 sha256=20710fc6f8d7f97af2195a9eeb17a965a3fa240723915dc15d6bfe79951ed3ee\n","  Stored in directory: /root/.cache/pip/wheels/5e/81/26/5956478df303e2bf5a85a5df595bb307bd25948a4bab69f7c7\n","  Building wheel for docopt (setup.py): started\n","  Building wheel for docopt (setup.py): finished with status 'done'\n","  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=e8c9ecd2c20ea443242a810fd39007f9f7a2c9ee7e2c9e1218bafa3da7e4a957\n","  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n","Successfully built object-detection avro-python3 crcmod dill hdfs seqeval pyjsparser docopt\n","Installing collected packages: pyjsparser, docopt, crcmod, zstandard, tensorflow_io, pyparsing, portalocker, orjson, objsize, numpy, js2py, immutabledict, fasteners, fastavro, dnspython, dill, colorama, avro-python3, tensorflow-model-optimization, sacrebleu, pymongo, hdfs, seqeval, lvis, apache-beam, tensorflow-text, tf-models-official, object-detection\n","  Attempting uninstall: pyparsing\n","    Found existing installation: pyparsing 3.1.1\n","    Uninstalling pyparsing-3.1.1:\n","      Successfully uninstalled pyparsing-3.1.1\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.25.2\n","    Uninstalling numpy-1.25.2:\n","      Successfully uninstalled numpy-1.25.2\n","Successfully installed apache-beam-2.54.0 avro-python3-1.10.2 colorama-0.4.6 crcmod-1.7 dill-0.3.1.1 dnspython-2.6.0 docopt-0.6.2 fastavro-1.9.4 fasteners-0.19 hdfs-2.7.3 immutabledict-4.1.0 js2py-0.74 lvis-0.5.3 numpy-1.24.4 object-detection-0.1 objsize-0.7.0 orjson-3.9.14 portalocker-2.8.2 pyjsparser-2.7.1 pymongo-4.6.1 pyparsing-2.4.7 sacrebleu-2.2.0 seqeval-1.2.2 tensorflow-model-optimization-0.8.0 tensorflow-text-2.15.0 tensorflow_io-0.36.0 tf-models-official-2.15.0 zstandard-0.22.0\n"]},{"name":"stderr","output_type":"stream","text":["ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires fastapi, which is not installed.\n","lida 0.0.10 requires kaleido, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\n"]}],"source":["# Install the Object Detection API\n","%%bash\n","cd models/research/\n","protoc object_detection/protos/*.proto --python_out=.\n","cp object_detection/packages/tf2/setup.py .\n","python -m pip install ."]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32384,"status":"ok","timestamp":1708183348025,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"b_mYXsDeJMsX","outputId":"003a5f91-1427-4cc2-b59f-d1131c987093"},"outputs":[{"name":"stdout","output_type":"stream","text":["loading Roboflow workspace...\n","loading Roboflow project...\n"]},{"name":"stderr","output_type":"stream","text":["Downloading Dataset Version Zip in Fabric-Defect-Capstone-1 to tfrecord:: 100%|██████████| 789109/789109 [00:25<00:00, 31309.51it/s]"]},{"name":"stdout","output_type":"stream","text":["\n"]},{"name":"stderr","output_type":"stream","text":["\n","Extracting Dataset Version Zip to Fabric-Defect-Capstone-1 in tfrecord:: 100%|██████████| 11/11 [00:04<00:00,  2.28it/s]\n"]}],"source":["if hyper_params[\"dataset\"] == 0:\n","    # dut\n","    project = rf.workspace(\"ducks-zdbul\").project(\"fabric-defect-capstone\")\n","    dataset = project.version(1).download(\"tfrecord\")\n","elif hyper_params[\"dataset\"] == 1:\n","    # tilda\n","    project = rf.workspace(\"irvin-andersen\").project(\"tilda-fabric\")\n","    dataset = project.version(2).download(\"tfrecord\")\n","elif hyper_params[\"dataset\"] == 2:\n","    # daffodil\n","    project = rf.workspace(\"defect-detection-witqu\").project(\"fabric-defect-daffodil\")\n","    dataset = project.version(1).download(\"tfrecord\")\n","elif hyper_params[\"dataset\"] == 3:\n","    # thesis\n","    project = rf.workspace(\"ducks-zdbul\").project(\"fabric-defect-thesis-quv7v\")\n","    dataset = project.version(1).download(\"tfrecord\")\n","elif hyper_params[\"dataset\"] == 4:\n","    pass"]},{"cell_type":"markdown","metadata":{"id":"8N8ZG5fxFYD0"},"source":["# Utils"]},{"cell_type":"markdown","metadata":{"id":"sZFFc8m4HIFH"},"source":["# augmentation"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1708190199402,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"p_NZkMjgHLNp"},"outputs":[],"source":["def apply(img, gt_boxes):\n","    \"\"\"Randomly applying data augmentation methods to image and ground truth boxes.\n","    inputs:\n","        img = (height, width, depth)\n","        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n","            in normalized form [0, 1]\n","    outputs:\n","        modified_img = (final_height, final_width, depth)\n","        modified_gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n","            in normalized form [0, 1]\n","    \"\"\"\n","    # Color operations\n","    # Randomly change hue, saturation, brightness and contrast of image\n","    color_methods = [random_brightness, random_contrast, random_hue, random_saturation]\n","    # Geometric operations\n","    # Randomly sample a patch and flip horizontally image and ground truth boxes\n","    geometric_methods = [patch, flip_horizontally]\n","\n","    for augmentation_method in geometric_methods + color_methods:\n","        img, gt_boxes = randomly_apply_operation(augmentation_method, img, gt_boxes)\n","\n","    img = tf.clip_by_value(img, 0, 1)\n","    return img, gt_boxes\n","\n","def get_random_bool():\n","    \"\"\"Generating random boolean.\n","    outputs:\n","        random boolean 0d tensor\n","    \"\"\"\n","    return tf.greater(tf.random.uniform((), dtype=tf.float32), 0.5)\n","\n","def randomly_apply_operation(operation, img, gt_boxes, *args):\n","    \"\"\"Randomly applying given method to image and ground truth boxes.\n","    inputs:\n","        operation = callable method\n","        img = (height, width, depth)\n","        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n","    outputs:\n","        modified_or_not_img = (final_height, final_width, depth)\n","        modified_or_not_gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n","    \"\"\"\n","    return tf.cond(\n","        get_random_bool(),\n","        lambda: operation(img, gt_boxes, *args),\n","        lambda: (img, gt_boxes)\n","    )\n","\n","def random_brightness(img, gt_boxes, max_delta=0.12):\n","    \"\"\"Randomly change brightness of the image.\n","    inputs:\n","        img = (height, width, depth)\n","        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n","    outputs:\n","        modified_img = (height, width, depth)\n","        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n","    \"\"\"\n","    return tf.image.random_brightness(img, max_delta), gt_boxes\n","\n","def random_contrast(img, gt_boxes, lower=0.5, upper=1.5):\n","    \"\"\"Randomly change contrast of the image.\n","    inputs:\n","        img = (height, width, depth)\n","        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n","    outputs:\n","        modified_img = (height, width, depth)\n","        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n","    \"\"\"\n","    return tf.image.random_contrast(img, lower, upper), gt_boxes\n","\n","def random_hue(img, gt_boxes, max_delta=0.08):\n","    \"\"\"Randomly change hue of the image.\n","    inputs:\n","        img = (height, width, depth)\n","        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n","    outputs:\n","        modified_img = (height, width, depth)\n","        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n","    \"\"\"\n","    return tf.image.random_hue(img, max_delta), gt_boxes\n","\n","def random_saturation(img, gt_boxes, lower=0.5, upper=1.5):\n","    \"\"\"Randomly change saturation of the image.\n","    inputs:\n","        img = (height, width, depth)\n","        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n","    outputs:\n","        modified_img = (height, width, depth)\n","        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n","    \"\"\"\n","    return tf.image.random_saturation(img, lower, upper), gt_boxes\n","\n","def flip_horizontally(img, gt_boxes):\n","    \"\"\"Flip image horizontally and adjust the ground truth boxes.\n","    inputs:\n","        img = (height, width, depth)\n","        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n","    outputs:\n","        modified_img = (height, width, depth)\n","        modified_gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n","    \"\"\"\n","    flipped_img = tf.image.flip_left_right(img)\n","    flipped_gt_boxes = tf.stack([gt_boxes[..., 0],\n","                                1.0 - gt_boxes[..., 3],\n","                                gt_boxes[..., 2],\n","                                1.0 - gt_boxes[..., 1]], -1)\n","    return flipped_img, flipped_gt_boxes\n","\n","##############################################################################\n","## Sample patch start\n","##############################################################################\n","\n","def get_random_min_overlap():\n","    \"\"\"Generating random minimum overlap value.\n","    outputs:\n","        min_overlap = random minimum overlap value 0d tensor\n","    \"\"\"\n","    overlaps = tf.constant([0.1, 0.3, 0.5, 0.7, 0.9], dtype=tf.float32)\n","    i = tf.random.uniform((), minval=0, maxval=tf.shape(overlaps)[0], dtype=tf.int32)\n","    return overlaps[i]\n","\n","def expand_image(img, gt_boxes, height, width):\n","    \"\"\"Randomly expanding image and adjusting ground truth object coordinates.\n","    inputs:\n","        img = (height, width, depth)\n","        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n","        height = height of the image\n","        width = width of the image\n","    outputs:\n","        img = (final_height, final_width, depth)\n","        modified_gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n","        final_height = final height of the image\n","        final_width = final width of the image\n","    \"\"\"\n","    expansion_ratio = tf.random.uniform((), minval=1, maxval=4, dtype=tf.float32)\n","    final_height, final_width = tf.round(height * expansion_ratio), tf.round(width * expansion_ratio)\n","    pad_left = tf.round(tf.random.uniform((), minval=0, maxval=final_width - width, dtype=tf.float32))\n","    pad_top = tf.round(tf.random.uniform((), minval=0, maxval=final_height - height, dtype=tf.float32))\n","    pad_right = final_width - (width + pad_left)\n","    pad_bottom = final_height - (height + pad_top)\n","\n","    mean, _ = tf.nn.moments(img, [0, 1])\n","    expanded_image = tf.pad(img, ((pad_top, pad_bottom), (pad_left, pad_right), (0,0)), constant_values=-1)\n","    expanded_image = tf.where(expanded_image == -1, mean, expanded_image)\n","\n","    min_max = tf.stack([-pad_top, -pad_left, pad_bottom+height, pad_right+width], -1) / [height, width, height, width]\n","    modified_gt_boxes = renormalize_bboxes_with_min_max(gt_boxes, min_max)\n","\n","    return expanded_image, modified_gt_boxes\n","\n","def patch(img, gt_boxes):\n","    \"\"\"Generating random patch and adjusting image and ground truth objects to this patch.\n","    After this operation some of the ground truth boxes / objects could be removed from the image.\n","    However, these objects are not excluded from the output, only the coordinates are changed as zero.\n","    inputs:\n","        img = (height, width, depth)\n","        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n","            in normalized form [0, 1]\n","    outputs:\n","        modified_img = (final_height, final_width, depth)\n","        modified_gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n","            in normalized form [0, 1]\n","    \"\"\"\n","    img_shape = tf.cast(tf.shape(img), dtype=tf.float32)\n","    org_height, org_width = img_shape[0], img_shape[1]\n","    # Randomly expand image and adjust bounding boxes\n","    img, gt_boxes = randomly_apply_operation(expand_image, img, gt_boxes, org_height, org_width)\n","    # Get random minimum overlap value\n","    min_overlap = get_random_min_overlap()\n","\n","    begin, size, new_boundaries = tf.image.sample_distorted_bounding_box(\n","        tf.shape(img),\n","        # use_image_if_no_bounding_boxes=True, ### FIX:26/1/24\n","        bounding_boxes=tf.expand_dims(gt_boxes, 0),\n","        aspect_ratio_range=[0.5, 2.0],\n","        min_object_covered=min_overlap)\n","\n","    img = tf.slice(img, begin, size)\n","    img = tf.image.resize(img, (org_height, org_width))\n","    gt_boxes = renormalize_bboxes_with_min_max(gt_boxes, new_boundaries[0, 0])\n","\n","    return img, gt_boxes"]},{"cell_type":"markdown","metadata":{"id":"qQE2tvn-Fhil"},"source":["# bbox_utils"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1708190199403,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"knGVG_zdT4Sf"},"outputs":[],"source":["def non_max_suppression(pred_bboxes, pred_labels, **kwargs):\n","    \"\"\"Applying non maximum suppression.\n","    SSD uses non-maximum suppression to prune away boxes that have IOU overlap with previously selected boxes.\n","    Details could be found on tensorflow documentation.\n","    https://www.tensorflow.org/api_docs/python/tf/image/combined_non_max_suppression\n","    inputs:\n","        pred_bboxes = (batch_size, total_bboxes, total_labels, [y1, x1, y2, x2])\n","            total_labels should be 1 for binary operations like in rpn\n","        pred_labels = (batch_size, total_bboxes, total_labels)\n","        **kwargs = other parameters\n","\n","    outputs:\n","        nms_boxes = (batch_size, max_detections, [y1, x1, y2, x2])\n","        nmsed_scores = (batch_size, max_detections)\n","        nmsed_classes = (batch_size, max_detections)\n","        valid_detections = (batch_size)\n","            Only the top valid_detections[i] entries in nms_boxes[i], nms_scores[i] and nms_class[i] are valid.\n","            The rest of the entries are zero paddings.\n","    \"\"\"\n","    return tf.image.combined_non_max_suppression(\n","        pred_bboxes,\n","        pred_labels,\n","        **kwargs\n","    )\n","\n","def generate_iou_map(bboxes, gt_boxes, transpose_perm=[0, 2, 1]):\n","    \"\"\"Calculating intersection over union values for each ground truth boxes in a dynamic manner.\n","    It is supported from 1d to 3d dimensions for bounding boxes.\n","    Even if bboxes have different rank from gt_boxes it should be work.\n","    inputs:\n","        bboxes = (dynamic_dimension, [y1, x1, y2, x2])\n","        gt_boxes = (dynamic_dimension, [y1, x1, y2, x2])\n","        transpose_perm = (transpose_perm_order)\n","            for 3d gt_boxes => [0, 2, 1]\n","            The returned tensor's dimension i will correspond to the input dimension perm[i].\n","\n","    outputs:\n","        iou_map = (dynamic_dimension, total_gt_boxes)\n","            same rank with the gt_boxes\n","    \"\"\"\n","    gt_rank = tf.rank(gt_boxes)\n","    gt_expand_axis = gt_rank - 2\n","\n","    bbox_y1, bbox_x1, bbox_y2, bbox_x2 = tf.split(bboxes, 4, axis=-1)\n","    gt_y1, gt_x1, gt_y2, gt_x2 = tf.split(gt_boxes, 4, axis=-1)\n","\n","    # Calculate bbox and ground truth boxes areas\n","    gt_area = tf.squeeze((gt_y2 - gt_y1) * (gt_x2 - gt_x1), axis=-1)\n","    bbox_area = tf.squeeze((bbox_y2 - bbox_y1) * (bbox_x2 - bbox_x1), axis=-1)\n","\n","    x_top = tf.maximum(bbox_x1, tf.transpose(gt_x1, transpose_perm))\n","    y_top = tf.maximum(bbox_y1, tf.transpose(gt_y1, transpose_perm))\n","    x_bottom = tf.minimum(bbox_x2, tf.transpose(gt_x2, transpose_perm))\n","    y_bottom = tf.minimum(bbox_y2, tf.transpose(gt_y2, transpose_perm))\n","\n","    # Calculate intersection area\n","    intersection_area = tf.maximum(x_bottom - x_top, 0) * tf.maximum(y_bottom - y_top, 0)\n","    # Calculate union area\n","    union_area = (tf.expand_dims(bbox_area, -1) + tf.expand_dims(gt_area, gt_expand_axis) - intersection_area)\n","    # Intersection over Union\n","    return intersection_area / union_area\n","\n","def get_bboxes_from_deltas(prior_boxes, deltas):\n","    \"\"\"Calculating bounding boxes for given bounding box and delta values.\n","    inputs:\n","        prior_boxes = (total_bboxes, [y1, x1, y2, x2])\n","        deltas = (batch_size, total_bboxes, [delta_y, delta_x, delta_h, delta_w])\n","\n","    outputs:\n","        final_boxes = (batch_size, total_bboxes, [y1, x1, y2, x2])\n","    \"\"\"\n","    all_pbox_width = prior_boxes[..., 3] - prior_boxes[..., 1]\n","    all_pbox_height = prior_boxes[..., 2] - prior_boxes[..., 0]\n","    all_pbox_ctr_x = prior_boxes[..., 1] + 0.5 * all_pbox_width\n","    all_pbox_ctr_y = prior_boxes[..., 0] + 0.5 * all_pbox_height\n","\n","    all_bbox_width = tf.exp(deltas[..., 3]) * all_pbox_width\n","    all_bbox_height = tf.exp(deltas[..., 2]) * all_pbox_height\n","    all_bbox_ctr_x = (deltas[..., 1] * all_pbox_width) + all_pbox_ctr_x\n","    all_bbox_ctr_y = (deltas[..., 0] * all_pbox_height) + all_pbox_ctr_y\n","\n","    # Calculate coordinates of predicted bounding box\n","    y1 = all_bbox_ctr_y - (0.5 * all_bbox_height)\n","    x1 = all_bbox_ctr_x - (0.5 * all_bbox_width)\n","    y2 = all_bbox_height + y1\n","    x2 = all_bbox_width + x1\n","\n","    return tf.stack([y1, x1, y2, x2], axis=-1)\n","\n","def get_deltas_from_bboxes(bboxes, gt_boxes):\n","    \"\"\"Calculating bounding box deltas for given bounding box and ground truth boxes.\n","    inputs:\n","        bboxes = (total_bboxes, [y1, x1, y2, x2])\n","        gt_boxes = (batch_size, total_bboxes, [y1, x1, y2, x2])\n","\n","    outputs:\n","        final_deltas = (batch_size, total_bboxes, [delta_y, delta_x, delta_h, delta_w])\n","    \"\"\"\n","    bbox_width = bboxes[..., 3] - bboxes[..., 1]\n","    bbox_height = bboxes[..., 2] - bboxes[..., 0]\n","    bbox_ctr_x = bboxes[..., 1] + 0.5 * bbox_width\n","    bbox_ctr_y = bboxes[..., 0] + 0.5 * bbox_height\n","\n","    try:\n","        gt_width = gt_boxes[..., 3] - gt_boxes[..., 1]\n","        gt_height = gt_boxes[..., 2] - gt_boxes[..., 0]\n","        gt_ctr_x = gt_boxes[..., 1] + 0.5 * gt_width\n","        gt_ctr_y = gt_boxes[..., 0] + 0.5 * gt_height\n","    except:\n","        tf.print(gt_boxes)\n","        tf.print(gt_boxes.shape)\n","\n","    # tf.where(condition, x, y) where values in x is replaced with y if false\n","    bbox_width = tf.where(tf.equal(bbox_width, 0), 1e-3, bbox_width)\n","    bbox_height = tf.where(tf.equal(bbox_height, 0), 1e-3, bbox_height)\n","\n","    delta_x = tf.where(tf.equal(gt_width, 0), tf.zeros_like(gt_width), tf.truediv((gt_ctr_x - bbox_ctr_x), bbox_width)) # 0 or offset/bbox_wdith\n","    delta_y = tf.where(tf.equal(gt_height, 0), tf.zeros_like(gt_height), tf.truediv((gt_ctr_y - bbox_ctr_y), bbox_height))\n","    delta_w = tf.where(tf.equal(gt_width, 0), tf.zeros_like(gt_width), tf.math.log(gt_width / bbox_width)) # 0 or ln(gt_width/bbox_width)\n","    delta_h = tf.where(tf.equal(gt_height, 0), tf.zeros_like(gt_height), tf.math.log(gt_height / bbox_height))\n","    return tf.stack([delta_y, delta_x, delta_h, delta_w], axis=-1)"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1708190199404,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"FngGpkXMT8F1"},"outputs":[],"source":["def renormalize_bboxes_with_min_max(bboxes, min_max):\n","    \"\"\"Renormalizing given bounding boxes to the new boundaries.\n","    r = (x - min) / (max - min)\n","    inputs:\n","        bboxes = (total_bboxes, [y1, x1, y2, x2])\n","        min_max = ([y_min, x_min, y_max, x_max])\n","\n","    outputs:\n","        normalized_bboxes = (total_bboxes, [y1, x1, y2, x2])\n","            in normalized form [0, 1]\n","    \"\"\"\n","    y_min, x_min, y_max, x_max = tf.split(min_max, 4)\n","    renomalized_bboxes = bboxes - tf.concat([y_min, x_min, y_min, x_min], -1)\n","    renomalized_bboxes /= tf.concat([y_max-y_min, x_max-x_min, y_max-y_min, x_max-x_min], -1)\n","    return tf.clip_by_value(renomalized_bboxes, 0, 1)\n","\n","def normalize_bboxes(bboxes, height, width):\n","    \"\"\"Normalizing bounding boxes.\n","    inputs:\n","        bboxes = (batch_size, total_bboxes, [y1, x1, y2, x2])\n","        height = image height\n","        width = image width\n","\n","    outputs:\n","        normalized_bboxes = (batch_size, total_bboxes, [y1, x1, y2, x2])\n","            in normalized form [0, 1]\n","    \"\"\"\n","    y1 = bboxes[..., 0] / height\n","    x1 = bboxes[..., 1] / width\n","    y2 = bboxes[..., 2] / height\n","    x2 = bboxes[..., 3] / width\n","    return tf.stack([y1, x1, y2, x2], axis=-1)\n","\n","def denormalize_bboxes(bboxes, height, width):\n","    \"\"\"Denormalizing bounding boxes.\n","    inputs:\n","        bboxes = (batch_size, total_bboxes, [y1, x1, y2, x2])\n","            in normalized form [0, 1]\n","        height = image height\n","        width = image width\n","\n","    outputs:\n","        denormalized_bboxes = (batch_size, total_bboxes, [y1, x1, y2, x2])\n","    \"\"\"\n","    y1 = bboxes[..., 0] * height\n","    x1 = bboxes[..., 1] * width\n","    y2 = bboxes[..., 2] * height\n","    x2 = bboxes[..., 3] * width\n","    return tf.round(tf.stack([y1, x1, y2, x2], axis=-1))"]},{"cell_type":"markdown","metadata":{"id":"hRkoKNc-F1Yw"},"source":["# drawing_utils"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1708190199404,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"ambu0h84FoUV"},"outputs":[],"source":["def draw_grid_map(img, grid_map, stride):\n","    \"\"\"Drawing grid intersection on given image.\n","    inputs:\n","        img = (height, width, channels)\n","        grid_map = (output_height * output_width, [y_index, x_index, y_index, x_index])\n","            tiled x, y coordinates\n","        stride = number of stride\n","\n","    outputs:\n","        array = (height, width, channels)\n","    \"\"\"\n","    image = Image.fromarray(img)\n","    draw = ImageDraw.Draw(image)\n","    counter = 0\n","    for grid in grid_map:\n","        draw.rectangle((\n","            grid[0] + stride // 2 - 2,\n","            grid[1] + stride // 2 - 2,\n","            grid[2] + stride // 2 + 2,\n","            grid[3] + stride // 2 + 2), fill=(255, 255, 255, 0))\n","        counter += 1\n","    plt.figure()\n","    plt.imshow(image)\n","    plt.show()\n","\n","def draw_bboxes(imgs, bboxes):\n","    \"\"\"Drawing bounding boxes on given images.\n","    inputs:\n","        imgs = (batch_size, height, width, channels)\n","        bboxes = (batch_size, total_bboxes, [y1, x1, y2, x2])\n","            in normalized form [0, 1]\n","    \"\"\"\n","    colors = tf.constant([[1, 0, 0, 1]], dtype=tf.float32)\n","    imgs_with_bb = tf.image.draw_bounding_boxes(imgs, bboxes, colors)\n","    plt.figure()\n","    for img_with_bb in imgs_with_bb:\n","        plt.imshow(img_with_bb)\n","        plt.show()\n","\n","def draw_bboxes_with_labels(img, bboxes, label_indices, probs, labels):\n","    \"\"\"Drawing bounding boxes with labels on given image.\n","    inputs:\n","        img = (height, width, channels)\n","        bboxes = (total_bboxes, [y1, x1, y2, x2])\n","            in denormalized form\n","        label_indices = (total_bboxes)\n","        probs = (total_bboxes)\n","        labels = [labels string list]\n","    \"\"\"\n","    colors = tf.random.uniform((len(labels), 4), maxval=256, dtype=tf.int32)\n","    image = tf.keras.preprocessing.image.array_to_img(img)\n","    width, height = image.size\n","    draw = ImageDraw.Draw(image)\n","    for index, bbox in enumerate(bboxes):\n","        y1, x1, y2, x2 = tf.split(bbox, 4)\n","        width = x2 - x1\n","        height = y2 - y1\n","        if width <= 0 or height <= 0:\n","            continue\n","        label_index = int(label_indices[index])\n","        color = tuple(colors[label_index].numpy())\n","        label_text = \"{0} {1:0.3f}\".format(labels[label_index], probs[index])\n","        draw.text((x1 + 4, y1 + 2), label_text, fill=color)\n","        draw.rectangle((x1, y1, x2, y2), outline=color, width=3)\n","    #\n","    plt.figure()\n","    plt.imshow(image)\n","    plt.show()\n","\n","def draw_predictions(dataset, pred_bboxes, pred_labels, pred_scores, labels, batch_size):\n","    for batch_id, image_data in enumerate(dataset):\n","        imgs, _, _ = image_data\n","        img_size = imgs.shape[1]\n","        start = batch_id * batch_size\n","        end = start + batch_size\n","        batch_bboxes, batch_labels, batch_scores = pred_bboxes[start:end], pred_labels[start:end], pred_scores[start:end]\n","        for i, img in enumerate(imgs):\n","            denormalized_bboxes = denormalize_bboxes(batch_bboxes[i], img_size, img_size)\n","            draw_bboxes_with_labels(img, denormalized_bboxes, batch_labels[i], batch_scores[i], labels)"]},{"cell_type":"markdown","metadata":{"id":"rZPgvuNbGMN_"},"source":["# io_utils"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1708190199405,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"u9QDiqrrGLm3"},"outputs":[],"source":["def get_log_path(model_type, custom_postfix=\"\"):\n","    \"\"\"Generating log path from model_type value for tensorboard.\n","    inputs:\n","        model_type = \"mobilenet_v2\"\n","        custom_postfix = any custom string for log folder name\n","\n","    outputs:\n","        log_path = tensorboard log path, for example: \"logs/mobilenet_v2/{date}\"\n","    \"\"\"\n","    return \"/content/drive/MyDrive/logs/{}{}/{}\".format(model_type, custom_postfix, datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","\n","def get_model_path(model_type):\n","    \"\"\"Generating model path from model_type value for save/load model weights.\n","    inputs:\n","        model_type = \"vgg16\", \"mobilenet_v2\"\n","\n","    outputs:\n","        model_path = os model path, for example: \"trained/ssd_vgg16_model_weights.h5\"\n","    \"\"\"\n","    main_path = \"/content/drive/MyDrive/trained\"\n","    if not os.path.exists(main_path):\n","        os.makedirs(main_path)\n","    model_path = os.path.join(main_path, \"ssd_{}_model_weights.h5\".format(model_type))\n","    return model_path"]},{"cell_type":"markdown","metadata":{"id":"odgPsWcyGRBW"},"source":["# train_utils"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1708190200075,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"NFs1NL6aGQkU"},"outputs":[],"source":["def scheduler(epoch):\n","    \"\"\"Generating learning rate value for a given epoch.\n","    inputs:\n","        epoch = number of current epoch\n","\n","    outputs:\n","        learning_rate = float learning rate value\n","    \"\"\"\n","    if epoch < 100:\n","        return hyper_params[\"lr\"]\n","    elif epoch < 125:\n","        return hyper_params[\"lr\"]*1e-1\n","    else:\n","        return hyper_params[\"lr\"]*1e-2\n","\n","def get_step_size(total_items, batch_size):\n","    \"\"\"Get step size for given total item size and batch size.\n","    inputs:\n","        total_items = number of total items\n","        batch_size = number of batch size during training or validation\n","\n","    outputs:\n","        step_size = number of step size for model training\n","    \"\"\"\n","    return math.ceil(total_items / batch_size)\n","\n","def calculate_actual_outputs(prior_boxes, gt_boxes, gt_labels, hyper_params):\n","    \"\"\"Calculate ssd actual output values.\n","    Batch operations supported.\n","    inputs:\n","        prior_boxes = (total_prior_boxes, [y1, x1, y2, x2])\n","            these values in normalized format between [0, 1]\n","        gt_boxes (batch_size, gt_box_size, [y1, x1, y2, x2])\n","            these values in normalized format between [0, 1]\n","        gt_labels (batch_size, gt_box_size)\n","        hyper_params = dictionary\n","\n","    outputs:\n","        bbox_deltas = (batch_size, total_bboxes, [delta_y, delta_x, delta_h, delta_w])\n","        bbox_labels = (batch_size, total_bboxes, [0,0,...,0])\n","            labels are one-hot encoded\n","    \"\"\"\n","    batch_size = tf.shape(gt_boxes)[0]\n","    total_labels = hyper_params[\"total_labels\"]\n","    iou_threshold = hyper_params[\"iou_threshold\"]\n","    variances = hyper_params[\"variances\"]\n","    # Number of default bbox\n","    total_prior_boxes = prior_boxes.shape[0]\n","    # Calculate iou values between each bboxes and ground truth boxes\n","    iou_map = generate_iou_map(prior_boxes, gt_boxes)\n","    # Get max index value for each row\n","    max_indices_each_gt_box = tf.argmax(iou_map, axis=2, output_type=tf.int32)\n","    # IoU map has iou values for every gt boxes and we merge these values column wise\n","    merged_iou_map = tf.reduce_max(iou_map, axis=2)\n","\n","    pos_cond = tf.greater(merged_iou_map, iou_threshold)\n","    gt_boxes_map = tf.gather(gt_boxes, max_indices_each_gt_box, batch_dims=1)\n","    expanded_gt_boxes = tf.where(tf.expand_dims(pos_cond, -1), gt_boxes_map, tf.zeros_like(gt_boxes_map))\n","    bbox_deltas = get_deltas_from_bboxes(prior_boxes, expanded_gt_boxes) / variances\n","\n","    gt_labels_map = tf.gather(gt_labels, max_indices_each_gt_box, batch_dims=1)\n","    expanded_gt_labels = tf.where(pos_cond, gt_labels_map, tf.zeros_like(gt_labels_map))\n","    bbox_labels = tf.one_hot(expanded_gt_labels, total_labels)\n","    return bbox_deltas, bbox_labels\n","\n","\n","def generator(dataset, prior_boxes, hyper_params):\n","    \"\"\"Tensorflow data generator for fit method, yielding inputs and outputs.\n","    inputs:\n","        dataset = tf.data.Dataset, PaddedBatchDataset\n","        prior_boxes = (total_prior_boxes, [y1, x1, y2, x2])\n","            these values in normalized format between [0, 1]\n","        hyper_params = dictionary\n","\n","    outputs:\n","        yield inputs, outputs\n","    \"\"\"\n","    while True:\n","        try:\n","            for image_data in dataset:\n","                img, gt_boxes, gt_labels = image_data\n","                # Calculate outputs for training\n","                actual_deltas, actual_labels = calculate_actual_outputs(prior_boxes, gt_boxes, gt_labels, hyper_params)\n","                yield img, (actual_deltas, actual_labels)\n","        except StopIteration:\n","            pass\n","        except:\n","            tf.print(img.shape, gt_boxes.shape, gt_labels.shape)\n","            tf.print(gt_boxes)\n","            pass"]},{"cell_type":"markdown","metadata":{"id":"KZ9rhI9ZGEKQ"},"source":["# eval_utils"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1708190200593,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"GIG-uml-F27J"},"outputs":[],"source":["def init_stats(labels):\n","    \"\"\"Initialise statistics used in evaluation.\n","    inputs:\n","        labels (list)\n","\n","    outputs:\n","        stats (dict)\n","    \"\"\"\n","    stats = {}\n","    for i, label in enumerate(labels):\n","        if i == 0: # first element is bg\n","            continue\n","        stats[i] = {\n","            \"label\": label,\n","            \"total\": 0,\n","            \"tp\": [],\n","            \"fp\": [],\n","            \"scores\": [],\n","        }\n","    return stats\n","\n","def update_stats(pred_bboxes, pred_labels, pred_scores, gt_boxes, gt_labels, stats):\n","    # Calculate iou values between predicted bboxes and ground truth boxes\n","    iou_map = generate_iou_map(pred_bboxes, gt_boxes)\n","    merged_iou_map = tf.reduce_max(iou_map, axis=-1)\n","    max_indices_each_gt = tf.argmax(iou_map, axis=-1, output_type=tf.int32)\n","    sorted_ids = tf.argsort(merged_iou_map, direction=\"DESCENDING\")\n","\n","    count_holder = tf.unique_with_counts(tf.reshape(gt_labels, (-1,)))\n","    for i, gt_label in enumerate(count_holder[0]):\n","        if gt_label == -1:\n","            continue\n","        gt_label = int(gt_label)\n","        stats[gt_label][\"total\"] += int(count_holder[2][i])\n","    for batch_id, m in enumerate(merged_iou_map):\n","        true_labels = []\n","        for i, sorted_id in enumerate(sorted_ids[batch_id]):\n","            pred_label = pred_labels[batch_id, sorted_id]\n","            if pred_label == 0:\n","                continue\n","\n","            iou = merged_iou_map[batch_id, sorted_id]\n","            gt_id = max_indices_each_gt[batch_id, sorted_id]\n","            gt_label = int(gt_labels[batch_id, gt_id])\n","            pred_label = int(pred_label)\n","            score = pred_scores[batch_id, sorted_id]\n","            stats[pred_label][\"scores\"].append(score)\n","            stats[pred_label][\"tp\"].append(0)\n","            stats[pred_label][\"fp\"].append(0)\n","            if iou >= 0.5 and pred_label == gt_label and gt_id not in true_labels:\n","                stats[pred_label][\"tp\"][-1] = 1\n","                true_labels.append(gt_id)\n","            else:\n","                stats[pred_label][\"fp\"][-1] = 1\n","    return stats\n","\n","def calculate_ap(recall, precision):\n","    \"\"\"Calculate Average Precision (AP).\n","    \"\"\"\n","    ap = 0\n","    for r in np.arange(0, 1.1, 0.1):\n","        prec_rec = precision[recall >= r]\n","        if len(prec_rec) > 0:\n","            ap += np.amax(prec_rec)\n","    # By definition AP = sum(max(precision whose recall is above r))/11\n","    ap /= 11\n","    return ap\n","\n","def calculate_mAP(stats):\n","    aps = []\n","    for label in stats:\n","        label_stats = stats[label]\n","        tp = np.array(label_stats[\"tp\"])\n","        fp = np.array(label_stats[\"fp\"])\n","        scores = np.array(label_stats[\"scores\"])\n","        ids = np.argsort(-scores)\n","        total = label_stats[\"total\"]\n","        accumulated_tp = np.cumsum(tp[ids])\n","        accumulated_fp = np.cumsum(fp[ids])\n","        recall = accumulated_tp / total\n","        precision = accumulated_tp / (accumulated_fp + accumulated_tp)\n","        ap = calculate_ap(recall, precision)\n","        stats[label][\"recall\"] = recall\n","        stats[label][\"precision\"] = precision\n","        stats[label][\"AP\"] = ap\n","        aps.append(ap)\n","    mAP = np.mean(aps)\n","    return stats, mAP\n","\n","def evaluate_predictions(dataset, pred_bboxes, pred_labels, pred_scores, labels, batch_size):\n","    stats = init_stats(labels)\n","    for batch_id, image_data in enumerate(dataset):\n","        imgs, gt_boxes, gt_labels = image_data\n","        # try:\n","        #     imgs, gt_boxes, gt_labels = image_data\n","        # except:\n","        #     imgs, gt_boxes, gt_labels = image_data[0], image_data[1][0], image_data[1][1]\n","        start = batch_id * batch_size\n","        end = start + batch_size\n","        batch_bboxes, batch_labels, batch_scores = pred_bboxes[start:end], pred_labels[start:end], pred_scores[start:end]\n","        stats = update_stats(batch_bboxes, batch_labels, batch_scores, gt_boxes, gt_labels, stats)\n","    stats, mAP = calculate_mAP(stats)\n","    print(\"mAP: {}\".format(float(mAP)))\n","    return stats, mAP"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1708190200593,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"T2QH8nntIUUq"},"outputs":[],"source":["class MeanAveragePrecisionCallback(tf.keras.callbacks.Callback):\n","    \"\"\"Calculate Mean Average Precision (mAP) at the end of every epoch.\n","    Early stop and saves model with best mAP.\n","    \"\"\"\n","    def __init__(self, val_data, val_steps, labels, prior_boxes, hyper_params, batch_size, patience, model_save_path, **kwargs):\n","        super(MeanAveragePrecisionCallback, self).__init__(**kwargs)\n","        self.val_data = val_data\n","        self.val_steps = val_steps\n","        self.labels = labels\n","        self.prior_boxes = prior_boxes\n","        self.hyper_params = hyper_params\n","        self.batch_size = batch_size\n","        self.best_mAP = 0.0\n","        self.mAP_values = []  # To store mAP values at each epoch\n","        self.patience = patience\n","        self.wait = 0\n","        self.model_save_path = model_save_path\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        ssd_decoder_model = get_decoder_model(self.model, self.prior_boxes, self.hyper_params)\n","        pred_bboxes, pred_labels, pred_scores = ssd_decoder_model.predict(self.val_data, steps=self.val_steps, verbose=1)\n","        stats, mAP = evaluate_predictions(self.val_data, pred_bboxes, pred_labels, pred_scores, self.labels, self.batch_size)\n","        self.mAP_values.append(mAP)\n","\n","        if mAP > self.best_mAP:\n","            self.wait = 0\n","            self.best_mAP = mAP\n","            self.model.save_weights(self.model_save_path)\n","        else:\n","            self.wait += 1\n","\n","        if self.wait >= self.patience:\n","            print(f\"Early stopping at epoch {epoch + 1} due to lack of improvement.\")\n","            self.model.stop_training = True\n","\n","    def on_train_begin(self, epoch, logs=None):\n","        self.best_mAP = 0.0\n","        self.wait = 0\n","        self.mAP_values = []\n","\n","    def on_train_end(self, logs=None):\n","        print(f'\\nBest Mean Average Precision: {self.best_mAP}\\n')\n","\n","    def get_mAP_values(self):\n","        return self.mAP_values"]},{"cell_type":"markdown","metadata":{"id":"BnvrtbMJGcah"},"source":["# decoder"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1708190201089,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"eLt0sLKBGYj-"},"outputs":[],"source":["from tensorflow.keras.layers import Layer, Input, Conv2D, MaxPool2D\n","from tensorflow.keras.models import Model\n","\n","class SSDDecoder(Layer):\n","    \"\"\"Generating bounding boxes and labels from ssd predictions.\n","    First calculating the boxes from predicted deltas and label probs.\n","    Then applied non max suppression and selecting top_n boxes by scores.\n","    inputs:\n","        pred_deltas = (batch_size, total_prior_boxes, [delta_y, delta_x, delta_h, delta_w])\n","        pred_label_probs = (batch_size, total_prior_boxes, [0,0,...,0])\n","    outputs:\n","        pred_bboxes = (batch_size, top_n, [y1, x1, y2, x2])\n","        pred_labels = (batch_size, top_n)\n","            1 to total label number\n","        pred_scores = (batch_size, top_n)\n","    \"\"\"\n","    def __init__(self, prior_boxes, variances, max_total_size=200, score_threshold=0.5, **kwargs):\n","        super(SSDDecoder, self).__init__(**kwargs)\n","        self.prior_boxes = prior_boxes\n","        self.variances = variances\n","        self.max_total_size = max_total_size\n","        self.score_threshold = score_threshold\n","\n","    def get_config(self):\n","        config = super(SSDDecoder, self).get_config()\n","        config.update({\n","            \"prior_boxes\": self.prior_boxes.numpy(),\n","            \"variances\": self.variances,\n","            \"max_total_size\": self.max_total_size,\n","            \"score_threshold\": self.score_threshold\n","        })\n","        return config\n","\n","    def call(self, inputs):\n","        pred_deltas = inputs[0]\n","        pred_label_probs = inputs[1]\n","        batch_size = tf.shape(pred_deltas)[0]\n","\n","        pred_deltas *= self.variances\n","        pred_bboxes = get_bboxes_from_deltas(self.prior_boxes, pred_deltas)\n","\n","        pred_labels_map = tf.expand_dims(tf.argmax(pred_label_probs, -1), -1)\n","        pred_labels = tf.where(tf.not_equal(pred_labels_map, 0), pred_label_probs, tf.zeros_like(pred_label_probs))\n","        # Reshape bboxes for non max suppression\n","        pred_bboxes = tf.reshape(pred_bboxes, (batch_size, -1, 1, 4))\n","\n","        final_bboxes, final_scores, final_labels, _ = non_max_suppression(\n","                                                                    pred_bboxes, pred_labels,\n","                                                                    max_output_size_per_class=self.max_total_size,\n","                                                                    max_total_size=self.max_total_size,\n","                                                                    score_threshold=self.score_threshold)\n","        return final_bboxes, final_labels, final_scores\n","\n","def get_decoder_model(base_model, prior_boxes, hyper_params):\n","    \"\"\"Decoding ssd predictions to valid bounding boxes and labels.\n","    inputs:\n","        base_model = tf.keras.model, base ssd model\n","        prior_boxes = (total_prior_boxes, [y1, x1, y2, x2])\n","            these values in normalized format between [0, 1]\n","        hyper_params = dictionary\n","\n","    outputs:\n","        ssd_decoder_model = tf.keras.model\n","    \"\"\"\n","    bboxes, classes, scores = SSDDecoder(prior_boxes, hyper_params[\"variances\"])(base_model.output)\n","    return Model(inputs=base_model.input, outputs=[bboxes, classes, scores])"]},{"cell_type":"markdown","metadata":{"id":"mEFNZpWUGoyx"},"source":["# header"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1708190202085,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"c0N10FKZGnBk"},"outputs":[],"source":["from tensorflow.keras.layers import Layer, Input, Conv2D, MaxPool2D, Activation\n","\n","class HeadWrapper(Layer):\n","    \"\"\"Merging all feature maps for detections.\n","    inputs:\n","        conv4_3 = (batch_size, (layer_shape x aspect_ratios), last_dimension)\n","            ssd300 conv4_3 shape => (38 x 38 x 4) = 5776\n","        conv7 = (batch_size, (layer_shape x aspect_ratios), last_dimension)\n","            ssd300 conv7 shape => (19 x 19 x 6) = 2166\n","        conv8_2 = (batch_size, (layer_shape x aspect_ratios), last_dimension)\n","            ssd300 conv8_2 shape => (10 x 10 x 6) = 600\n","        conv9_2 = (batch_size, (layer_shape x aspect_ratios), last_dimension)\n","            ssd300 conv9_2 shape => (5 x 5 x 6) = 150\n","        conv10_2 = (batch_size, (layer_shape x aspect_ratios), last_dimension)\n","            ssd300 conv10_2 shape => (3 x 3 x 4) = 36\n","        conv11_2 = (batch_size, (layer_shape x aspect_ratios), last_dimension)\n","            ssd300 conv11_2 shape => (1 x 1 x 4) = 4\n","                                           Total = 8732 default box\n","\n","    outputs:\n","        merged_head = (batch_size, total_prior_boxes, last_dimension)\n","    \"\"\"\n","\n","    def __init__(self, last_dimension, **kwargs):\n","        super(HeadWrapper, self).__init__(**kwargs)\n","        self.last_dimension = last_dimension\n","\n","    def get_config(self):\n","        config = super(HeadWrapper, self).get_config()\n","        config.update({\"last_dimension\": self.last_dimension})\n","        return config\n","\n","    def call(self, inputs):\n","        last_dimension = self.last_dimension\n","        batch_size = tf.shape(inputs[0])[0]\n","        outputs = []\n","        for conv_layer in inputs:\n","            outputs.append(tf.reshape(conv_layer, (batch_size, -1, last_dimension)))\n","        return tf.concat(outputs, axis=1)\n","\n","def get_head_from_outputs(hyper_params, outputs):\n","    \"\"\"Generating ssd bbox delta and label heads.\n","    inputs:\n","        hyper_params = dictionary\n","        outputs = list of ssd layers output to be used for prediction\n","\n","    outputs:\n","        pred_deltas = merged outputs for bbox delta head\n","        pred_labels = merged outputs for bbox label head\n","    \"\"\"\n","    total_labels = hyper_params[\"total_labels\"]\n","    # +1 for ratio 1\n","    len_aspect_ratios = [len(x) + 1 for x in hyper_params[\"aspect_ratios\"]]\n","    # print(len_aspect_ratios)\n","    labels_head = []\n","    boxes_head = []\n","    for i, output in enumerate(outputs):\n","        # print(i)\n","        aspect_ratio = len_aspect_ratios[i]\n","        labels_head.append(Conv2D(aspect_ratio * total_labels, (3, 3), padding=\"same\", name=\"{}_conv_label_output\".format(i+1))(output))\n","        boxes_head.append(Conv2D(aspect_ratio * 4, (3, 3), padding=\"same\", name=\"{}_conv_boxes_output\".format(i+1))(output))\n","\n","    pred_labels = HeadWrapper(total_labels, name=\"labels_head\")(labels_head)\n","    pred_labels = Activation(\"softmax\", name=\"conf\")(pred_labels)\n","\n","    pred_deltas = HeadWrapper(4, name=\"loc\")(boxes_head)\n","    return pred_deltas, pred_labels"]},{"cell_type":"markdown","metadata":{"id":"gJANTXL-HBrD"},"source":["# Main"]},{"cell_type":"markdown","metadata":{"id":"FaalWXrEH4PN"},"source":["# ssd_loss: cross-entropy/focal and huber loss\n","\n","Focal loss for classification task and Huber loss for regression task"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1708190203687,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"no7DmauDH51C"},"outputs":[],"source":["class CustomLoss(object):\n","    \"\"\"Composition of Focal and Huber losses.\"\"\"\n","\n","    def __init__(self, neg_pos_ratio, loc_loss_alpha,\n","                 alpha,\n","                 gamma,\n","                 use_focal=False):\n","        \"\"\"\n","        Args:\n","            neg_pos_ratio: a float number representing the negative to positive ratio.\n","            loc_loss_alpha: a float number representing the localization loss.\n","            alpha, gamma: a float number for Focal loss formula.\n","        \"\"\"\n","        self.neg_pos_ratio = tf.constant(neg_pos_ratio, dtype=tf.float32)\n","        self.loc_loss_alpha = tf.constant(loc_loss_alpha, dtype=tf.float32)\n","        self.alpha = tf.constant(alpha, dtype=tf.float32)\n","        self.gamma = tf.constant(gamma, dtype=tf.float32)\n","        self.use_focal = use_focal\n","\n","    def loc_loss_fn(self, actual_deltas, pred_deltas):\n","        \"\"\"Calculating SSD localization loss value for only positive samples.\n","        inputs:\n","            actual_deltas = (batch_size, total_prior_boxes, [delta_y, delta_x, delta_h, delta_w])\n","            pred_deltas = (batch_size, total_prior_boxes, [delta_y, delta_x, delta_h, delta_w])\n","\n","        outputs:\n","            loc_loss = localization / bbox / regression loss value\n","        \"\"\"\n","        # Localization / bbox / regression loss calculation for all bboxes\n","        loc_loss_fn = tf.losses.Huber(reduction=tf.losses.Reduction.NONE) # delta=1.0\n","        loc_loss_for_all = loc_loss_fn(actual_deltas, pred_deltas)\n","\n","        # After tf 2.2.0 version, the huber calculates mean over the last axis\n","        loc_loss_for_all = tf.cond(tf.greater(tf.rank(loc_loss_for_all), tf.constant(2)),\n","                                   lambda: tf.reduce_sum(loc_loss_for_all, axis=-1),\n","                                   lambda: loc_loss_for_all * tf.cast(tf.shape(pred_deltas)[-1], dtype=tf.float32))\n","\n","        # Creating Positive Mask\n","        pos_cond = tf.reduce_any(tf.not_equal(actual_deltas, tf.constant(0.0)), axis=2)\n","        pos_mask = tf.cast(pos_cond, dtype=tf.float32)\n","        # Counting Total Positive Bounding Boxes\n","        total_pos_bboxes = tf.reduce_sum(pos_mask, axis=1)\n","\n","        # Calculating Localization Loss for Positive Bounding Boxes\n","        loc_loss = tf.reduce_sum(pos_mask * loc_loss_for_all, axis=-1)\n","        # Handling Cases with No Positive Bounding Boxes\n","        total_pos_bboxes = tf.where(tf.equal(total_pos_bboxes, tf.constant(0.0)), tf.constant(1.0), total_pos_bboxes)\n","        # Final Localization Loss Calculation\n","        loc_loss = loc_loss / total_pos_bboxes\n","        return loc_loss * self.loc_loss_alpha\n","\n","    def conf_loss_fn(self, actual_labels, pred_labels):\n","        \"\"\"Calculating SSD confidence loss value with hard negative mining as mentioned in the paper.\n","        Replaced CategoricalCrossentropy with CategoricalFocalCrossentropy.\n","        inputs:\n","            actual_labels = (batch_size, total_prior_boxes, total_labels)\n","            pred_labels = (batch_size, total_prior_boxes, total_labels)\n","\n","        outputs:\n","            conf_loss = confidence / class / label loss value\n","        \"\"\"\n","        # tf.print(actual_labels) # one-hot\n","        # tf.print(pred_labels) # float32\n","\n","        # Confidence / Label loss calculation for all labels\n","        if self.use_focal:\n","            conf_loss_fn = tf.keras.losses.CategoricalFocalCrossentropy(alpha=self.alpha, gamma=self.gamma, reduction=tf.losses.Reduction.NONE)\n","            conf_loss_for_all = conf_loss_fn(actual_labels, pred_labels)\n","            # tf.print(\"Confidence Loss:\", conf_loss_for_all)\n","        else:\n","            conf_loss_fn = tf.losses.CategoricalCrossentropy(reduction=tf.losses.Reduction.NONE)\n","            conf_loss_for_all = conf_loss_fn(actual_labels, pred_labels)\n","            # tf.print(\"Confidence Loss:\", conf_loss_for_all)\n","\n","        # Creating Positive Mask for non-background class\n","        pos_cond = tf.reduce_any(tf.not_equal(actual_labels[..., 1:], tf.constant(0.0)), axis=2)\n","        pos_mask = tf.cast(pos_cond, dtype=tf.float32)\n","        # Counting Total Positive Bounding Boxes\n","        total_pos_bboxes = tf.reduce_sum(pos_mask, axis=1)\n","\n","        # Hard negative mining\n","        total_neg_bboxes = tf.cast(total_pos_bboxes * self.neg_pos_ratio, tf.int32)\n","\n","        masked_loss = conf_loss_for_all * actual_labels[..., 0]\n","        sorted_loss = tf.argsort(masked_loss, direction=\"DESCENDING\")\n","        sorted_loss = tf.argsort(sorted_loss)\n","        neg_cond = tf.less(sorted_loss, tf.expand_dims(total_neg_bboxes, axis=1))\n","        neg_mask = tf.cast(neg_cond, dtype=tf.float32)\n","\n","        final_mask = pos_mask + neg_mask\n","        conf_loss = tf.reduce_sum(final_mask * conf_loss_for_all, axis=-1)\n","        total_pos_bboxes = tf.where(tf.equal(total_pos_bboxes, tf.constant(0.0)), tf.constant(1.0), total_pos_bboxes)\n","        conf_loss = conf_loss / total_pos_bboxes\n","\n","        return conf_loss"]},{"cell_type":"markdown","metadata":{"id":"qpEJH16WFrWQ"},"source":["# data_utils"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1708190204921,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"1RSbUDlZFp-4"},"outputs":[],"source":["def preprocessing(image_data, final_height, final_width, augmentation_fn=None, evaluate=False):\n","    \"\"\"Image resizing operation handled before batch operations.\n","    inputs:\n","        image_data = tensorflow dataset image_data\n","        final_height = final image height after resizing\n","        final_width = final image width after resizing\n","\n","    outputs:\n","        img = (final_height, final_width, channels)\n","        gt_boxes = (gt_box_size, [y1, x1, y2, x2])\n","        gt_labels = (gt_box_size)\n","    \"\"\"\n","    img = image_data[\"image\"]\n","    gt_boxes = image_data[\"objects\"][\"bbox\"]\n","    gt_labels = tf.cast(image_data[\"objects\"][\"label\"] + 1, tf.int32)\n","    img = tf.image.convert_image_dtype(img, tf.float32)\n","    img = tf.image.resize(img, (final_height, final_width))\n","    if evaluate:\n","        not_diff = tf.logical_not(image_data[\"objects\"][\"is_difficult\"])\n","        gt_boxes = gt_boxes[not_diff]\n","        gt_labels = gt_labels[not_diff]\n","    if augmentation_fn:\n","        img, gt_boxes = augmentation_fn(img, gt_boxes)\n","    return img, gt_boxes, gt_labels\n","\n","def tfr_preprocessing(image_data, final_height, final_width, augmentation_fn=None, evaluate=False):\n","\n","    img = image_data[\"image/encoded\"]\n","    img = tf.io.decode_image(img, channels=3)\n","    xmin = tf.sparse.to_dense(image_data['image/object/bbox/xmin'])\n","    ymin = tf.sparse.to_dense(image_data['image/object/bbox/ymin'])\n","    xmax = tf.sparse.to_dense(image_data['image/object/bbox/xmax'])\n","    ymax = tf.sparse.to_dense(image_data['image/object/bbox/ymax'])\n","    gt_boxes = tf.stack(\n","        [ymin, xmin, ymax, xmax], axis=-1\n","    )\n","    gt_labels = tf.sparse.to_dense(image_data['image/object/class/label'])\n","    # gt_labels +=1 # VOC has idx 0 but tfr does not\n","    gt_labels = tf.cast(gt_labels, tf.int32)\n","    img = tf.image.convert_image_dtype(img, tf.float32)\n","    img.set_shape([None,None,3])\n","    img = tf.image.resize(img, (final_height, final_width))\n","    if augmentation_fn:\n","        img, gt_boxes = augmentation_fn(img, gt_boxes)\n","\n","    return img, gt_boxes, gt_labels\n","\n","def tfr_dataset(data_dir):\n","\n","    image_feature_description={\n","      'image/encoded':tf.io.FixedLenFeature([],tf.string),\n","      'image/object/bbox/xmin':tf.io.VarLenFeature(tf.float32),\n","      'image/object/bbox/ymin':tf.io.VarLenFeature(tf.float32),\n","      'image/object/bbox/xmax':tf.io.VarLenFeature(tf.float32),\n","      'image/object/bbox/ymax':tf.io.VarLenFeature(tf.float32),\n","      'image/object/class/label':tf.io.VarLenFeature(tf.int64),\n","    }\n","\n","    dataset = tf.data.TFRecordDataset(filenames=data_dir)\n","    count = 0\n","    for record in dataset:\n","        count += 1\n","    parsed_dataset = dataset.map(lambda x: tf.io.parse_single_example(x, image_feature_description))\n","\n","    return parsed_dataset, count\n","\n","def get_dataset(name, split, data_dir=\"~/tensorflow_datasets\"):\n","    \"\"\"Get tensorflow dataset split and info.\n","    inputs:\n","        name = name of the dataset, voc/2007, voc/2012, etc.\n","        split = data split string, should be one of [\"train\", \"validation\", \"test\"]\n","        data_dir = read/write path for tensorflow datasets\n","\n","    outputs:\n","        dataset = tensorflow dataset split\n","        info = tensorflow dataset info\n","    \"\"\"\n","    assert split in [\"train\", \"train+validation\", \"validation\", \"test\"]\n","    dataset, info = tfds.load(name, split=split, data_dir=data_dir, with_info=True)\n","    return dataset, info\n","\n","def get_total_item_size(info, split):\n","    \"\"\"Get total item size for given split.\n","    inputs:\n","        info = tensorflow dataset info\n","        split = data split string, should be one of [\"train\", \"validation\", \"test\"]\n","\n","    outputs:\n","        total_item_size = number of total items\n","    \"\"\"\n","    assert split in [\"train\", \"train+validation\", \"validation\", \"test\"]\n","    if split == \"train+validation\":\n","        return info.splits[\"train\"].num_examples + info.splits[\"validation\"].num_examples\n","    return info.splits[split].num_examples\n","\n","def tfr_labels(pbtxt_fname):\n","\n","    from object_detection.utils import label_map_util\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=90, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)\n","    print(categories)\n","    labels = [item['name'] for item in categories]\n","    return len(category_index.keys()), labels\n","\n","def get_labels(info):\n","    \"\"\"Get label names list.\n","    inputs:\n","        info = tensorflow dataset info\n","\n","    outputs:\n","        labels = [labels list]\n","    \"\"\"\n","    return info.features[\"labels\"].names\n","\n","def get_custom_imgs(custom_image_path):\n","    \"\"\"Generating a list of images for given path.\n","    inputs:\n","        custom_image_path = folder of the custom images\n","    outputs:\n","        custom image list = [path1, path2]\n","    \"\"\"\n","    img_paths = []\n","    for path, dir, filenames in os.walk(custom_image_path):\n","        for filename in filenames:\n","            img_paths.append(os.path.join(path, filename))\n","        break\n","    return img_paths\n","\n","def custom_data_generator(img_paths, final_height, final_width):\n","    \"\"\"Yielding custom entities as dataset.\n","    inputs:\n","        img_paths = custom image paths\n","        final_height = final image height after resizing\n","        final_width = final image width after resizing\n","    outputs:\n","        img = (final_height, final_width, depth)\n","        dummy_gt_boxes = (None, None)\n","        dummy_gt_labels = (None, )\n","    \"\"\"\n","    for img_path in img_paths:\n","        image = Image.open(img_path)\n","        resized_image = image.resize((final_width, final_height), Image.LANCZOS)\n","        img = np.array(resized_image)\n","        img = tf.image.convert_image_dtype(img, tf.float32)\n","        yield img, tf.constant([[]], dtype=tf.float32), tf.constant([], dtype=tf.int32)\n","\n","def get_data_types():\n","    \"\"\"Generating data types for tensorflow datasets.\n","    outputs:\n","        data types = output data types for (images, ground truth boxes, ground truth labels)\n","    \"\"\"\n","    return (tf.float32, tf.float32, tf.int32)\n","\n","def get_data_shapes():\n","    \"\"\"Generating data shapes for tensorflow datasets.\n","    outputs:\n","        data shapes = output data shapes for (images, ground truth boxes, ground truth labels)\n","    \"\"\"\n","    return ([None, None, None], [None, None], [None,])\n","\n","def get_padding_values():\n","    \"\"\"Generating padding values for missing values in batch for tensorflow datasets.\n","    outputs:\n","        padding values = padding values with dtypes for (images, ground truth boxes, ground truth labels)\n","    \"\"\"\n","    return (tf.constant(0, tf.float32), tf.constant(0, tf.float32), tf.constant(-1, tf.int32))"]},{"cell_type":"markdown","metadata":{"id":"amJ3m8RBjPU1"},"source":["# process Roboflow TFRecord\n","\n","\n","As of now, this only accepts TFR directly from Roboflow with apply removed from preprocessing.\n","\n","Issue: use_image_if_no_bounding_boxes=True leads to missing prediction."]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1708190205970,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"Djg8OEQWCOxp"},"outputs":[],"source":["def check_for_nans(parsed_dataset, final_height, final_width):\n","    for record in parsed_dataset:\n","        img, gt_boxes, gt_labels = tfr_preprocessing(record, final_height, final_width)\n","        gt_labels = tf.cast(gt_labels, tf.float32)\n","\n","        # Check for NaN values in the image tensor\n","        img_has_nan = tf.reduce_any(tf.math.is_nan(img))\n","\n","        # Check for NaN values in the ground truth boxes tensor\n","        gt_boxes_has_nan = tf.reduce_any(tf.math.is_nan(gt_boxes))\n","\n","        # Check for NaN values in the ground truth labels tensor\n","        gt_labels_has_nan = tf.reduce_any(tf.math.is_nan(gt_labels))\n","\n","        # Print information if NaN values are found\n","        if img_has_nan or gt_boxes_has_nan or gt_labels_has_nan:\n","            print(\"NaN values found in the dataset!\")\n","            print(\"Image has NaN values:\", img_has_nan.numpy())\n","            print(\"Ground truth boxes have NaN values:\", gt_boxes_has_nan.numpy())\n","            print(\"Ground truth labels have NaN values:\", gt_labels_has_nan.numpy())\n","\n","            # You can return or handle the information accordingly\n","            return True\n","\n","    print(\"No NaN values found in the dataset.\")\n","    return False"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1609,"status":"ok","timestamp":1708190208098,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"3uobVEH9Lidp","outputId":"52427f10-b9bf-4f67-d389-8f303b4f1bab"},"outputs":[{"name":"stdout","output_type":"stream","text":["[{'id': 1, 'name': 'Hole'}, {'id': 2, 'name': 'Knot'}, {'id': 3, 'name': 'Line'}, {'id': 4, 'name': 'Stain'}]\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-23-1d918a581818>:56: ignore_errors (from tensorflow.python.data.experimental.ops.error_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.ignore_errors` instead.\n"]},{"name":"stdout","output_type":"stream","text":["5724 225\n","4 ['bg', 'Hole', 'Knot', 'Line', 'Stain']\n","([None, None, None], [None, None], [None]) (<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=int32, numpy=-1>)\n"]}],"source":["# Train Parameters\n","batch_size = hyper_params[\"batch_size\"]\n","epochs = hyper_params[\"epochs\"]\n","load_weights = False\n","img_size = hyper_params[\"img_size\"] # determined by the backbone\n","\n","if hyper_params[\"dataset\"] == 0:\n","    # dut\n","    train_files='/content/Fabric-Defect-Capstone-1/train/defects.tfrecord'\n","    val_files='/content/Fabric-Defect-Capstone-1/valid/defects.tfrecord'\n","    test_files='/content/Fabric-Defect-Capstone-1/test/defects.tfrecord'\n","    num_classes, labels = tfr_labels('/content/Fabric-Defect-Capstone-1/train/defects_label_map.pbtxt')\n","elif hyper_params[\"dataset\"] == 1:\n","    # tilda\n","    train_files='/content/TILDA-Fabric-2/train/Fabric.tfrecord'\n","    val_files='/content/TILDA-Fabric-2/valid/Fabric.tfrecord'\n","    test_files='/content/TILDA-Fabric-2/test/Fabric.tfrecord'\n","    num_classes, labels = tfr_labels('/content/TILDA-Fabric-2/train/Fabric_label_map.pbtxt')\n","elif hyper_params[\"dataset\"] == 2:\n","    # daffodil\n","    train_files='/content/Fabric-Defect-Daffodil-1/train/defects.tfrecord'\n","    val_files='/content/Fabric-Defect-Daffodil-1/valid/defects.tfrecord'\n","    test_files='/content/Fabric-Defect-Daffodil-1/test/defects.tfrecord'\n","    num_classes, labels = tfr_labels('/content/Fabric-Defect-Daffodil-1/train/defects_label_map.pbtxt')\n","elif hyper_params[\"dataset\"] == 3:\n","    # thesis\n","    train_files='/content/Fabric-Defect-Thesis-1/train/defects.tfrecord'\n","    val_files='/content/Fabric-Defect-Thesis-1/valid/defects.tfrecord'\n","    test_files='/content/Fabric-Defect-Thesis-1/test/defects.tfrecord'\n","    num_classes, labels = tfr_labels('/content/Fabric-Defect-Thesis-1/train/defects_label_map.pbtxt')\n","elif hyper_params[\"dataset\"] == 4:\n","    pass\n","\n","train_data, train_total_items = tfr_dataset(train_files)\n","val_data, val_total_items = tfr_dataset(val_files)\n","\n","# check_for_nans(train_data, img_size, img_size)\n","# check_for_nans(val_data, img_size, img_size)\n","\n","labels = [\"bg\"] + labels\n","hyper_params[\"total_labels\"] = len(labels)\n","print(train_total_items, val_total_items)\n","print(num_classes, labels)\n","\n","train_data = train_data.map(lambda x : tfr_preprocessing(x, img_size, img_size))\n","val_data = val_data.map(lambda x : tfr_preprocessing(x, img_size, img_size))\n","\n","data_shapes = get_data_shapes()\n","padding_values = get_padding_values()\n","print(data_shapes, padding_values)\n","train_data = train_data.shuffle(batch_size*4).padded_batch(batch_size, padded_shapes=data_shapes, padding_values=padding_values)\n","val_data = val_data.padded_batch(batch_size, padded_shapes=data_shapes, padding_values=padding_values)\n","\n","def transform(dataset):\n","    autotune = tf.data.experimental.AUTOTUNE\n","    dataset = dataset.apply(tf.data.experimental.ignore_errors())\n","    dataset = dataset.repeat(epochs)\n","    dataset = dataset.prefetch(autotune)\n","    return dataset\n","\n","train_data = transform(train_data)\n","\n","ssd_train_feed = generator(train_data, prior_boxes, hyper_params)\n","ssd_val_feed = generator(val_data, prior_boxes, hyper_params)"]},{"cell_type":"markdown","metadata":{"id":"Nj-9WLjVHLhN"},"source":["# trainer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"tootxTnvHA3t"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"]},{"name":"stdout","output_type":"stream","text":["716 29\n","Epoch 1/200\n","  6/716 [..............................] - ETA: 4:05 - loss: 37.9149 - loc_loss: 4.3171 - conf_loss: 33.5978"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1820s vs `on_train_batch_end` time: 0.2092s). Check your callbacks.\n"]},{"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 5s 111ms/step\n","mAP: 0.0009100938728540043\n","716/716 [==============================] - 350s 424ms/step - loss: 14.6157 - loc_loss: 3.7895 - conf_loss: 10.8262 - val_loss: 10.1001 - val_loc_loss: 3.3234 - val_conf_loss: 6.7767 - lr: 1.0000e-05\n","Epoch 2/200\n","29/29 [==============================] - 5s 113ms/step\n","mAP: 0.02753264023210832\n","716/716 [==============================] - 287s 401ms/step - loss: 9.0814 - loc_loss: 3.3091 - conf_loss: 5.7723 - val_loss: 8.6901 - val_loc_loss: 3.1053 - val_conf_loss: 5.5848 - lr: 1.0000e-05\n","Epoch 3/200\n","29/29 [==============================] - 4s 112ms/step\n","mAP: 0.03699196035014383\n","716/716 [==============================] - 322s 449ms/step - loss: 7.9423 - loc_loss: 3.0765 - conf_loss: 4.8657 - val_loss: 7.5700 - val_loc_loss: 2.8580 - val_conf_loss: 4.7121 - lr: 1.0000e-05\n","Epoch 4/200\n","29/29 [==============================] - 5s 116ms/step\n","mAP: 0.05480417597826746\n","716/716 [==============================] - 283s 395ms/step - loss: 7.3592 - loc_loss: 2.9285 - conf_loss: 4.4307 - val_loss: 6.7415 - val_loc_loss: 2.6148 - val_conf_loss: 4.1267 - lr: 1.0000e-05\n","Epoch 5/200\n","29/29 [==============================] - 5s 119ms/step\n","mAP: 0.061349809103693725\n","716/716 [==============================] - 319s 446ms/step - loss: 6.9557 - loc_loss: 2.8153 - conf_loss: 4.1403 - val_loss: 6.1102 - val_loc_loss: 2.4139 - val_conf_loss: 3.6963 - lr: 1.0000e-05\n","Epoch 6/200\n","29/29 [==============================] - 5s 117ms/step\n","mAP: 0.07170040715786655\n","716/716 [==============================] - 326s 456ms/step - loss: 6.6381 - loc_loss: 2.7128 - conf_loss: 3.9253 - val_loss: 5.8027 - val_loc_loss: 2.3041 - val_conf_loss: 3.4986 - lr: 1.0000e-05\n","Epoch 7/200\n","29/29 [==============================] - 4s 112ms/step\n","mAP: 0.10115925930317149\n","716/716 [==============================] - 279s 390ms/step - loss: 6.3809 - loc_loss: 2.6259 - conf_loss: 3.7550 - val_loss: 5.5566 - val_loc_loss: 2.2228 - val_conf_loss: 3.3338 - lr: 1.0000e-05\n","Epoch 8/200\n","29/29 [==============================] - 4s 111ms/step\n","mAP: 0.10874186566458155\n","716/716 [==============================] - 278s 389ms/step - loss: 6.1476 - loc_loss: 2.5451 - conf_loss: 3.6025 - val_loss: 5.2717 - val_loc_loss: 2.1223 - val_conf_loss: 3.1494 - lr: 1.0000e-05\n","Epoch 9/200\n","29/29 [==============================] - 4s 110ms/step\n","mAP: 0.13531994616028228\n","716/716 [==============================] - 322s 450ms/step - loss: 5.9640 - loc_loss: 2.4756 - conf_loss: 3.4884 - val_loss: 5.0801 - val_loc_loss: 2.0608 - val_conf_loss: 3.0193 - lr: 1.0000e-05\n","Epoch 10/200\n","29/29 [==============================] - 4s 112ms/step\n","mAP: 0.13550068308171648\n","716/716 [==============================] - 279s 389ms/step - loss: 5.7888 - loc_loss: 2.4061 - conf_loss: 3.3827 - val_loss: 4.8833 - val_loc_loss: 1.9851 - val_conf_loss: 2.8982 - lr: 1.0000e-05\n","Epoch 11/200\n","29/29 [==============================] - 5s 119ms/step\n","mAP: 0.16226066673507414\n","716/716 [==============================] - 279s 389ms/step - loss: 5.6376 - loc_loss: 2.3441 - conf_loss: 3.2935 - val_loss: 4.7102 - val_loc_loss: 1.9110 - val_conf_loss: 2.7992 - lr: 1.0000e-05\n","Epoch 12/200\n","29/29 [==============================] - 4s 114ms/step\n","mAP: 0.1646655529367871\n","716/716 [==============================] - 279s 390ms/step - loss: 5.4766 - loc_loss: 2.2777 - conf_loss: 3.1989 - val_loss: 4.5738 - val_loc_loss: 1.8595 - val_conf_loss: 2.7143 - lr: 1.0000e-05\n","Epoch 13/200\n","29/29 [==============================] - 4s 112ms/step\n","mAP: 0.16434848628209348\n","716/716 [==============================] - 278s 388ms/step - loss: 5.3632 - loc_loss: 2.2218 - conf_loss: 3.1414 - val_loss: 4.4288 - val_loc_loss: 1.7927 - val_conf_loss: 2.6361 - lr: 1.0000e-05\n","Epoch 14/200\n","29/29 [==============================] - 5s 125ms/step\n","mAP: 0.16855307809245826\n","716/716 [==============================] - 279s 389ms/step - loss: 5.2331 - loc_loss: 2.1705 - conf_loss: 3.0625 - val_loss: 4.3394 - val_loc_loss: 1.7645 - val_conf_loss: 2.5749 - lr: 1.0000e-05\n","Epoch 15/200\n","29/29 [==============================] - 4s 110ms/step\n","mAP: 0.241283685219602\n","716/716 [==============================] - 283s 395ms/step - loss: 5.1252 - loc_loss: 2.1200 - conf_loss: 3.0052 - val_loss: 4.2745 - val_loc_loss: 1.7476 - val_conf_loss: 2.5268 - lr: 1.0000e-05\n","Epoch 16/200\n","29/29 [==============================] - 4s 112ms/step\n","mAP: 0.22761507950665938\n","716/716 [==============================] - 357s 499ms/step - loss: 4.9988 - loc_loss: 2.0649 - conf_loss: 2.9338 - val_loss: 4.1752 - val_loc_loss: 1.6970 - val_conf_loss: 2.4782 - lr: 1.0000e-05\n","Epoch 17/200\n","29/29 [==============================] - 5s 116ms/step\n","mAP: 0.24533269165291638\n","716/716 [==============================] - 278s 389ms/step - loss: 4.8976 - loc_loss: 2.0218 - conf_loss: 2.8758 - val_loss: 4.0475 - val_loc_loss: 1.6339 - val_conf_loss: 2.4136 - lr: 1.0000e-05\n","Epoch 18/200\n","29/29 [==============================] - 5s 111ms/step\n","mAP: 0.25819504046464975\n","716/716 [==============================] - 280s 390ms/step - loss: 4.7936 - loc_loss: 1.9633 - conf_loss: 2.8303 - val_loss: 4.0332 - val_loc_loss: 1.6427 - val_conf_loss: 2.3906 - lr: 1.0000e-05\n","Epoch 19/200\n","29/29 [==============================] - 5s 114ms/step\n","mAP: 0.26396166401896093\n","716/716 [==============================] - 279s 390ms/step - loss: 4.6961 - loc_loss: 1.9192 - conf_loss: 2.7769 - val_loss: 3.9386 - val_loc_loss: 1.6110 - val_conf_loss: 2.3276 - lr: 1.0000e-05\n","Epoch 20/200\n","29/29 [==============================] - 4s 110ms/step\n","mAP: 0.2540492435340967\n","716/716 [==============================] - 356s 497ms/step - loss: 4.6090 - loc_loss: 1.8772 - conf_loss: 2.7318 - val_loss: 3.8843 - val_loc_loss: 1.5710 - val_conf_loss: 2.3133 - lr: 1.0000e-05\n","Epoch 21/200\n","29/29 [==============================] - 5s 115ms/step\n","mAP: 0.2613945973866794\n","716/716 [==============================] - 279s 390ms/step - loss: 4.5294 - loc_loss: 1.8412 - conf_loss: 2.6883 - val_loss: 3.7984 - val_loc_loss: 1.5324 - val_conf_loss: 2.2660 - lr: 1.0000e-05\n","Epoch 22/200\n","29/29 [==============================] - 5s 121ms/step\n","mAP: 0.2934898598593182\n","716/716 [==============================] - 322s 450ms/step - loss: 4.4399 - loc_loss: 1.7993 - conf_loss: 2.6405 - val_loss: 3.7509 - val_loc_loss: 1.5071 - val_conf_loss: 2.2438 - lr: 1.0000e-05\n","Epoch 23/200\n","29/29 [==============================] - 4s 113ms/step\n","mAP: 0.2900855049584996\n","716/716 [==============================] - 281s 393ms/step - loss: 4.3637 - loc_loss: 1.7617 - conf_loss: 2.6021 - val_loss: 3.6540 - val_loc_loss: 1.4669 - val_conf_loss: 2.1871 - lr: 1.0000e-05\n","Epoch 24/200\n","29/29 [==============================] - 6s 143ms/step\n","mAP: 0.2935421884830649\n","716/716 [==============================] - 279s 390ms/step - loss: 4.2931 - loc_loss: 1.7227 - conf_loss: 2.5704 - val_loss: 3.5831 - val_loc_loss: 1.4320 - val_conf_loss: 2.1511 - lr: 1.0000e-05\n","Epoch 25/200\n","29/29 [==============================] - 5s 113ms/step\n","mAP: 0.31019131585740634\n","716/716 [==============================] - 280s 390ms/step - loss: 4.2096 - loc_loss: 1.6834 - conf_loss: 2.5261 - val_loss: 3.5507 - val_loc_loss: 1.4278 - val_conf_loss: 2.1228 - lr: 1.0000e-05\n","Epoch 26/200\n","29/29 [==============================] - 5s 113ms/step\n","mAP: 0.32939358674715213\n","716/716 [==============================] - 357s 499ms/step - loss: 4.1436 - loc_loss: 1.6538 - conf_loss: 2.4899 - val_loss: 3.4912 - val_loc_loss: 1.3873 - val_conf_loss: 2.1038 - lr: 1.0000e-05\n","Epoch 27/200\n","29/29 [==============================] - 4s 112ms/step\n","mAP: 0.3469567808250415\n","716/716 [==============================] - 282s 394ms/step - loss: 4.0843 - loc_loss: 1.6234 - conf_loss: 2.4610 - val_loss: 3.4575 - val_loc_loss: 1.3683 - val_conf_loss: 2.0892 - lr: 1.0000e-05\n","Epoch 28/200\n","29/29 [==============================] - 5s 115ms/step\n","mAP: 0.3522960368823922\n","716/716 [==============================] - 358s 501ms/step - loss: 4.0215 - loc_loss: 1.5927 - conf_loss: 2.4288 - val_loss: 3.3878 - val_loc_loss: 1.3416 - val_conf_loss: 2.0462 - lr: 1.0000e-05\n","Epoch 29/200\n","29/29 [==============================] - 4s 112ms/step\n","mAP: 0.37840404300372865\n","716/716 [==============================] - 283s 396ms/step - loss: 3.9704 - loc_loss: 1.5677 - conf_loss: 2.4027 - val_loss: 3.3384 - val_loc_loss: 1.3030 - val_conf_loss: 2.0354 - lr: 1.0000e-05\n","Epoch 30/200\n","29/29 [==============================] - 5s 118ms/step\n","mAP: 0.37717634546626405\n","716/716 [==============================] - 279s 390ms/step - loss: 3.9075 - loc_loss: 1.5314 - conf_loss: 2.3760 - val_loss: 3.2653 - val_loc_loss: 1.2592 - val_conf_loss: 2.0061 - lr: 1.0000e-05\n","Epoch 31/200\n","29/29 [==============================] - 4s 114ms/step\n","mAP: 0.3929393394264936\n","716/716 [==============================] - 278s 388ms/step - loss: 3.8502 - loc_loss: 1.5048 - conf_loss: 2.3454 - val_loss: 3.2441 - val_loc_loss: 1.2601 - val_conf_loss: 1.9840 - lr: 1.0000e-05\n","Epoch 32/200\n","29/29 [==============================] - 5s 112ms/step\n","mAP: 0.4020398000095748\n","716/716 [==============================] - 324s 453ms/step - loss: 3.7824 - loc_loss: 1.4770 - conf_loss: 2.3055 - val_loss: 3.1910 - val_loc_loss: 1.2203 - val_conf_loss: 1.9707 - lr: 1.0000e-05\n","Epoch 33/200\n","29/29 [==============================] - 4s 108ms/step\n","mAP: 0.40319935053537054\n","716/716 [==============================] - 279s 390ms/step - loss: 3.7332 - loc_loss: 1.4447 - conf_loss: 2.2885 - val_loss: 3.1905 - val_loc_loss: 1.2427 - val_conf_loss: 1.9478 - lr: 1.0000e-05\n","Epoch 34/200\n","29/29 [==============================] - 4s 110ms/step\n","mAP: 0.41766556039597597\n","716/716 [==============================] - 324s 453ms/step - loss: 3.6859 - loc_loss: 1.4225 - conf_loss: 2.2634 - val_loss: 3.1634 - val_loc_loss: 1.2324 - val_conf_loss: 1.9310 - lr: 1.0000e-05\n","Epoch 35/200\n","29/29 [==============================] - 5s 118ms/step\n","mAP: 0.3971572016458952\n","716/716 [==============================] - 279s 389ms/step - loss: 3.6365 - loc_loss: 1.4004 - conf_loss: 2.2361 - val_loss: 3.1221 - val_loc_loss: 1.2056 - val_conf_loss: 1.9164 - lr: 1.0000e-05\n","Epoch 36/200\n","29/29 [==============================] - 5s 113ms/step\n","mAP: 0.42828939002400246\n","716/716 [==============================] - 281s 393ms/step - loss: 3.5748 - loc_loss: 1.3693 - conf_loss: 2.2055 - val_loss: 3.0631 - val_loc_loss: 1.1751 - val_conf_loss: 1.8880 - lr: 1.0000e-05\n","Epoch 37/200\n","29/29 [==============================] - 5s 120ms/step\n","mAP: 0.44246028901683243\n","716/716 [==============================] - 278s 389ms/step - loss: 3.5357 - loc_loss: 1.3504 - conf_loss: 2.1854 - val_loss: 3.0245 - val_loc_loss: 1.1572 - val_conf_loss: 1.8673 - lr: 1.0000e-05\n","Epoch 38/200\n","29/29 [==============================] - 4s 111ms/step\n","mAP: 0.4448622082706385\n","716/716 [==============================] - 282s 394ms/step - loss: 3.4866 - loc_loss: 1.3252 - conf_loss: 2.1614 - val_loss: 3.0122 - val_loc_loss: 1.1425 - val_conf_loss: 1.8698 - lr: 1.0000e-05\n","Epoch 39/200\n","29/29 [==============================] - 5s 116ms/step\n","mAP: 0.4412302950494448\n","716/716 [==============================] - 278s 389ms/step - loss: 3.4378 - loc_loss: 1.3011 - conf_loss: 2.1366 - val_loss: 2.9777 - val_loc_loss: 1.1295 - val_conf_loss: 1.8482 - lr: 1.0000e-05\n","Epoch 40/200\n","29/29 [==============================] - 4s 114ms/step\n","mAP: 0.4548412690200294\n","716/716 [==============================] - 279s 390ms/step - loss: 3.4032 - loc_loss: 1.2850 - conf_loss: 2.1183 - val_loss: 2.9552 - val_loc_loss: 1.1167 - val_conf_loss: 1.8386 - lr: 1.0000e-05\n","Epoch 41/200\n","29/29 [==============================] - 5s 123ms/step\n","mAP: 0.4318447653202034\n","716/716 [==============================] - 279s 390ms/step - loss: 3.3557 - loc_loss: 1.2614 - conf_loss: 2.0943 - val_loss: 2.9070 - val_loc_loss: 1.0854 - val_conf_loss: 1.8216 - lr: 1.0000e-05\n","Epoch 42/200\n","29/29 [==============================] - 4s 112ms/step\n","mAP: 0.44271645015134103\n","716/716 [==============================] - 280s 390ms/step - loss: 3.3168 - loc_loss: 1.2438 - conf_loss: 2.0729 - val_loss: 2.8987 - val_loc_loss: 1.0715 - val_conf_loss: 1.8271 - lr: 1.0000e-05\n","Epoch 43/200\n","29/29 [==============================] - 5s 125ms/step\n","mAP: 0.44094096917324965\n","716/716 [==============================] - 279s 389ms/step - loss: 3.2712 - loc_loss: 1.2188 - conf_loss: 2.0524 - val_loss: 2.9105 - val_loc_loss: 1.0827 - val_conf_loss: 1.8278 - lr: 1.0000e-05\n","Epoch 44/200\n","29/29 [==============================] - 5s 114ms/step\n","mAP: 0.4189046037791331\n","716/716 [==============================] - 279s 389ms/step - loss: 3.2442 - loc_loss: 1.2049 - conf_loss: 2.0393 - val_loss: 2.8831 - val_loc_loss: 1.0701 - val_conf_loss: 1.8130 - lr: 1.0000e-05\n","Epoch 45/200\n","29/29 [==============================] - 4s 108ms/step\n","mAP: 0.4409661797215758\n","716/716 [==============================] - 278s 388ms/step - loss: 3.1945 - loc_loss: 1.1793 - conf_loss: 2.0152 - val_loss: 2.8657 - val_loc_loss: 1.0615 - val_conf_loss: 1.8042 - lr: 1.0000e-05\n","Epoch 46/200\n","29/29 [==============================] - 5s 121ms/step\n","mAP: 0.4405416500882672\n","716/716 [==============================] - 278s 388ms/step - loss: 3.1609 - loc_loss: 1.1658 - conf_loss: 1.9951 - val_loss: 2.8767 - val_loc_loss: 1.0761 - val_conf_loss: 1.8006 - lr: 1.0000e-05\n","Epoch 47/200\n","29/29 [==============================] - 5s 124ms/step\n","mAP: 0.4458970119257385\n","716/716 [==============================] - 357s 499ms/step - loss: 3.1359 - loc_loss: 1.1508 - conf_loss: 1.9851 - val_loss: 2.8231 - val_loc_loss: 1.0523 - val_conf_loss: 1.7708 - lr: 1.0000e-05\n","Epoch 48/200\n","29/29 [==============================] - 4s 114ms/step\n","mAP: 0.42557400063419165\n","716/716 [==============================] - 279s 390ms/step - loss: 3.0850 - loc_loss: 1.1295 - conf_loss: 1.9556 - val_loss: 2.7963 - val_loc_loss: 1.0376 - val_conf_loss: 1.7587 - lr: 1.0000e-05\n","Epoch 49/200\n","29/29 [==============================] - 5s 122ms/step\n","mAP: 0.44649574804257874\n","716/716 [==============================] - 280s 391ms/step - loss: 3.0588 - loc_loss: 1.1141 - conf_loss: 1.9447 - val_loss: 2.7757 - val_loc_loss: 1.0164 - val_conf_loss: 1.7593 - lr: 1.0000e-05\n","Epoch 50/200\n","29/29 [==============================] - 4s 112ms/step\n","mAP: 0.4552212426568695\n","716/716 [==============================] - 279s 390ms/step - loss: 3.0288 - loc_loss: 1.0991 - conf_loss: 1.9297 - val_loss: 2.7773 - val_loc_loss: 1.0153 - val_conf_loss: 1.7621 - lr: 1.0000e-05\n","Epoch 51/200\n","29/29 [==============================] - 4s 113ms/step\n","mAP: 0.45487733464312896\n","716/716 [==============================] - 278s 389ms/step - loss: 2.9935 - loc_loss: 1.0805 - conf_loss: 1.9130 - val_loss: 2.7577 - val_loc_loss: 1.0083 - val_conf_loss: 1.7494 - lr: 1.0000e-05\n","Epoch 52/200\n","29/29 [==============================] - 4s 114ms/step\n","mAP: 0.45118302223922935\n","716/716 [==============================] - 279s 390ms/step - loss: 2.9557 - loc_loss: 1.0643 - conf_loss: 1.8915 - val_loss: 2.7467 - val_loc_loss: 1.0050 - val_conf_loss: 1.7417 - lr: 1.0000e-05\n","Epoch 53/200\n","29/29 [==============================] - 5s 114ms/step\n","mAP: 0.4598860515121208\n","716/716 [==============================] - 281s 392ms/step - loss: 2.9164 - loc_loss: 1.0465 - conf_loss: 1.8699 - val_loss: 2.7220 - val_loc_loss: 0.9876 - val_conf_loss: 1.7345 - lr: 1.0000e-05\n","Epoch 54/200\n","29/29 [==============================] - 5s 117ms/step\n","mAP: 0.46071337464496465\n","716/716 [==============================] - 279s 389ms/step - loss: 2.8914 - loc_loss: 1.0340 - conf_loss: 1.8575 - val_loss: 2.7401 - val_loc_loss: 0.9997 - val_conf_loss: 1.7404 - lr: 1.0000e-05\n","Epoch 55/200\n","29/29 [==============================] - 4s 114ms/step\n","mAP: 0.4583008346738627\n","716/716 [==============================] - 280s 391ms/step - loss: 2.8708 - loc_loss: 1.0238 - conf_loss: 1.8470 - val_loss: 2.7178 - val_loc_loss: 0.9939 - val_conf_loss: 1.7239 - lr: 1.0000e-05\n","Epoch 56/200\n","29/29 [==============================] - 5s 128ms/step\n","mAP: 0.4632565347896878\n","716/716 [==============================] - 278s 388ms/step - loss: 2.8315 - loc_loss: 1.0056 - conf_loss: 1.8259 - val_loss: 2.6977 - val_loc_loss: 0.9822 - val_conf_loss: 1.7155 - lr: 1.0000e-05\n","Epoch 57/200\n","29/29 [==============================] - 4s 111ms/step\n","mAP: 0.46004742581031194\n","716/716 [==============================] - 278s 388ms/step - loss: 2.8047 - loc_loss: 0.9947 - conf_loss: 1.8101 - val_loss: 2.6886 - val_loc_loss: 0.9778 - val_conf_loss: 1.7108 - lr: 1.0000e-05\n","Epoch 58/200\n","29/29 [==============================] - 5s 121ms/step\n","mAP: 0.4526793118709326\n","716/716 [==============================] - 277s 386ms/step - loss: 2.7893 - loc_loss: 0.9885 - conf_loss: 1.8008 - val_loss: 2.6691 - val_loc_loss: 0.9579 - val_conf_loss: 1.7112 - lr: 1.0000e-05\n","Epoch 59/200\n","29/29 [==============================] - 4s 111ms/step\n","mAP: 0.4644661129712754\n","716/716 [==============================] - 279s 390ms/step - loss: 2.7483 - loc_loss: 0.9679 - conf_loss: 1.7804 - val_loss: 2.6755 - val_loc_loss: 0.9719 - val_conf_loss: 1.7036 - lr: 1.0000e-05\n","Epoch 60/200\n","29/29 [==============================] - 5s 116ms/step\n","mAP: 0.4700582829602597\n","716/716 [==============================] - 355s 497ms/step - loss: 2.7195 - loc_loss: 0.9543 - conf_loss: 1.7652 - val_loss: 2.6545 - val_loc_loss: 0.9694 - val_conf_loss: 1.6852 - lr: 1.0000e-05\n","Epoch 61/200\n","29/29 [==============================] - 4s 111ms/step\n","mAP: 0.4580650144571571\n","716/716 [==============================] - 278s 388ms/step - loss: 2.6934 - loc_loss: 0.9433 - conf_loss: 1.7501 - val_loss: 2.6512 - val_loc_loss: 0.9701 - val_conf_loss: 1.6811 - lr: 1.0000e-05\n","Epoch 62/200\n","29/29 [==============================] - 5s 116ms/step\n","mAP: 0.4637678347020724\n","716/716 [==============================] - 277s 387ms/step - loss: 2.6725 - loc_loss: 0.9346 - conf_loss: 1.7378 - val_loss: 2.6496 - val_loc_loss: 0.9720 - val_conf_loss: 1.6776 - lr: 1.0000e-05\n","Epoch 63/200\n","29/29 [==============================] - 4s 111ms/step\n","mAP: 0.4449505706742102\n","716/716 [==============================] - 278s 388ms/step - loss: 2.6460 - loc_loss: 0.9222 - conf_loss: 1.7238 - val_loss: 2.6485 - val_loc_loss: 0.9612 - val_conf_loss: 1.6872 - lr: 1.0000e-05\n","Epoch 64/200\n","29/29 [==============================] - 5s 121ms/step\n","mAP: 0.45909209109360444\n","716/716 [==============================] - 278s 389ms/step - loss: 2.6128 - loc_loss: 0.9058 - conf_loss: 1.7070 - val_loss: 2.6394 - val_loc_loss: 0.9478 - val_conf_loss: 1.6915 - lr: 1.0000e-05\n","Epoch 65/200\n","29/29 [==============================] - 4s 112ms/step\n","mAP: 0.464783941701723\n","716/716 [==============================] - 277s 387ms/step - loss: 2.5994 - loc_loss: 0.9007 - conf_loss: 1.6986 - val_loss: 2.6189 - val_loc_loss: 0.9496 - val_conf_loss: 1.6693 - lr: 1.0000e-05\n","Epoch 66/200\n","29/29 [==============================] - 4s 113ms/step\n","mAP: 0.46512232764942585\n","716/716 [==============================] - 278s 388ms/step - loss: 2.5631 - loc_loss: 0.8836 - conf_loss: 1.6795 - val_loss: 2.6036 - val_loc_loss: 0.9416 - val_conf_loss: 1.6619 - lr: 1.0000e-05\n","Epoch 67/200\n","29/29 [==============================] - 5s 125ms/step\n","mAP: 0.46254233815236384\n","716/716 [==============================] - 277s 387ms/step - loss: 2.5366 - loc_loss: 0.8726 - conf_loss: 1.6640 - val_loss: 2.6061 - val_loc_loss: 0.9440 - val_conf_loss: 1.6621 - lr: 1.0000e-05\n","Epoch 68/200\n","694/716 [============================>.] - ETA: 7s - loss: 2.5172 - loc_loss: 0.8664 - conf_loss: 1.6508"]}],"source":["from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, LearningRateScheduler\n","from tensorflow.keras.optimizers import SGD, Adam\n","\n","ssd_custom_losses = CustomLoss(hyper_params[\"neg_pos_ratio\"], hyper_params[\"loc_loss_alpha\"],\n","                               hyper_params[\"alpha\"], hyper_params[\"gamma\"], hyper_params[\"use_focal\"])\n","\n","ssd_model = get_model(hyper_params)\n","ssd_model.compile(optimizer=Adam(learning_rate=hyper_params[\"lr\"]),\n","                  loss=[ssd_custom_losses.loc_loss_fn, ssd_custom_losses.conf_loss_fn])\n","init_model(ssd_model, img_size)\n","\n","ssd_model_path = get_model_path(backbone)\n","if load_weights:\n","    ssd_model.load_weights(ssd_model_path)\n","ssd_log_path = get_log_path(backbone)\n","\n","step_size_train = get_step_size(train_total_items, batch_size)\n","step_size_val = get_step_size(val_total_items, batch_size)\n","print(step_size_train, step_size_val)\n","\n","# Moved under mAP_callback\n","# checkpoint_callback = ModelCheckpoint(ssd_model_path, monitor=\"val_loss\", save_best_only=True, save_weights_only=True)\n","learning_rate_callback = LearningRateScheduler(scheduler, verbose=0)\n","tensorboard_callback = TensorBoard(log_dir=ssd_log_path)\n","# mAP_callback both early stopping and checkpoint\n","mAP_callback = MeanAveragePrecisionCallback(val_data, step_size_val, labels, prior_boxes, hyper_params,\n","                                            batch_size, hyper_params[\"patience\"], ssd_model_path)\n","\n","history = ssd_model.fit(ssd_train_feed,\n","              steps_per_epoch=step_size_train,\n","              validation_data=ssd_val_feed,\n","              validation_steps=step_size_val,\n","              epochs=epochs,\n","              callbacks=[tensorboard_callback, learning_rate_callback, mAP_callback],\n","              use_multiprocessing = False)"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2502,"status":"ok","timestamp":1708189638727,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"r8bG8i6PPpkg","outputId":"60175c7a-c366-458f-ffcd-e7505409cd3c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_2 (InputLayer)        [(None, 640, 640, 3)]        0         []                            \n","                                                                                                  \n"," Conv1 (Conv2D)              (None, 320, 320, 32)         864       ['input_2[0][0]']             \n","                                                                                                  \n"," bn_Conv1 (BatchNormalizati  (None, 320, 320, 32)         128       ['Conv1[0][0]']               \n"," on)                                                                                              \n","                                                                                                  \n"," Conv1_relu (ReLU)           (None, 320, 320, 32)         0         ['bn_Conv1[0][0]']            \n","                                                                                                  \n"," expanded_conv_depthwise (D  (None, 320, 320, 32)         288       ['Conv1_relu[0][0]']          \n"," epthwiseConv2D)                                                                                  \n","                                                                                                  \n"," expanded_conv_depthwise_BN  (None, 320, 320, 32)         128       ['expanded_conv_depthwise[0][0\n","  (BatchNormalization)                                              ]']                           \n","                                                                                                  \n"," expanded_conv_depthwise_re  (None, 320, 320, 32)         0         ['expanded_conv_depthwise_BN[0\n"," lu (ReLU)                                                          ][0]']                        \n","                                                                                                  \n"," expanded_conv_project (Con  (None, 320, 320, 16)         512       ['expanded_conv_depthwise_relu\n"," v2D)                                                               [0][0]']                      \n","                                                                                                  \n"," expanded_conv_project_BN (  (None, 320, 320, 16)         64        ['expanded_conv_project[0][0]'\n"," BatchNormalization)                                                ]                             \n","                                                                                                  \n"," block_1_expand (Conv2D)     (None, 320, 320, 96)         1536      ['expanded_conv_project_BN[0][\n","                                                                    0]']                          \n","                                                                                                  \n"," block_1_expand_BN (BatchNo  (None, 320, 320, 96)         384       ['block_1_expand[0][0]']      \n"," rmalization)                                                                                     \n","                                                                                                  \n"," block_1_expand_relu (ReLU)  (None, 320, 320, 96)         0         ['block_1_expand_BN[0][0]']   \n","                                                                                                  \n"," block_1_pad (ZeroPadding2D  (None, 321, 321, 96)         0         ['block_1_expand_relu[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," block_1_depthwise (Depthwi  (None, 160, 160, 96)         864       ['block_1_pad[0][0]']         \n"," seConv2D)                                                                                        \n","                                                                                                  \n"," block_1_depthwise_BN (Batc  (None, 160, 160, 96)         384       ['block_1_depthwise[0][0]']   \n"," hNormalization)                                                                                  \n","                                                                                                  \n"," block_1_depthwise_relu (Re  (None, 160, 160, 96)         0         ['block_1_depthwise_BN[0][0]']\n"," LU)                                                                                              \n","                                                                                                  \n"," block_1_project (Conv2D)    (None, 160, 160, 24)         2304      ['block_1_depthwise_relu[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," block_1_project_BN (BatchN  (None, 160, 160, 24)         96        ['block_1_project[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_2_expand (Conv2D)     (None, 160, 160, 144)        3456      ['block_1_project_BN[0][0]']  \n","                                                                                                  \n"," block_2_expand_BN (BatchNo  (None, 160, 160, 144)        576       ['block_2_expand[0][0]']      \n"," rmalization)                                                                                     \n","                                                                                                  \n"," block_2_expand_relu (ReLU)  (None, 160, 160, 144)        0         ['block_2_expand_BN[0][0]']   \n","                                                                                                  \n"," block_2_depthwise (Depthwi  (None, 160, 160, 144)        1296      ['block_2_expand_relu[0][0]'] \n"," seConv2D)                                                                                        \n","                                                                                                  \n"," block_2_depthwise_BN (Batc  (None, 160, 160, 144)        576       ['block_2_depthwise[0][0]']   \n"," hNormalization)                                                                                  \n","                                                                                                  \n"," block_2_depthwise_relu (Re  (None, 160, 160, 144)        0         ['block_2_depthwise_BN[0][0]']\n"," LU)                                                                                              \n","                                                                                                  \n"," block_2_project (Conv2D)    (None, 160, 160, 24)         3456      ['block_2_depthwise_relu[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," block_2_project_BN (BatchN  (None, 160, 160, 24)         96        ['block_2_project[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_2_add (Add)           (None, 160, 160, 24)         0         ['block_1_project_BN[0][0]',  \n","                                                                     'block_2_project_BN[0][0]']  \n","                                                                                                  \n"," block_3_expand (Conv2D)     (None, 160, 160, 144)        3456      ['block_2_add[0][0]']         \n","                                                                                                  \n"," block_3_expand_BN (BatchNo  (None, 160, 160, 144)        576       ['block_3_expand[0][0]']      \n"," rmalization)                                                                                     \n","                                                                                                  \n"," block_3_expand_relu (ReLU)  (None, 160, 160, 144)        0         ['block_3_expand_BN[0][0]']   \n","                                                                                                  \n"," block_3_pad (ZeroPadding2D  (None, 161, 161, 144)        0         ['block_3_expand_relu[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," block_3_depthwise (Depthwi  (None, 80, 80, 144)          1296      ['block_3_pad[0][0]']         \n"," seConv2D)                                                                                        \n","                                                                                                  \n"," block_3_depthwise_BN (Batc  (None, 80, 80, 144)          576       ['block_3_depthwise[0][0]']   \n"," hNormalization)                                                                                  \n","                                                                                                  \n"," block_3_depthwise_relu (Re  (None, 80, 80, 144)          0         ['block_3_depthwise_BN[0][0]']\n"," LU)                                                                                              \n","                                                                                                  \n"," block_3_project (Conv2D)    (None, 80, 80, 32)           4608      ['block_3_depthwise_relu[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," block_3_project_BN (BatchN  (None, 80, 80, 32)           128       ['block_3_project[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_4_expand (Conv2D)     (None, 80, 80, 192)          6144      ['block_3_project_BN[0][0]']  \n","                                                                                                  \n"," block_4_expand_BN (BatchNo  (None, 80, 80, 192)          768       ['block_4_expand[0][0]']      \n"," rmalization)                                                                                     \n","                                                                                                  \n"," block_4_expand_relu (ReLU)  (None, 80, 80, 192)          0         ['block_4_expand_BN[0][0]']   \n","                                                                                                  \n"," block_4_depthwise (Depthwi  (None, 80, 80, 192)          1728      ['block_4_expand_relu[0][0]'] \n"," seConv2D)                                                                                        \n","                                                                                                  \n"," block_4_depthwise_BN (Batc  (None, 80, 80, 192)          768       ['block_4_depthwise[0][0]']   \n"," hNormalization)                                                                                  \n","                                                                                                  \n"," block_4_depthwise_relu (Re  (None, 80, 80, 192)          0         ['block_4_depthwise_BN[0][0]']\n"," LU)                                                                                              \n","                                                                                                  \n"," block_4_project (Conv2D)    (None, 80, 80, 32)           6144      ['block_4_depthwise_relu[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," block_4_project_BN (BatchN  (None, 80, 80, 32)           128       ['block_4_project[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_4_add (Add)           (None, 80, 80, 32)           0         ['block_3_project_BN[0][0]',  \n","                                                                     'block_4_project_BN[0][0]']  \n","                                                                                                  \n"," block_5_expand (Conv2D)     (None, 80, 80, 192)          6144      ['block_4_add[0][0]']         \n","                                                                                                  \n"," block_5_expand_BN (BatchNo  (None, 80, 80, 192)          768       ['block_5_expand[0][0]']      \n"," rmalization)                                                                                     \n","                                                                                                  \n"," block_5_expand_relu (ReLU)  (None, 80, 80, 192)          0         ['block_5_expand_BN[0][0]']   \n","                                                                                                  \n"," block_5_depthwise (Depthwi  (None, 80, 80, 192)          1728      ['block_5_expand_relu[0][0]'] \n"," seConv2D)                                                                                        \n","                                                                                                  \n"," block_5_depthwise_BN (Batc  (None, 80, 80, 192)          768       ['block_5_depthwise[0][0]']   \n"," hNormalization)                                                                                  \n","                                                                                                  \n"," block_5_depthwise_relu (Re  (None, 80, 80, 192)          0         ['block_5_depthwise_BN[0][0]']\n"," LU)                                                                                              \n","                                                                                                  \n"," block_5_project (Conv2D)    (None, 80, 80, 32)           6144      ['block_5_depthwise_relu[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," block_5_project_BN (BatchN  (None, 80, 80, 32)           128       ['block_5_project[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_5_add (Add)           (None, 80, 80, 32)           0         ['block_4_add[0][0]',         \n","                                                                     'block_5_project_BN[0][0]']  \n","                                                                                                  \n"," block_6_expand (Conv2D)     (None, 80, 80, 192)          6144      ['block_5_add[0][0]']         \n","                                                                                                  \n"," block_6_expand_BN (BatchNo  (None, 80, 80, 192)          768       ['block_6_expand[0][0]']      \n"," rmalization)                                                                                     \n","                                                                                                  \n"," block_6_expand_relu (ReLU)  (None, 80, 80, 192)          0         ['block_6_expand_BN[0][0]']   \n","                                                                                                  \n"," block_6_pad (ZeroPadding2D  (None, 81, 81, 192)          0         ['block_6_expand_relu[0][0]'] \n"," )                                                                                                \n","                                                                                                  \n"," block_6_depthwise (Depthwi  (None, 40, 40, 192)          1728      ['block_6_pad[0][0]']         \n"," seConv2D)                                                                                        \n","                                                                                                  \n"," block_6_depthwise_BN (Batc  (None, 40, 40, 192)          768       ['block_6_depthwise[0][0]']   \n"," hNormalization)                                                                                  \n","                                                                                                  \n"," block_6_depthwise_relu (Re  (None, 40, 40, 192)          0         ['block_6_depthwise_BN[0][0]']\n"," LU)                                                                                              \n","                                                                                                  \n"," block_6_project (Conv2D)    (None, 40, 40, 64)           12288     ['block_6_depthwise_relu[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," block_6_project_BN (BatchN  (None, 40, 40, 64)           256       ['block_6_project[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_7_expand (Conv2D)     (None, 40, 40, 384)          24576     ['block_6_project_BN[0][0]']  \n","                                                                                                  \n"," block_7_expand_BN (BatchNo  (None, 40, 40, 384)          1536      ['block_7_expand[0][0]']      \n"," rmalization)                                                                                     \n","                                                                                                  \n"," block_7_expand_relu (ReLU)  (None, 40, 40, 384)          0         ['block_7_expand_BN[0][0]']   \n","                                                                                                  \n"," block_7_depthwise (Depthwi  (None, 40, 40, 384)          3456      ['block_7_expand_relu[0][0]'] \n"," seConv2D)                                                                                        \n","                                                                                                  \n"," block_7_depthwise_BN (Batc  (None, 40, 40, 384)          1536      ['block_7_depthwise[0][0]']   \n"," hNormalization)                                                                                  \n","                                                                                                  \n"," block_7_depthwise_relu (Re  (None, 40, 40, 384)          0         ['block_7_depthwise_BN[0][0]']\n"," LU)                                                                                              \n","                                                                                                  \n"," block_7_project (Conv2D)    (None, 40, 40, 64)           24576     ['block_7_depthwise_relu[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," block_7_project_BN (BatchN  (None, 40, 40, 64)           256       ['block_7_project[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_7_add (Add)           (None, 40, 40, 64)           0         ['block_6_project_BN[0][0]',  \n","                                                                     'block_7_project_BN[0][0]']  \n","                                                                                                  \n"," block_8_expand (Conv2D)     (None, 40, 40, 384)          24576     ['block_7_add[0][0]']         \n","                                                                                                  \n"," block_8_expand_BN (BatchNo  (None, 40, 40, 384)          1536      ['block_8_expand[0][0]']      \n"," rmalization)                                                                                     \n","                                                                                                  \n"," block_8_expand_relu (ReLU)  (None, 40, 40, 384)          0         ['block_8_expand_BN[0][0]']   \n","                                                                                                  \n"," block_8_depthwise (Depthwi  (None, 40, 40, 384)          3456      ['block_8_expand_relu[0][0]'] \n"," seConv2D)                                                                                        \n","                                                                                                  \n"," block_8_depthwise_BN (Batc  (None, 40, 40, 384)          1536      ['block_8_depthwise[0][0]']   \n"," hNormalization)                                                                                  \n","                                                                                                  \n"," block_8_depthwise_relu (Re  (None, 40, 40, 384)          0         ['block_8_depthwise_BN[0][0]']\n"," LU)                                                                                              \n","                                                                                                  \n"," block_8_project (Conv2D)    (None, 40, 40, 64)           24576     ['block_8_depthwise_relu[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," block_8_project_BN (BatchN  (None, 40, 40, 64)           256       ['block_8_project[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_8_add (Add)           (None, 40, 40, 64)           0         ['block_7_add[0][0]',         \n","                                                                     'block_8_project_BN[0][0]']  \n","                                                                                                  \n"," block_9_expand (Conv2D)     (None, 40, 40, 384)          24576     ['block_8_add[0][0]']         \n","                                                                                                  \n"," block_9_expand_BN (BatchNo  (None, 40, 40, 384)          1536      ['block_9_expand[0][0]']      \n"," rmalization)                                                                                     \n","                                                                                                  \n"," block_9_expand_relu (ReLU)  (None, 40, 40, 384)          0         ['block_9_expand_BN[0][0]']   \n","                                                                                                  \n"," block_9_depthwise (Depthwi  (None, 40, 40, 384)          3456      ['block_9_expand_relu[0][0]'] \n"," seConv2D)                                                                                        \n","                                                                                                  \n"," block_9_depthwise_BN (Batc  (None, 40, 40, 384)          1536      ['block_9_depthwise[0][0]']   \n"," hNormalization)                                                                                  \n","                                                                                                  \n"," block_9_depthwise_relu (Re  (None, 40, 40, 384)          0         ['block_9_depthwise_BN[0][0]']\n"," LU)                                                                                              \n","                                                                                                  \n"," block_9_project (Conv2D)    (None, 40, 40, 64)           24576     ['block_9_depthwise_relu[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," block_9_project_BN (BatchN  (None, 40, 40, 64)           256       ['block_9_project[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_9_add (Add)           (None, 40, 40, 64)           0         ['block_8_add[0][0]',         \n","                                                                     'block_9_project_BN[0][0]']  \n","                                                                                                  \n"," block_10_expand (Conv2D)    (None, 40, 40, 384)          24576     ['block_9_add[0][0]']         \n","                                                                                                  \n"," block_10_expand_BN (BatchN  (None, 40, 40, 384)          1536      ['block_10_expand[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_10_expand_relu (ReLU  (None, 40, 40, 384)          0         ['block_10_expand_BN[0][0]']  \n"," )                                                                                                \n","                                                                                                  \n"," block_10_depthwise (Depthw  (None, 40, 40, 384)          3456      ['block_10_expand_relu[0][0]']\n"," iseConv2D)                                                                                       \n","                                                                                                  \n"," block_10_depthwise_BN (Bat  (None, 40, 40, 384)          1536      ['block_10_depthwise[0][0]']  \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," block_10_depthwise_relu (R  (None, 40, 40, 384)          0         ['block_10_depthwise_BN[0][0]'\n"," eLU)                                                               ]                             \n","                                                                                                  \n"," block_10_project (Conv2D)   (None, 40, 40, 96)           36864     ['block_10_depthwise_relu[0][0\n","                                                                    ]']                           \n","                                                                                                  \n"," block_10_project_BN (Batch  (None, 40, 40, 96)           384       ['block_10_project[0][0]']    \n"," Normalization)                                                                                   \n","                                                                                                  \n"," block_11_expand (Conv2D)    (None, 40, 40, 576)          55296     ['block_10_project_BN[0][0]'] \n","                                                                                                  \n"," block_11_expand_BN (BatchN  (None, 40, 40, 576)          2304      ['block_11_expand[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_11_expand_relu (ReLU  (None, 40, 40, 576)          0         ['block_11_expand_BN[0][0]']  \n"," )                                                                                                \n","                                                                                                  \n"," block_11_depthwise (Depthw  (None, 40, 40, 576)          5184      ['block_11_expand_relu[0][0]']\n"," iseConv2D)                                                                                       \n","                                                                                                  \n"," block_11_depthwise_BN (Bat  (None, 40, 40, 576)          2304      ['block_11_depthwise[0][0]']  \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," block_11_depthwise_relu (R  (None, 40, 40, 576)          0         ['block_11_depthwise_BN[0][0]'\n"," eLU)                                                               ]                             \n","                                                                                                  \n"," block_11_project (Conv2D)   (None, 40, 40, 96)           55296     ['block_11_depthwise_relu[0][0\n","                                                                    ]']                           \n","                                                                                                  \n"," block_11_project_BN (Batch  (None, 40, 40, 96)           384       ['block_11_project[0][0]']    \n"," Normalization)                                                                                   \n","                                                                                                  \n"," block_11_add (Add)          (None, 40, 40, 96)           0         ['block_10_project_BN[0][0]', \n","                                                                     'block_11_project_BN[0][0]'] \n","                                                                                                  \n"," block_12_expand (Conv2D)    (None, 40, 40, 576)          55296     ['block_11_add[0][0]']        \n","                                                                                                  \n"," block_12_expand_BN (BatchN  (None, 40, 40, 576)          2304      ['block_12_expand[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_12_expand_relu (ReLU  (None, 40, 40, 576)          0         ['block_12_expand_BN[0][0]']  \n"," )                                                                                                \n","                                                                                                  \n"," block_12_depthwise (Depthw  (None, 40, 40, 576)          5184      ['block_12_expand_relu[0][0]']\n"," iseConv2D)                                                                                       \n","                                                                                                  \n"," block_12_depthwise_BN (Bat  (None, 40, 40, 576)          2304      ['block_12_depthwise[0][0]']  \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," block_12_depthwise_relu (R  (None, 40, 40, 576)          0         ['block_12_depthwise_BN[0][0]'\n"," eLU)                                                               ]                             \n","                                                                                                  \n"," block_12_project (Conv2D)   (None, 40, 40, 96)           55296     ['block_12_depthwise_relu[0][0\n","                                                                    ]']                           \n","                                                                                                  \n"," block_12_project_BN (Batch  (None, 40, 40, 96)           384       ['block_12_project[0][0]']    \n"," Normalization)                                                                                   \n","                                                                                                  \n"," block_12_add (Add)          (None, 40, 40, 96)           0         ['block_11_add[0][0]',        \n","                                                                     'block_12_project_BN[0][0]'] \n","                                                                                                  \n"," block_13_expand (Conv2D)    (None, 40, 40, 576)          55296     ['block_12_add[0][0]']        \n","                                                                                                  \n"," block_13_expand_BN (BatchN  (None, 40, 40, 576)          2304      ['block_13_expand[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_13_expand_relu (ReLU  (None, 40, 40, 576)          0         ['block_13_expand_BN[0][0]']  \n"," )                                                                                                \n","                                                                                                  \n"," block_13_pad (ZeroPadding2  (None, 41, 41, 576)          0         ['block_13_expand_relu[0][0]']\n"," D)                                                                                               \n","                                                                                                  \n"," block_13_depthwise (Depthw  (None, 20, 20, 576)          5184      ['block_13_pad[0][0]']        \n"," iseConv2D)                                                                                       \n","                                                                                                  \n"," block_13_depthwise_BN (Bat  (None, 20, 20, 576)          2304      ['block_13_depthwise[0][0]']  \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," block_13_depthwise_relu (R  (None, 20, 20, 576)          0         ['block_13_depthwise_BN[0][0]'\n"," eLU)                                                               ]                             \n","                                                                                                  \n"," block_13_project (Conv2D)   (None, 20, 20, 160)          92160     ['block_13_depthwise_relu[0][0\n","                                                                    ]']                           \n","                                                                                                  \n"," block_13_project_BN (Batch  (None, 20, 20, 160)          640       ['block_13_project[0][0]']    \n"," Normalization)                                                                                   \n","                                                                                                  \n"," block_14_expand (Conv2D)    (None, 20, 20, 960)          153600    ['block_13_project_BN[0][0]'] \n","                                                                                                  \n"," block_14_expand_BN (BatchN  (None, 20, 20, 960)          3840      ['block_14_expand[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_14_expand_relu (ReLU  (None, 20, 20, 960)          0         ['block_14_expand_BN[0][0]']  \n"," )                                                                                                \n","                                                                                                  \n"," block_14_depthwise (Depthw  (None, 20, 20, 960)          8640      ['block_14_expand_relu[0][0]']\n"," iseConv2D)                                                                                       \n","                                                                                                  \n"," block_14_depthwise_BN (Bat  (None, 20, 20, 960)          3840      ['block_14_depthwise[0][0]']  \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," block_14_depthwise_relu (R  (None, 20, 20, 960)          0         ['block_14_depthwise_BN[0][0]'\n"," eLU)                                                               ]                             \n","                                                                                                  \n"," block_14_project (Conv2D)   (None, 20, 20, 160)          153600    ['block_14_depthwise_relu[0][0\n","                                                                    ]']                           \n","                                                                                                  \n"," block_14_project_BN (Batch  (None, 20, 20, 160)          640       ['block_14_project[0][0]']    \n"," Normalization)                                                                                   \n","                                                                                                  \n"," block_14_add (Add)          (None, 20, 20, 160)          0         ['block_13_project_BN[0][0]', \n","                                                                     'block_14_project_BN[0][0]'] \n","                                                                                                  \n"," block_15_expand (Conv2D)    (None, 20, 20, 960)          153600    ['block_14_add[0][0]']        \n","                                                                                                  \n"," block_15_expand_BN (BatchN  (None, 20, 20, 960)          3840      ['block_15_expand[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_15_expand_relu (ReLU  (None, 20, 20, 960)          0         ['block_15_expand_BN[0][0]']  \n"," )                                                                                                \n","                                                                                                  \n"," block_15_depthwise (Depthw  (None, 20, 20, 960)          8640      ['block_15_expand_relu[0][0]']\n"," iseConv2D)                                                                                       \n","                                                                                                  \n"," block_15_depthwise_BN (Bat  (None, 20, 20, 960)          3840      ['block_15_depthwise[0][0]']  \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," block_15_depthwise_relu (R  (None, 20, 20, 960)          0         ['block_15_depthwise_BN[0][0]'\n"," eLU)                                                               ]                             \n","                                                                                                  \n"," block_15_project (Conv2D)   (None, 20, 20, 160)          153600    ['block_15_depthwise_relu[0][0\n","                                                                    ]']                           \n","                                                                                                  \n"," block_15_project_BN (Batch  (None, 20, 20, 160)          640       ['block_15_project[0][0]']    \n"," Normalization)                                                                                   \n","                                                                                                  \n"," block_15_add (Add)          (None, 20, 20, 160)          0         ['block_14_add[0][0]',        \n","                                                                     'block_15_project_BN[0][0]'] \n","                                                                                                  \n"," block_16_expand (Conv2D)    (None, 20, 20, 960)          153600    ['block_15_add[0][0]']        \n","                                                                                                  \n"," block_16_expand_BN (BatchN  (None, 20, 20, 960)          3840      ['block_16_expand[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," block_16_expand_relu (ReLU  (None, 20, 20, 960)          0         ['block_16_expand_BN[0][0]']  \n"," )                                                                                                \n","                                                                                                  \n"," block_16_depthwise (Depthw  (None, 20, 20, 960)          8640      ['block_16_expand_relu[0][0]']\n"," iseConv2D)                                                                                       \n","                                                                                                  \n"," block_16_depthwise_BN (Bat  (None, 20, 20, 960)          3840      ['block_16_depthwise[0][0]']  \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," block_16_depthwise_relu (R  (None, 20, 20, 960)          0         ['block_16_depthwise_BN[0][0]'\n"," eLU)                                                               ]                             \n","                                                                                                  \n"," block_16_project (Conv2D)   (None, 20, 20, 320)          307200    ['block_16_depthwise_relu[0][0\n","                                                                    ]']                           \n","                                                                                                  \n"," block_16_project_BN (Batch  (None, 20, 20, 320)          1280      ['block_16_project[0][0]']    \n"," Normalization)                                                                                   \n","                                                                                                  \n"," Conv_1 (Conv2D)             (None, 20, 20, 1280)         409600    ['block_16_project_BN[0][0]'] \n","                                                                                                  \n"," Conv_1_bn (BatchNormalizat  (None, 20, 20, 1280)         5120      ['Conv_1[0][0]']              \n"," ion)                                                                                             \n","                                                                                                  \n"," out_relu (ReLU)             (None, 20, 20, 1280)         0         ['Conv_1_bn[0][0]']           \n","                                                                                                  \n"," extra1_1 (Conv2D)           (None, 20, 20, 256)          327936    ['out_relu[0][0]']            \n","                                                                                                  \n"," batch_normalization (Batch  (None, 20, 20, 256)          1024      ['extra1_1[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu (ReLU)                (None, 20, 20, 256)          0         ['batch_normalization[0][0]'] \n","                                                                                                  \n"," extra1_2 (Conv2D)           (None, 10, 10, 512)          1180160   ['re_lu[0][0]']               \n","                                                                                                  \n"," batch_normalization_1 (Bat  (None, 10, 10, 512)          2048      ['extra1_2[0][0]']            \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," re_lu_1 (ReLU)              (None, 10, 10, 512)          0         ['batch_normalization_1[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," extra2_1 (Conv2D)           (None, 10, 10, 128)          65664     ['re_lu_1[0][0]']             \n","                                                                                                  \n"," batch_normalization_2 (Bat  (None, 10, 10, 128)          512       ['extra2_1[0][0]']            \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," re_lu_2 (ReLU)              (None, 10, 10, 128)          0         ['batch_normalization_2[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," extra2_2 (Conv2D)           (None, 5, 5, 256)            295168    ['re_lu_2[0][0]']             \n","                                                                                                  \n"," batch_normalization_3 (Bat  (None, 5, 5, 256)            1024      ['extra2_2[0][0]']            \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," re_lu_3 (ReLU)              (None, 5, 5, 256)            0         ['batch_normalization_3[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," extra3_1 (Conv2D)           (None, 5, 5, 128)            32896     ['re_lu_3[0][0]']             \n","                                                                                                  \n"," batch_normalization_4 (Bat  (None, 5, 5, 128)            512       ['extra3_1[0][0]']            \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," re_lu_4 (ReLU)              (None, 5, 5, 128)            0         ['batch_normalization_4[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," extra3_2 (Conv2D)           (None, 3, 3, 256)            295168    ['re_lu_4[0][0]']             \n","                                                                                                  \n"," up_sampling2d_2 (UpSamplin  (None, 80, 80, 576)          0         ['block_13_expand_relu[0][0]']\n"," g2D)                                                                                             \n","                                                                                                  \n"," batch_normalization_5 (Bat  (None, 3, 3, 256)            1024      ['extra3_2[0][0]']            \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," concatenate_1 (Concatenate  (None, 80, 80, 768)          0         ['block_6_expand_relu[0][0]', \n"," )                                                                   'up_sampling2d_2[0][0]']     \n","                                                                                                  \n"," re_lu_5 (ReLU)              (None, 3, 3, 256)            0         ['batch_normalization_5[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," 1_conv_label_output (Conv2  (None, 80, 80, 30)           207390    ['concatenate_1[0][0]']       \n"," D)                                                                                               \n","                                                                                                  \n"," 2_conv_label_output (Conv2  (None, 40, 40, 30)           155550    ['block_13_expand_relu[0][0]']\n"," D)                                                                                               \n","                                                                                                  \n"," 3_conv_label_output (Conv2  (None, 20, 20, 30)           345630    ['out_relu[0][0]']            \n"," D)                                                                                               \n","                                                                                                  \n"," 4_conv_label_output (Conv2  (None, 10, 10, 30)           138270    ['re_lu_1[0][0]']             \n"," D)                                                                                               \n","                                                                                                  \n"," 5_conv_label_output (Conv2  (None, 5, 5, 30)             69150     ['re_lu_3[0][0]']             \n"," D)                                                                                               \n","                                                                                                  \n"," 6_conv_label_output (Conv2  (None, 3, 3, 30)             69150     ['re_lu_5[0][0]']             \n"," D)                                                                                               \n","                                                                                                  \n"," 1_conv_boxes_output (Conv2  (None, 80, 80, 24)           165912    ['concatenate_1[0][0]']       \n"," D)                                                                                               \n","                                                                                                  \n"," 2_conv_boxes_output (Conv2  (None, 40, 40, 24)           124440    ['block_13_expand_relu[0][0]']\n"," D)                                                                                               \n","                                                                                                  \n"," 3_conv_boxes_output (Conv2  (None, 20, 20, 24)           276504    ['out_relu[0][0]']            \n"," D)                                                                                               \n","                                                                                                  \n"," 4_conv_boxes_output (Conv2  (None, 10, 10, 24)           110616    ['re_lu_1[0][0]']             \n"," D)                                                                                               \n","                                                                                                  \n"," 5_conv_boxes_output (Conv2  (None, 5, 5, 24)             55320     ['re_lu_3[0][0]']             \n"," D)                                                                                               \n","                                                                                                  \n"," 6_conv_boxes_output (Conv2  (None, 3, 3, 24)             55320     ['re_lu_5[0][0]']             \n"," D)                                                                                               \n","                                                                                                  \n"," labels_head (HeadWrapper)   (None, None, 5)              0         ['1_conv_label_output[0][0]', \n","                                                                     '2_conv_label_output[0][0]', \n","                                                                     '3_conv_label_output[0][0]', \n","                                                                     '4_conv_label_output[0][0]', \n","                                                                     '5_conv_label_output[0][0]', \n","                                                                     '6_conv_label_output[0][0]'] \n","                                                                                                  \n"," loc (HeadWrapper)           (None, None, 4)              0         ['1_conv_boxes_output[0][0]', \n","                                                                     '2_conv_boxes_output[0][0]', \n","                                                                     '3_conv_boxes_output[0][0]', \n","                                                                     '4_conv_boxes_output[0][0]', \n","                                                                     '5_conv_boxes_output[0][0]', \n","                                                                     '6_conv_boxes_output[0][0]'] \n","                                                                                                  \n"," conf (Activation)           (None, None, 5)              0         ['labels_head[0][0]']         \n","                                                                                                  \n","==================================================================================================\n","Total params: 6234372 (23.78 MB)\n","Trainable params: 6197188 (23.64 MB)\n","Non-trainable params: 37184 (145.25 KB)\n","__________________________________________________________________________________________________\n"]}],"source":["ssd_model.summary()"]},{"cell_type":"markdown","metadata":{"id":"nVPhU6-xkSF5"},"source":["# Tensorboard"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"executionInfo":{"elapsed":10,"status":"error","timestamp":1708189638728,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"i4HPimys1Wfv","outputId":"677288ff-4a57-444e-fc4d-1a747a4e2f47"},"outputs":[{"ename":"NameError","evalue":"name 'history' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-35b870f19037>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"]},{"data":{"text/plain":["<Figure size 640x480 with 0 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.figure(1)\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'valid'], loc='upper left')\n","\n","plt.figure(2)\n","plt.plot(history.history['loc_loss'])\n","plt.plot(history.history['val_loc_loss'])\n","plt.title('model loss')\n","plt.ylabel('loc loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'valid'], loc='upper left')\n","\n","plt.figure(3)\n","plt.plot(history.history['conf_loss'])\n","plt.plot(history.history['val_conf_loss'])\n","plt.title('model loss')\n","plt.ylabel('conf loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'valid'], loc='upper left')"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":489},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1708189639092,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"-YoXADJikWs6","outputId":"cb153f99-793c-447d-b0a2-aeb181c651d4"},"outputs":[{"data":{"text/plain":["Text(0.5, 0, 'epoch')"]},"execution_count":41,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["mAP_values = mAP_callback.get_mAP_values()\n","plt.plot(mAP_values)\n","plt.title('mAP')\n","plt.xlabel('epoch')"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1708189639457,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"KDTcajkTw4DG","outputId":"99ed968c-c152-4f6f-d7ef-689b293d9b3a"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/logs/mobilenet_v2/20240217-152235\n"]}],"source":["import glob\n","\n","logs = os.listdir(f\"/content/drive/MyDrive/logs/{backbone}/\")\n","logs.sort()\n","log_path = f\"/content/drive/MyDrive/logs/{backbone}/{logs[-1]}\"\n","print(log_path)"]},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1708189648892,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"hk0iUI8PreZR"},"outputs":[],"source":["# # %load_ext tensorboard\n","# %reload_ext tensorboard\n","# %tensorboard --logdir \"/content/logs/mobilenet_v2/20240129-090642\""]},{"cell_type":"markdown","metadata":{"id":"yNKy8TbeM4AA"},"source":["# predictor (test mAP + FPS)"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1708189649458,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"h9sYYPOeNoy0","outputId":"83614ada-ddf5-4b18-911c-fe2743c93206"},"outputs":[{"name":"stdout","output_type":"stream","text":["116\n"]}],"source":["evaluate = True\n","use_custom_images = False\n","custom_image_path = \"data/images/\"\n","\n","test_data, total_items = tfr_dataset(test_files)\n","print(total_items)\n","\n","data_types = get_data_types()\n","data_shapes = get_data_shapes()\n","padding_values = get_padding_values()\n","\n","if use_custom_images:\n","    img_paths = get_custom_imgs(custom_image_path)\n","    total_items = len(img_paths)\n","    test_data = tf.data.Dataset.from_generator(lambda: custom_data_generator(\n","                                               img_paths, img_size, img_size), data_types, data_shapes)\n","else:\n","    test_data = test_data.map(lambda x : tfr_preprocessing(x, img_size, img_size))\n","\n","test_data = test_data.padded_batch(batch_size, padded_shapes=data_shapes, padding_values=padding_values)"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":515},"executionInfo":{"elapsed":1702,"status":"error","timestamp":1708189652945,"user":{"displayName":"happy duck","userId":"12590459388487510630"},"user_tz":-480},"id":"LGcBVI4Gn_Mz","outputId":"f769d652-2698-42f9-d762-8a312654748d"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"]},{"ename":"FileNotFoundError","evalue":"[Errno 2] Unable to open file (unable to open file: name = '/content/drive/MyDrive/trained/ssd_mobilenet_v2_model_weights.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-45-e79e28159ae4>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mssd_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyper_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mssd_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mssd_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mssd_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mssd_decoder_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_decoder_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mssd_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyper_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    565\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 567\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = '/content/drive/MyDrive/trained/ssd_mobilenet_v2_model_weights.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"]}],"source":["import time\n","\n","ssd_model = get_model(hyper_params)\n","ssd_model_path = get_model_path(backbone)\n","ssd_model.load_weights(ssd_model_path)\n","ssd_decoder_model = get_decoder_model(ssd_model, prior_boxes, hyper_params)\n","\n","step_size = get_step_size(total_items, batch_size)\n","\n","start_time = time.time()\n","pred_bboxes, pred_labels, pred_scores = ssd_decoder_model.predict(test_data, steps=step_size, verbose=1)\n","end_time = time.time()\n","total_time_taken = end_time - start_time\n","\n","# Calculate Frames Per Second (FPS)\n","fps = total_items / total_time_taken\n","\n","# Print the results\n","print(f\"Total time taken: {total_time_taken} seconds\")\n","print(f\"Frames Per Second (FPS): {fps}\")\n","\n","if evaluate:\n","    stats, mAP = evaluate_predictions(test_data, pred_bboxes, pred_labels, pred_scores, labels, batch_size)\n","else:\n","    draw_predictions(test_data, pred_bboxes, pred_labels, pred_scores, labels, batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nn03Kvkm3UlW"},"outputs":[],"source":["for i in stats:\n","    print(stats[i]['label'])\n","    print('Total:', stats[i]['total'])\n","    print('Total Predictions', len(stats[i]['tp']))\n","    print('Correct Predictions:', stats[i]['tp'].count(1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eAcOo-yBBG9L"},"outputs":[],"source":["stats"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"itzp-sJcSswM"},"outputs":[],"source":["# draw_predictions(test_data, pred_bboxes, pred_labels, pred_scores, labels, batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fWtZLX68Zx4-"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["TTVGVeV8BG8P"],"gpuType":"T4","name":"","provenance":[{"file_id":"1uQDSXIZHIiX-EknvI5cI09jEVrhhRpHo","timestamp":1708061567564},{"file_id":"1EjObPAbR41QnPNy_eFhmeWQVSiQSgiJ3","timestamp":1708006496588}],"toc_visible":true,"version":""},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
