{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64cb28cf",
   "metadata": {
    "id": "y1von-1uFPIV",
    "papermill": {
     "duration": 0.015077,
     "end_time": "2024-03-08T08:22:20.474582",
     "exception": false,
     "start_time": "2024-03-08T08:22:20.459505",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Fusion via Concatenation / Elemental Sum\n",
    "\n",
    "Github repo:\n",
    "https://github.com/FurkanOM/tf-ssd/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d0bc405",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:22:20.505475Z",
     "iopub.status.busy": "2024-03-08T08:22:20.505121Z",
     "iopub.status.idle": "2024-03-08T08:22:35.448195Z",
     "shell.execute_reply": "2024-03-08T08:22:35.447348Z"
    },
    "papermill": {
     "duration": 14.961065,
     "end_time": "2024-03-08T08:22:35.450459",
     "exception": false,
     "start_time": "2024-03-08T08:22:20.489394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-08 08:22:22.243858: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-08 08:22:22.243958: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-08 08:22:22.381824: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pathlib\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9583b4",
   "metadata": {
    "papermill": {
     "duration": 0.014657,
     "end_time": "2024-03-08T08:22:35.480987",
     "exception": false,
     "start_time": "2024-03-08T08:22:35.466330",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# anchor_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "454eb7a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:22:35.513986Z",
     "iopub.status.busy": "2024-03-08T08:22:35.513002Z",
     "iopub.status.idle": "2024-03-08T08:22:35.530453Z",
     "shell.execute_reply": "2024-03-08T08:22:35.529639Z"
    },
    "id": "D9N9T9kpDwjD",
    "papermill": {
     "duration": 0.03647,
     "end_time": "2024-03-08T08:22:35.532420",
     "exception": false,
     "start_time": "2024-03-08T08:22:35.495950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Generate Anchor Boxes.\n",
    "\"\"\"\n",
    "\n",
    "def get_scale_for_nth_feature_map(k, m=6, scale_min=0.2, scale_max=0.9):\n",
    "    \"\"\"Calculating scale value for nth feature map using the given method in the paper.\n",
    "    inputs:\n",
    "        k = nth feature map for scale calculation\n",
    "        m = length of all using feature maps for detections, 6 for ssd300\n",
    "\n",
    "    outputs:\n",
    "        scale = calculated scale value for given index\n",
    "    \"\"\"\n",
    "    # [0.2, 0.34, 0.48, 0.62, 0.76, 0.9, 1.04]\n",
    "    return scale_min + ((scale_max - scale_min) / (m - 1)) * (k - 1)\n",
    "\n",
    "def generate_base_prior_boxes(aspect_ratios, feature_map_index, total_feature_map, hyper_params):\n",
    "    \"\"\"Generating top left prior boxes for given stride, height and width pairs of different aspect ratios.\n",
    "    These prior boxes same with the anchors in Faster-RCNN.\n",
    "    inputs:\n",
    "        aspect_ratios = for all feature map shapes + 1 for ratio 1\n",
    "        feature_map_index = nth feature maps for scale calculation\n",
    "        total_feature_map = length of all using feature map for detections, 6 for ssd300\n",
    "\n",
    "    outputs:\n",
    "        base_prior_boxes = (prior_box_count, [y1, x1, y2, x2])\n",
    "    \"\"\"\n",
    "    # print(feature_map_index)\n",
    "    if hyper_params[\"use_custom_scale\"]:    \n",
    "        current_scale = hyper_params[\"scale\"][feature_map_index-1]\n",
    "        next_scale = hyper_params[\"scale\"][feature_map_index]\n",
    "    else:\n",
    "        current_scale = get_scale_for_nth_feature_map(feature_map_index, m=total_feature_map, \n",
    "                                                      scale_min=hyper_params[\"scale_min\"], scale_max=hyper_params[\"scale_max\"])\n",
    "        next_scale = get_scale_for_nth_feature_map(feature_map_index + 1, m=total_feature_map, \n",
    "                                                   scale_min=hyper_params[\"scale_min\"], scale_max=hyper_params[\"scale_max\"])\n",
    "    print(current_scale, next_scale)\n",
    "    base_prior_boxes = []\n",
    "    for aspect_ratio in aspect_ratios:\n",
    "        height = current_scale / tf.sqrt(aspect_ratio)\n",
    "        width = current_scale * tf.sqrt(aspect_ratio)\n",
    "        base_prior_boxes.append([-height/2, -width/2, height/2, width/2])\n",
    "#         print(height, width)\n",
    "    # 1 extra pair for ratio 1\n",
    "    height = width = tf.sqrt(current_scale * next_scale)\n",
    "#     print(height, width)\n",
    "    base_prior_boxes.append([-height/2, -width/2, height/2, width/2])\n",
    "    return tf.cast(base_prior_boxes, dtype=tf.float32)\n",
    "\n",
    "def generate_prior_boxes(feature_map_shapes, aspect_ratios, hyper_params):\n",
    "    \"\"\"Generating top left prior boxes for given stride, height and width pairs of different aspect ratios.\n",
    "    These prior boxes same with the anchors in Faster-RCNN.\n",
    "    Aspect ratio is the width to height ratio.\n",
    "    inputs:\n",
    "        feature_map_shapes = for all feature map output size\n",
    "        aspect_ratios = for all feature map shapes + 1 for ratio 1\n",
    "\n",
    "    outputs:\n",
    "        prior_boxes = (total_prior_boxes, [y1, x1, y2, x2])\n",
    "            these values in normalized format between [0, 1]\n",
    "    \"\"\"\n",
    "    prior_boxes = []\n",
    "    for i, feature_map_shape in enumerate(feature_map_shapes):\n",
    "        print(feature_map_shape)\n",
    "        base_prior_boxes = generate_base_prior_boxes(aspect_ratios[i], i+1, len(feature_map_shapes), hyper_params)\n",
    "        print(base_prior_boxes)\n",
    "\n",
    "        stride = 1 / feature_map_shape\n",
    "        # Create linearly spaced arrays of x and y coordinates\n",
    "        grid_coords = tf.cast(tf.range(0, feature_map_shape) / feature_map_shape + stride / 2, dtype=tf.float32)\n",
    "        grid_x, grid_y = tf.meshgrid(grid_coords, grid_coords)\n",
    "        flat_grid_x, flat_grid_y = tf.reshape(grid_x, (-1, )), tf.reshape(grid_y, (-1, ))\n",
    "\n",
    "        grid_map = tf.stack([flat_grid_y, flat_grid_x, flat_grid_y, flat_grid_x], -1)\n",
    "\n",
    "        prior_boxes_for_feature_map = tf.reshape(base_prior_boxes, (1, -1, 4)) + tf.reshape(grid_map, (-1, 1, 4))\n",
    "        prior_boxes_for_feature_map = tf.reshape(prior_boxes_for_feature_map, (-1, 4))\n",
    "        prior_boxes.append(prior_boxes_for_feature_map)\n",
    "        \n",
    "    prior_boxes = tf.concat(prior_boxes, axis=0)\n",
    "    # print(prior_boxes)\n",
    "    return tf.clip_by_value(prior_boxes, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adccd26e",
   "metadata": {
    "id": "Stm5EzBc79ca",
    "papermill": {
     "duration": 0.014669,
     "end_time": "2024-03-08T08:22:35.561996",
     "exception": false,
     "start_time": "2024-03-08T08:22:35.547327",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dbaa246",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:22:35.594665Z",
     "iopub.status.busy": "2024-03-08T08:22:35.594209Z",
     "iopub.status.idle": "2024-03-08T08:22:35.598791Z",
     "shell.execute_reply": "2024-03-08T08:22:35.597624Z"
    },
    "papermill": {
     "duration": 0.024322,
     "end_time": "2024-03-08T08:22:35.601247",
     "exception": false,
     "start_time": "2024-03-08T08:22:35.576925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "backbone = \"mobilenet_v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6f8b0fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:22:35.634333Z",
     "iopub.status.busy": "2024-03-08T08:22:35.633993Z",
     "iopub.status.idle": "2024-03-08T08:22:37.852805Z",
     "shell.execute_reply": "2024-03-08T08:22:37.851629Z"
    },
    "id": "AE1YUdJu7_HW",
    "papermill": {
     "duration": 2.237994,
     "end_time": "2024-03-08T08:22:37.854987",
     "exception": false,
     "start_time": "2024-03-08T08:22:35.616993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img_size': 640,\n",
       " 'feature_map_shapes': [80, 40, 20, 10, 5, 3],\n",
       " 'aspect_ratios': [[1.0, 2.0, 0.5, 5.0, 0.2],\n",
       "  [1.0, 2.0, 0.5, 5.0, 0.2],\n",
       "  [1.0, 2.0, 0.5, 5.0, 0.2],\n",
       "  [1.0, 2.0, 0.5, 5.0, 0.2],\n",
       "  [1.0, 2.0, 0.5, 5.0, 0.2],\n",
       "  [1.0, 2.0, 0.5, 5.0, 0.2]],\n",
       " 'use_custom_scale': False,\n",
       " 'scale_min': 0.05,\n",
       " 'scale_max': 0.5,\n",
       " 'scale': [0.05, 0.1, 0.2, 0.4, 0.6, 0.8, 1.2],\n",
       " 'trainable': True,\n",
       " 'num_trainable': None,\n",
       " 'detection': None,\n",
       " 'feature_fusion': 'concat',\n",
       " 'dataset': 0,\n",
       " 'iou_threshold': 0.5,\n",
       " 'neg_pos_ratio': 3,\n",
       " 'loc_loss_alpha': 1,\n",
       " 'variances': [0.1, 0.1, 0.2, 0.2],\n",
       " 'use_focal': False,\n",
       " 'alpha': 2.0,\n",
       " 'gamma': 0.25,\n",
       " 'batch_size': 8,\n",
       " 'epochs': 200,\n",
       " 'lr': 1e-05,\n",
       " 'patience': 20}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "0.05 0.14\n",
      "tf.Tensor(\n",
      "[[-0.025      -0.025       0.025       0.025     ]\n",
      " [-0.01767767 -0.03535534  0.01767767  0.03535534]\n",
      " [-0.03535534 -0.01767767  0.03535534  0.01767767]\n",
      " [-0.01118034 -0.0559017   0.01118034  0.0559017 ]\n",
      " [-0.0559017  -0.01118034  0.0559017   0.01118034]\n",
      " [-0.041833   -0.041833    0.041833    0.041833  ]], shape=(6, 4), dtype=float32)\n",
      "40\n",
      "0.14 0.22999999999999998\n",
      "tf.Tensor(\n",
      "[[-0.07       -0.07        0.07        0.07      ]\n",
      " [-0.04949747 -0.09899495  0.04949747  0.09899495]\n",
      " [-0.09899495 -0.04949747  0.09899495  0.04949747]\n",
      " [-0.03130496 -0.15652475  0.03130496  0.15652475]\n",
      " [-0.15652476 -0.03130495  0.15652476  0.03130495]\n",
      " [-0.0897218  -0.0897218   0.0897218   0.0897218 ]], shape=(6, 4), dtype=float32)\n",
      "20\n",
      "0.22999999999999998 0.32\n",
      "tf.Tensor(\n",
      "[[-0.115      -0.115       0.115       0.115     ]\n",
      " [-0.08131728 -0.16263457  0.08131728  0.16263457]\n",
      " [-0.16263457 -0.08131728  0.16263457  0.08131728]\n",
      " [-0.05142957 -0.2571478   0.05142957  0.2571478 ]\n",
      " [-0.25714782 -0.05142956  0.25714782  0.05142956]\n",
      " [-0.1356466  -0.1356466   0.1356466   0.1356466 ]], shape=(6, 4), dtype=float32)\n",
      "10\n",
      "0.32 0.41\n",
      "tf.Tensor(\n",
      "[[-0.16       -0.16        0.16        0.16      ]\n",
      " [-0.11313708 -0.22627416  0.11313708  0.22627416]\n",
      " [-0.22627416 -0.11313708  0.22627416  0.11313708]\n",
      " [-0.07155418 -0.35777083  0.07155418  0.35777083]\n",
      " [-0.35777086 -0.07155418  0.35777086  0.07155418]\n",
      " [-0.1811077  -0.1811077   0.1811077   0.1811077 ]], shape=(6, 4), dtype=float32)\n",
      "5\n",
      "0.41 0.49999999999999994\n",
      "tf.Tensor(\n",
      "[[-0.205      -0.205       0.205       0.205     ]\n",
      " [-0.14495689 -0.28991377  0.14495689  0.28991377]\n",
      " [-0.28991377 -0.14495689  0.28991377  0.14495689]\n",
      " [-0.0916788  -0.4583939   0.0916788   0.4583939 ]\n",
      " [-0.45839393 -0.09167878  0.45839393  0.09167878]\n",
      " [-0.22638462 -0.22638462  0.22638462  0.22638462]], shape=(6, 4), dtype=float32)\n",
      "3\n",
      "0.49999999999999994 0.5900000000000001\n",
      "tf.Tensor(\n",
      "[[-0.25       -0.25        0.25        0.25      ]\n",
      " [-0.17677669 -0.35355338  0.17677669  0.35355338]\n",
      " [-0.35355338 -0.17677669  0.35355338  0.17677669]\n",
      " [-0.11180341 -0.55901694  0.11180341  0.55901694]\n",
      " [-0.559017   -0.1118034   0.559017    0.1118034 ]\n",
      " [-0.2715695  -0.2715695   0.2715695   0.2715695 ]], shape=(6, 4), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(51204, 4), dtype=float32, numpy=\n",
       "array([[0.        , 0.        , 0.03125   , 0.03125   ],\n",
       "       [0.        , 0.        , 0.02392767, 0.04160534],\n",
       "       [0.        , 0.        , 0.04160534, 0.02392767],\n",
       "       ...,\n",
       "       [0.7215299 , 0.27431637, 0.9451367 , 1.        ],\n",
       "       [0.2743163 , 0.7215299 , 1.        , 0.9451367 ],\n",
       "       [0.5617638 , 0.5617638 , 1.        , 1.        ]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SSD = {\n",
    "#     \"mobilenet_v2\": {\n",
    "#         \"img_size\": 1024,\n",
    "#         \"feature_map_shapes\": [128,64,32,16,8,4],\n",
    "#         \"aspect_ratios\": [[1., 2., 1./2., 5., 1./5.],\n",
    "#                           [1., 2., 1./2., 5., 1./5.],\n",
    "#                           [1., 2., 1./2., 5., 1./5.],\n",
    "#                           [1., 2., 1./2., 5., 1./5.],\n",
    "#                           [1., 2., 1./2., 5., 1./5.],\n",
    "#                           [1., 2., 1./2., 5., 1./5.]],\n",
    "#         \"use_custom_scale\": False,\n",
    "#         \"scale_min\": 0.05,\n",
    "#         \"scale_max\": 0.5,\n",
    "#         \"scale\": [0.05, 0.1, 0.2, 0.4, 0.6, 0.8, 1.2],\n",
    "#         \"trainable\": True,\n",
    "#         \"num_trainable\": None\n",
    "#     },\n",
    "    \"mobilenet_v2\": {\n",
    "        \"img_size\": 640,\n",
    "        \"feature_map_shapes\": [80, 40, 20, 10, 5, 3],\n",
    "        \"aspect_ratios\": [[1., 2., 1./2., 5., 1./5.],\n",
    "                          [1., 2., 1./2., 5., 1./5.],\n",
    "                          [1., 2., 1./2., 5., 1./5.],\n",
    "                          [1., 2., 1./2., 5., 1./5.],\n",
    "                          [1., 2., 1./2., 5., 1./5.],\n",
    "                          [1., 2., 1./2., 5., 1./5.]],\n",
    "        \"use_custom_scale\": False,\n",
    "        \"scale_min\": 0.05,\n",
    "        \"scale_max\": 0.5,\n",
    "        \"scale\": [0.05, 0.1, 0.2, 0.4, 0.6, 0.8, 1.2],\n",
    "        \"trainable\": True,\n",
    "        \"num_trainable\": None\n",
    "    },\n",
    "    # original\n",
    "    # \"mobilenet_v2\": {\n",
    "    #     \"img_size\": 300,\n",
    "    #     \"feature_map_shapes\": [38, 19, 10, 5, 3, 2, 1],\n",
    "    #     \"aspect_ratios\": [[1., 2., 1./2.],\n",
    "    #                       [1., 2., 1./2.],\n",
    "    #                      [1., 2., 1./2., 3., 1./3.],\n",
    "    #                      [1., 2., 1./2., 3., 1./3.],\n",
    "    #                      [1., 2., 1./2., 3., 1./3.],\n",
    "    #                      [1., 2., 1./2.],\n",
    "    #                      [1., 2., 1./2.]],\n",
    "    # },\n",
    "}\n",
    "\n",
    "def get_hyper_params(backbone, **kwargs):\n",
    "    \"\"\"Generating hyper params in a dynamic way.\n",
    "    inputs:\n",
    "        **kwargs = any value could be updated in the hyper_params\n",
    "\n",
    "    outputs:\n",
    "        hyper_params = dictionary\n",
    "    \"\"\"\n",
    "    hyper_params = SSD[backbone]\n",
    "    hyper_params[\"detection\"] = None # None / \"FPN\" / \"BiFPN\" / \"PAFPN\" / \"NASFPN\"\n",
    "    hyper_params[\"feature_fusion\"] = \"concat\" # None / \"concat\" / \"elesum\"\n",
    "    hyper_params[\"dataset\"] = 0 # dut, tilda, daffodil, thesis, combined\n",
    "    hyper_params[\"iou_threshold\"] = 0.5\n",
    "    hyper_params[\"neg_pos_ratio\"] = 3 # neg:pos 3:1 ratio\n",
    "    hyper_params[\"loc_loss_alpha\"] = 1 # weight for the localization loss\n",
    "    hyper_params[\"variances\"] = [0.1, 0.1, 0.2, 0.2]\n",
    "    hyper_params[\"use_focal\"] = False\n",
    "    hyper_params[\"alpha\"] = 2.0\n",
    "    hyper_params[\"gamma\"] = 0.25\n",
    "    hyper_params[\"batch_size\"] = 8\n",
    "    hyper_params[\"epochs\"] = 200\n",
    "    hyper_params[\"lr\"] = 1e-5\n",
    "    hyper_params[\"patience\"] = 20\n",
    "    # overwrite any parameters\n",
    "    for key, value in kwargs.items():\n",
    "        if key in hyper_params and value:\n",
    "            hyper_params[key] = value\n",
    "\n",
    "    return hyper_params\n",
    "\n",
    "hyper_params = get_hyper_params(backbone)\n",
    "display(hyper_params)\n",
    "\n",
    "# We calculate prior boxes for one time and use it for all operations because of the all images are the same sizes\n",
    "prior_boxes = generate_prior_boxes(hyper_params[\"feature_map_shapes\"], hyper_params[\"aspect_ratios\"], hyper_params)\n",
    "display(prior_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec3eb833",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:22:37.888450Z",
     "iopub.status.busy": "2024-03-08T08:22:37.887588Z",
     "iopub.status.idle": "2024-03-08T08:22:37.892185Z",
     "shell.execute_reply": "2024-03-08T08:22:37.891289Z"
    },
    "papermill": {
     "duration": 0.023158,
     "end_time": "2024-03-08T08:22:37.894135",
     "exception": false,
     "start_time": "2024-03-08T08:22:37.870977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sanity Check \n",
    "assert isinstance(hyper_params[\"dataset\"], int) and -1 < hyper_params[\"dataset\"] < 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c5f2234",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:22:37.928140Z",
     "iopub.status.busy": "2024-03-08T08:22:37.927755Z",
     "iopub.status.idle": "2024-03-08T08:22:37.989933Z",
     "shell.execute_reply": "2024-03-08T08:22:37.988871Z"
    },
    "papermill": {
     "duration": 0.081911,
     "end_time": "2024-03-08T08:22:37.992364",
     "exception": false,
     "start_time": "2024-03-08T08:22:37.910453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "0.05 0.14\n",
      "tf.Tensor(\n",
      "[[-0.025      -0.025       0.025       0.025     ]\n",
      " [-0.01767767 -0.03535534  0.01767767  0.03535534]\n",
      " [-0.03535534 -0.01767767  0.03535534  0.01767767]\n",
      " [-0.01118034 -0.0559017   0.01118034  0.0559017 ]\n",
      " [-0.0559017  -0.01118034  0.0559017   0.01118034]\n",
      " [-0.041833   -0.041833    0.041833    0.041833  ]], shape=(6, 4), dtype=float32)\n",
      "40\n",
      "0.14 0.22999999999999998\n",
      "tf.Tensor(\n",
      "[[-0.07       -0.07        0.07        0.07      ]\n",
      " [-0.04949747 -0.09899495  0.04949747  0.09899495]\n",
      " [-0.09899495 -0.04949747  0.09899495  0.04949747]\n",
      " [-0.03130496 -0.15652475  0.03130496  0.15652475]\n",
      " [-0.15652476 -0.03130495  0.15652476  0.03130495]\n",
      " [-0.0897218  -0.0897218   0.0897218   0.0897218 ]], shape=(6, 4), dtype=float32)\n",
      "20\n",
      "0.22999999999999998 0.32\n",
      "tf.Tensor(\n",
      "[[-0.115      -0.115       0.115       0.115     ]\n",
      " [-0.08131728 -0.16263457  0.08131728  0.16263457]\n",
      " [-0.16263457 -0.08131728  0.16263457  0.08131728]\n",
      " [-0.05142957 -0.2571478   0.05142957  0.2571478 ]\n",
      " [-0.25714782 -0.05142956  0.25714782  0.05142956]\n",
      " [-0.1356466  -0.1356466   0.1356466   0.1356466 ]], shape=(6, 4), dtype=float32)\n",
      "10\n",
      "0.32 0.41\n",
      "tf.Tensor(\n",
      "[[-0.16       -0.16        0.16        0.16      ]\n",
      " [-0.11313708 -0.22627416  0.11313708  0.22627416]\n",
      " [-0.22627416 -0.11313708  0.22627416  0.11313708]\n",
      " [-0.07155418 -0.35777083  0.07155418  0.35777083]\n",
      " [-0.35777086 -0.07155418  0.35777086  0.07155418]\n",
      " [-0.1811077  -0.1811077   0.1811077   0.1811077 ]], shape=(6, 4), dtype=float32)\n",
      "5\n",
      "0.41 0.49999999999999994\n",
      "tf.Tensor(\n",
      "[[-0.205      -0.205       0.205       0.205     ]\n",
      " [-0.14495689 -0.28991377  0.14495689  0.28991377]\n",
      " [-0.28991377 -0.14495689  0.28991377  0.14495689]\n",
      " [-0.0916788  -0.4583939   0.0916788   0.4583939 ]\n",
      " [-0.45839393 -0.09167878  0.45839393  0.09167878]\n",
      " [-0.22638462 -0.22638462  0.22638462  0.22638462]], shape=(6, 4), dtype=float32)\n",
      "3\n",
      "0.49999999999999994 0.5900000000000001\n",
      "tf.Tensor(\n",
      "[[-0.25       -0.25        0.25        0.25      ]\n",
      " [-0.17677669 -0.35355338  0.17677669  0.35355338]\n",
      " [-0.35355338 -0.17677669  0.35355338  0.17677669]\n",
      " [-0.11180341 -0.55901694  0.11180341  0.55901694]\n",
      " [-0.559017   -0.1118034   0.559017    0.1118034 ]\n",
      " [-0.2715695  -0.2715695   0.2715695   0.2715695 ]], shape=(6, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# We calculate prior boxes for one time and use it for all operations because of the all images are the same sizes\n",
    "prior_boxes = generate_prior_boxes(hyper_params[\"feature_map_shapes\"], hyper_params[\"aspect_ratios\"], hyper_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9443d066",
   "metadata": {
    "id": "nmkV2S7HGtZ8",
    "papermill": {
     "duration": 0.015599,
     "end_time": "2024-03-08T08:22:38.024995",
     "exception": false,
     "start_time": "2024-03-08T08:22:38.009396",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MobileNetV2 SSD\n",
    "\n",
    "Specified backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "171e8ce0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:22:38.057892Z",
     "iopub.status.busy": "2024-03-08T08:22:38.057174Z",
     "iopub.status.idle": "2024-03-08T08:22:38.061502Z",
     "shell.execute_reply": "2024-03-08T08:22:38.060491Z"
    },
    "id": "oy32ZRGbcVlA",
    "outputId": "c9089fdf-a636-430f-fe45-fc6a6e57728c",
    "papermill": {
     "duration": 0.023102,
     "end_time": "2024-03-08T08:22:38.063625",
     "exception": false,
     "start_time": "2024-03-08T08:22:38.040523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "# base_model = MobileNetV2(include_top=False, input_shape=(1024, 1024, 3))\n",
    "# base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0abff703",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:22:38.096987Z",
     "iopub.status.busy": "2024-03-08T08:22:38.096277Z",
     "iopub.status.idle": "2024-03-08T08:22:38.103802Z",
     "shell.execute_reply": "2024-03-08T08:22:38.102858Z"
    },
    "id": "qLVgx-fklhgd",
    "papermill": {
     "duration": 0.026341,
     "end_time": "2024-03-08T08:22:38.105780",
     "exception": false,
     "start_time": "2024-03-08T08:22:38.079439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conv_layer(filter, kernel_size,\n",
    "               layer, strides=1,\n",
    "               padding='same',\n",
    "               activation='linear',\n",
    "               name='conv2d',pool=False,\n",
    "               poolsize=2,poolstride=2,conv=True):\n",
    "    if conv == True:\n",
    "        layer = tf.keras.layers.Conv2D(filters=filter,\n",
    "                                    kernel_size=kernel_size,\n",
    "                                    strides=strides,\n",
    "                                    activation=activation,\n",
    "                                    padding=padding,\n",
    "                                    name=name,\n",
    "                                    kernel_initializer='he_normal')(layer)\n",
    "        layer = tf.keras.layers.BatchNormalization()(layer)\n",
    "        layer = tf.keras.layers.ReLU()(layer)\n",
    "    elif pool == True:\n",
    "        layer=tf.keras.layers.MaxPool2D(pool_size=(poolsize, poolsize),\n",
    "                                        strides=poolstride, padding='same')(layer)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11508bd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:22:38.139751Z",
     "iopub.status.busy": "2024-03-08T08:22:38.139387Z",
     "iopub.status.idle": "2024-03-08T08:22:38.268360Z",
     "shell.execute_reply": "2024-03-08T08:22:38.267530Z"
    },
    "id": "yApDXEFhKhJb",
    "papermill": {
     "duration": 0.149037,
     "end_time": "2024-03-08T08:22:38.270903",
     "exception": false,
     "start_time": "2024-03-08T08:22:38.121866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D, Concatenate, BatchNormalization, ReLU, Add\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def get_model(hyper_params):\n",
    "    \"\"\"Generating ssd model for hyper params.\n",
    "    inputs:\n",
    "        hyper_params = dictionary\n",
    "\n",
    "    outputs:\n",
    "        ssd_model = tf.keras.model\n",
    "    \"\"\"\n",
    "    img_size = hyper_params[\"img_size\"]\n",
    "    num_classes = hyper_params[\"total_labels\"]\n",
    "    base_model = MobileNetV2(include_top=False, input_shape=(img_size, img_size, 3))\n",
    "    \n",
    "    if hyper_params[\"trainable\"]:\n",
    "        base_model.trainable = True\n",
    "        if hyper_params[\"num_trainable\"] != None:\n",
    "            for layer in base_model.layers[:-hyper_params[\"num_trainable\"]]:\n",
    "                layer.trainable = False\n",
    "    else: base_model.trainable = False\n",
    "\n",
    "    input = base_model.input\n",
    "\n",
    "    zero_conv = base_model.get_layer(\"block_6_expand_relu\").output # \n",
    "    first_conv = base_model.get_layer(\"block_13_expand_relu\").output # \n",
    "    second_conv = base_model.output # 32x32x1280\n",
    "    \n",
    "    # first_conv = base_model.get_layer(\"block_13_expand_relu\").output # 19 x 19 x 576\n",
    "    # second_conv = base_model.output # 10 x 10 x 1280\n",
    "    \n",
    "    if hyper_params[\"feature_fusion\"] != None:\n",
    "        first_conv_upsampled = UpSampling2D(size=(2, 2), interpolation='bilinear')(first_conv)\n",
    "        second1_conv_upsampled = UpSampling2D(size=(4, 4), interpolation='bilinear')(second_conv)\n",
    "        second2_conv_upsampled = UpSampling2D(size=(2, 2), interpolation='bilinear')(second_conv)\n",
    "        if hyper_params[\"feature_fusion\"] == \"concat\": # require same size\n",
    "            zero_conv = tf.keras.layers.Conv2D(filters=256,\n",
    "                                    kernel_size=(3,3),\n",
    "                                    strides=(1,1),\n",
    "                                    activation=\"relu\",\n",
    "                                    padding=\"same\",\n",
    "                                    name=\"zero_conv\",\n",
    "                                    kernel_initializer='he_normal')(zero_conv)\n",
    "            zero_conv = tf.keras.layers.BatchNormalization(gamma_initializer=tf.keras.initializers.Constant(value=20))(zero_conv)\n",
    "            zero_conv = tf.keras.layers.ReLU()(zero_conv)\n",
    "            first_conv_upsampled = tf.keras.layers.Conv2D(filters=256,\n",
    "                                    kernel_size=(3,3),\n",
    "                                    strides=(1,1),\n",
    "                                    activation=\"relu\",\n",
    "                                    padding=\"same\",\n",
    "                                    name=\"first_conv_upsampled\",\n",
    "                                    kernel_initializer='he_normal')(first_conv_upsampled)\n",
    "            first_conv_upsampled = tf.keras.layers.BatchNormalization(gamma_initializer=tf.keras.initializers.Constant(value=10))(first_conv_upsampled)\n",
    "            first_conv_upsampled = tf.keras.layers.ReLU()(first_conv_upsampled)\n",
    "            second1_conv_upsampled = tf.keras.layers.Conv2D(filters=256,\n",
    "                                    kernel_size=(3,3),\n",
    "                                    strides=(1,1),\n",
    "                                    activation=\"relu\",\n",
    "                                    padding=\"same\",\n",
    "                                    name=\"second1_conv_upsampled\",\n",
    "                                    kernel_initializer='he_normal')(second1_conv_upsampled)\n",
    "            second1_conv_upsampled = tf.keras.layers.BatchNormalization(gamma_initializer=tf.keras.initializers.Constant(value=5))(second1_conv_upsampled)\n",
    "            second1_conv_upsampled = tf.keras.layers.ReLU()(second1_conv_upsampled)\n",
    "#             zero_conv = Concatenate(axis=-1)([zero_conv, first_conv_upsampled])\n",
    "            zero_conv = Concatenate(axis=-1)([zero_conv, first_conv_upsampled, second1_conv_upsampled])\n",
    "            zero_conv = tf.keras.layers.Conv2D(filters=256,\n",
    "                                    kernel_size=(1,1),\n",
    "                                    strides=(1,1),\n",
    "                                    activation=\"relu\",\n",
    "                                    padding=\"valid\",\n",
    "                                    name=\"final_zero_conv\",\n",
    "                                    kernel_initializer='he_normal')(zero_conv)\n",
    "            zero_conv = tf.keras.layers.ReLU()(zero_conv)\n",
    "            zero_conv = tf.keras.layers.BatchNormalization()(zero_conv)\n",
    "            \n",
    "            first_conv = tf.keras.layers.Conv2D(filters=256,\n",
    "                                    kernel_size=(3,3),\n",
    "                                    strides=(1,1),\n",
    "                                    activation=\"relu\",\n",
    "                                    padding=\"same\",\n",
    "                                    name=\"first_conv\",\n",
    "                                    kernel_initializer='he_normal')(first_conv)\n",
    "            first_conv = tf.keras.layers.BatchNormalization(gamma_initializer=tf.keras.initializers.Constant(value=20))(first_conv)\n",
    "            first_conv = tf.keras.layers.ReLU()(first_conv)\n",
    "            second2_conv_upsampled = tf.keras.layers.Conv2D(filters=256,\n",
    "                                    kernel_size=(3,3),\n",
    "                                    strides=(1,1),\n",
    "                                    activation=\"relu\",\n",
    "                                    padding=\"same\",\n",
    "                                    name=\"second2_conv_upsampled\",\n",
    "                                    kernel_initializer='he_normal')(second2_conv_upsampled)\n",
    "            second2_conv_upsampled = tf.keras.layers.BatchNormalization(gamma_initializer=tf.keras.initializers.Constant(value=10))(second2_conv_upsampled)\n",
    "            second2_conv_upsampled = tf.keras.layers.ReLU()(second2_conv_upsampled)\n",
    "            first_conv = Concatenate(axis=-1)([first_conv, second2_conv_upsampled])\n",
    "            first_conv = tf.keras.layers.Conv2D(filters=256,\n",
    "                                    kernel_size=(1,1),\n",
    "                                    strides=(1,1),\n",
    "                                    activation=\"relu\",\n",
    "                                    padding=\"valid\",\n",
    "                                    name=\"final_first_conv\",\n",
    "                                    kernel_initializer='he_normal')(first_conv)\n",
    "            first_conv = tf.keras.layers.ReLU()(first_conv)\n",
    "            first_conv = tf.keras.layers.BatchNormalization()(first_conv)\n",
    "            \n",
    "        elif hyper_params[\"feature_fusion\"] == \"elesum\": # require same size and same number of channels\n",
    "            zero_conv = tf.keras.layers.Conv2D(filters=256,\n",
    "                                    kernel_size=(1,1),\n",
    "                                    strides=(1,1),\n",
    "                                    padding=\"valid\",\n",
    "                                    name=\"zero_conv\",\n",
    "                                    kernel_initializer='he_normal')(zero_conv)\n",
    "            zero_conv = tf.keras.layers.BatchNormalization(gamma_initializer=tf.keras.initializers.Constant(value=20))(zero_conv)\n",
    "#             zero_conv = tf.keras.layers.ReLU()(zero_conv)\n",
    "            first_conv_upsampled = tf.keras.layers.Conv2D(filters=256,\n",
    "                                    kernel_size=(1,1),\n",
    "                                    strides=(1,1),\n",
    "                                    padding=\"valid\",\n",
    "                                    name=\"first_conv_upsampled\",\n",
    "                                    kernel_initializer='he_normal')(first_conv_upsampled)\n",
    "            first_conv_upsampled = tf.keras.layers.BatchNormalization(gamma_initializer=tf.keras.initializers.Constant(value=10))(first_conv_upsampled)\n",
    "#             first_conv_upsampled = tf.keras.layers.ReLU()(first_conv_upsampled)\n",
    "            second1_conv_upsampled = tf.keras.layers.Conv2D(filters=256,\n",
    "                                    kernel_size=(1,1),\n",
    "                                    strides=(1,1),\n",
    "                                    padding=\"valid\",\n",
    "                                    name=\"second1_conv_upsampled\",\n",
    "                                    kernel_initializer='he_normal')(second1_conv_upsampled)\n",
    "            second1_conv_upsampled = tf.keras.layers.BatchNormalization(gamma_initializer=tf.keras.initializers.Constant(value=5))(second1_conv_upsampled)\n",
    "#             second1_conv_upsampled = tf.keras.layers.ReLU()(second1_conv_upsampled)\n",
    "\n",
    "            first_conv = tf.keras.layers.Conv2D(filters=256,\n",
    "                                    kernel_size=(1,1),\n",
    "                                    strides=(1,1),\n",
    "                                    padding=\"valid\",\n",
    "                                    name=\"first_conv\",\n",
    "                                    kernel_initializer='he_normal')(first_conv)\n",
    "            first_conv = tf.keras.layers.BatchNormalization(gamma_initializer=tf.keras.initializers.Constant(value=20))(first_conv)\n",
    "#             first_conv = tf.keras.layers.ReLU()(first_conv)\n",
    "            second2_conv_upsampled = tf.keras.layers.Conv2D(filters=256,\n",
    "                                    kernel_size=(1,1),\n",
    "                                    strides=(1,1),\n",
    "                                    padding=\"valid\",\n",
    "                                    name=\"second2_conv_upsampled\",\n",
    "                                    kernel_initializer='he_normal')(second2_conv_upsampled)\n",
    "            second2_conv_upsampled = tf.keras.layers.BatchNormalization(gamma_initializer=tf.keras.initializers.Constant(value=10))(second2_conv_upsampled)\n",
    "#             second2_conv_upsampled = tf.keras.layers.ReLU()(second2_conv_upsampled)\n",
    "#             zero_conv = Add()([zero_conv, first_conv_upsampled])        \n",
    "            zero_conv = Add()([zero_conv, first_conv_upsampled, second1_conv_upsampled])\n",
    "            first_conv = Add()([first_conv, second2_conv_upsampled])\n",
    "            zero_conv = BatchNormalization()(zero_conv)\n",
    "            zero_conv = Activation(\"relu\")(zero_conv)\n",
    "            \n",
    "            first_conv = BatchNormalization()(first_conv)\n",
    "            first_conv = Activation(\"relu\")(first_conv)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    ############################ Extra Feature Layers Start ############################\n",
    "    extra1_1 = conv_layer(256, (1, 1), strides=(1, 1), padding=\"valid\", activation=\"relu\", name=\"extra1_1\", layer=second_conv)\n",
    "    extra1_2 = conv_layer(512, (3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\", name=\"extra1_2\", layer=extra1_1)\n",
    "\n",
    "    extra2_1 = conv_layer(128, (1, 1), strides=(1, 1), padding=\"valid\", activation=\"relu\", name=\"extra2_1\", layer=extra1_2)\n",
    "    extra2_2 = conv_layer(256, (3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\", name=\"extra2_2\", layer=extra2_1)\n",
    "\n",
    "    extra3_1 = conv_layer(128, (1, 1), strides=(1, 1), padding=\"valid\", activation=\"relu\", name=\"extra3_1\", layer=extra2_2)\n",
    "    extra3_2 = conv_layer(256, (3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\", name=\"extra3_2\", layer=extra3_1)\n",
    "    \n",
    "#     extra4_1 = conv_layer(128, (1, 1), strides=(1, 1), padding=\"valid\", activation=\"relu\", name=\"extra4_1\", layer=extra3_2)\n",
    "#     extra4_2 = conv_layer(256, (3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\", name=\"extra4_2\", layer=extra4_1)\n",
    "    ############################ Extra Feature Layers End ############################\n",
    "    \n",
    "    pred_deltas, pred_labels = get_head_from_outputs(hyper_params, [zero_conv, first_conv, second_conv, extra1_2, extra2_2, extra3_2])\n",
    "#     pred_deltas, pred_labels = get_head_from_outputs(hyper_params, [first_conv, second_conv, extra1_2, extra2_2, extra3_2, extra4_2])\n",
    "    return Model(inputs=input, outputs=[pred_deltas, pred_labels])\n",
    "\n",
    "def init_model(model, img_size):\n",
    "    \"\"\"Initializing model with dummy data for load weights with optimizer state and also graph construction.\n",
    "    inputs:\n",
    "        model = tf.keras.model\n",
    "\n",
    "    \"\"\"\n",
    "    model(tf.random.uniform((1, img_size, img_size, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db56acd9",
   "metadata": {
    "papermill": {
     "duration": 0.015625,
     "end_time": "2024-03-08T08:22:38.303136",
     "exception": false,
     "start_time": "2024-03-08T08:22:38.287511",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Roboflow Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36b76cc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:22:38.336227Z",
     "iopub.status.busy": "2024-03-08T08:22:38.335870Z",
     "iopub.status.idle": "2024-03-08T08:22:56.875106Z",
     "shell.execute_reply": "2024-03-08T08:22:56.874083Z"
    },
    "id": "vGmfrj73iUhb",
    "outputId": "5fa4234b-908f-46b4-97b6-b53d2fc919d2",
    "papermill": {
     "duration": 18.558819,
     "end_time": "2024-03-08T08:22:56.877480",
     "exception": false,
     "start_time": "2024-03-08T08:22:38.318661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\r\n",
      "  Downloading roboflow-1.1.21-py3-none-any.whl.metadata (9.3 kB)\r\n",
      "Collecting certifi==2023.7.22 (from roboflow)\r\n",
      "  Downloading certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\r\n",
      "Collecting chardet==4.0.0 (from roboflow)\r\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\r\n",
      "Collecting cycler==0.10.0 (from roboflow)\r\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl.metadata (722 bytes)\r\n",
      "Collecting idna==2.10 (from roboflow)\r\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.4.5)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from roboflow) (3.7.4)\r\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.24.4)\r\n",
      "Collecting opencv-python-headless==4.8.0.74 (from roboflow)\r\n",
      "  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\r\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from roboflow) (9.5.0)\r\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from roboflow) (2.8.2)\r\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.0.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from roboflow) (2.31.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.16.0)\r\n",
      "Collecting supervision (from roboflow)\r\n",
      "  Downloading supervision-0.18.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.26.18)\r\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from roboflow) (4.66.1)\r\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from roboflow) (6.0.1)\r\n",
      "Requirement already satisfied: requests-toolbelt in /opt/conda/lib/python3.10/site-packages (from roboflow) (0.10.1)\r\n",
      "Collecting python-magic (from roboflow)\r\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (1.2.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (4.47.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (21.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (3.1.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->roboflow) (3.3.2)\r\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from supervision->roboflow) (0.7.1)\r\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from supervision->roboflow) (1.11.4)\r\n",
      "Downloading roboflow-1.1.21-py3-none-any.whl (70 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.2/70.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading certifi-2023.7.22-py3-none-any.whl (158 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\r\n",
      "Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\r\n",
      "Downloading supervision-0.18.0-py3-none-any.whl (86 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: python-magic, opencv-python-headless, idna, cycler, chardet, certifi, supervision, roboflow\r\n",
      "  Attempting uninstall: opencv-python-headless\r\n",
      "    Found existing installation: opencv-python-headless 4.9.0.80\r\n",
      "    Uninstalling opencv-python-headless-4.9.0.80:\r\n",
      "      Successfully uninstalled opencv-python-headless-4.9.0.80\r\n",
      "  Attempting uninstall: idna\r\n",
      "    Found existing installation: idna 3.6\r\n",
      "    Uninstalling idna-3.6:\r\n",
      "      Successfully uninstalled idna-3.6\r\n",
      "  Attempting uninstall: cycler\r\n",
      "    Found existing installation: cycler 0.12.1\r\n",
      "    Uninstalling cycler-0.12.1:\r\n",
      "      Successfully uninstalled cycler-0.12.1\r\n",
      "  Attempting uninstall: certifi\r\n",
      "    Found existing installation: certifi 2023.11.17\r\n",
      "    Uninstalling certifi-2023.11.17:\r\n",
      "      Successfully uninstalled certifi-2023.11.17\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "jupyterlab 4.0.11 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.0.2 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "osmnx 1.8.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflowjs 4.16.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed certifi-2023.7.22 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 python-magic-0.4.27 roboflow-1.1.21 supervision-0.18.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"YOUR API KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fb64218",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:22:56.919699Z",
     "iopub.status.busy": "2024-03-08T08:22:56.918642Z",
     "iopub.status.idle": "2024-03-08T08:24:12.540088Z",
     "shell.execute_reply": "2024-03-08T08:24:12.538861Z"
    },
    "id": "hszpdXFNv3zP",
    "outputId": "8047d572-5a62-411c-9197-c9296ce74328",
    "papermill": {
     "duration": 75.645395,
     "end_time": "2024-03-08T08:24:12.542873",
     "exception": false,
     "start_time": "2024-03-08T08:22:56.897478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'models'...\r\n",
      "remote: Enumerating objects: 96640, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (6528/6528), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (3523/3523), done.\u001b[K\r\n",
      "remote: Total 96640 (delta 3320), reused 6070 (delta 2957), pack-reused 90112\u001b[K\r\n",
      "Receiving objects: 100% (96640/96640), 619.98 MiB | 30.20 MiB/s, done.\r\n",
      "Resolving deltas: 100% (68252/68252), done.\r\n",
      "Processing /kaggle/working/models/research\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\r\n",
      "\u001b[?25hCollecting avro-python3 (from object_detection==0.1)\r\n",
      "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: apache-beam in /opt/conda/lib/python3.10/site-packages (from object_detection==0.1) (2.46.0)\r\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from object_detection==0.1) (9.5.0)\r\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from object_detection==0.1) (5.1.0)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from object_detection==0.1) (3.7.4)\r\n",
      "Requirement already satisfied: Cython in /opt/conda/lib/python3.10/site-packages (from object_detection==0.1) (3.0.8)\r\n",
      "Collecting contextlib2 (from object_detection==0.1)\r\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\r\n",
      "Collecting tf-slim (from object_detection==0.1)\r\n",
      "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from object_detection==0.1) (1.16.0)\r\n",
      "Collecting pycocotools (from object_detection==0.1)\r\n",
      "  Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\r\n",
      "Collecting lvis (from object_detection==0.1)\r\n",
      "  Downloading lvis-0.5.3-py3-none-any.whl.metadata (856 bytes)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from object_detection==0.1) (1.11.4)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from object_detection==0.1) (2.1.4)\r\n",
      "Collecting tf-models-official>=2.5.1 (from object_detection==0.1)\r\n",
      "  Downloading tf_models_official-2.15.0-py2.py3-none-any.whl.metadata (1.4 kB)\r\n",
      "Requirement already satisfied: tensorflow_io in /opt/conda/lib/python3.10/site-packages (from object_detection==0.1) (0.35.0)\r\n",
      "Requirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (from object_detection==0.1) (2.15.0)\r\n",
      "Collecting pyparsing==2.4.7 (from object_detection==0.1)\r\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl.metadata (3.6 kB)\r\n",
      "Collecting sacrebleu<=2.2.0 (from object_detection==0.1)\r\n",
      "  Downloading sacrebleu-2.2.0-py3-none-any.whl.metadata (55 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting portalocker (from sacrebleu<=2.2.0->object_detection==0.1)\r\n",
      "  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\r\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu<=2.2.0->object_detection==0.1) (2023.12.25)\r\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.9.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu<=2.2.0->object_detection==0.1) (1.24.4)\r\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.4.6)\r\n",
      "Collecting gin-config (from tf-models-official>=2.5.1->object_detection==0.1)\r\n",
      "  Downloading gin_config-0.5.0-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.115.0)\r\n",
      "Collecting immutabledict (from tf-models-official>=2.5.1->object_detection==0.1)\r\n",
      "  Downloading immutabledict-4.2.0-py3-none-any.whl.metadata (3.4 kB)\r\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (1.6.3)\r\n",
      "Requirement already satisfied: oauth2client in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.1.3)\r\n",
      "Requirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.8.0.74)\r\n",
      "Requirement already satisfied: psutil>=5.4.3 in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (5.9.3)\r\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (9.0.0)\r\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (6.0.1)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.1.99)\r\n",
      "Collecting seqeval (from tf-models-official>=2.5.1->object_detection==0.1)\r\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.9.4)\r\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.15.0)\r\n",
      "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official>=2.5.1->object_detection==0.1)\r\n",
      "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\r\n",
      "Requirement already satisfied: tensorflow-text~=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.15.0)\r\n",
      "Requirement already satisfied: tensorflow~=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.15.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->object_detection==0.1) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->object_detection==0.1) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->object_detection==0.1) (2023.4)\r\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from tf-slim->object_detection==0.1) (1.4.0)\r\n",
      "Requirement already satisfied: protobuf<4,>3.12.2 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (3.20.3)\r\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (1.7)\r\n",
      "Requirement already satisfied: orjson<4.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (3.9.10)\r\n",
      "Collecting dill<0.3.2,>=0.3.1.1 (from apache-beam->object_detection==0.1)\r\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: cloudpickle~=2.2.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (2.2.1)\r\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (1.9.3)\r\n",
      "Requirement already satisfied: fasteners<1.0,>=0.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (0.19)\r\n",
      "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (1.51.1)\r\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (2.7.3)\r\n",
      "Requirement already satisfied: httplib2<0.22.0,>=0.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (0.21.0)\r\n",
      "Requirement already satisfied: objsize<0.7.0,>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (0.6.1)\r\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (3.13.0)\r\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (1.23.0)\r\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (1.4.2)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (2.31.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (4.9.0)\r\n",
      "Requirement already satisfied: zstandard<1,>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (0.22.0)\r\n",
      "Collecting pyarrow<10.0.0,>=3.0.0 (from apache-beam->object_detection==0.1)\r\n",
      "  Downloading pyarrow-9.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\r\n",
      "Requirement already satisfied: cycler>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from lvis->object_detection==0.1) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from lvis->object_detection==0.1) (1.4.5)\r\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /opt/conda/lib/python3.10/site-packages (from lvis->object_detection==0.1) (4.9.0.80)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->object_detection==0.1) (1.2.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->object_detection==0.1) (4.47.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->object_detection==0.1) (21.3)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.35.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_io->object_detection==0.1) (0.35.0)\r\n",
      "Requirement already satisfied: google-auth<3.0.0.dev0,>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (2.26.1)\r\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (0.1.1)\r\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (2.11.1)\r\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (3.0.1)\r\n",
      "Requirement already satisfied: docopt in /opt/conda/lib/python3.10/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object_detection==0.1) (0.6.2)\r\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (2023.7.22)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (4.66.1)\r\n",
      "Requirement already satisfied: python-slugify in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (8.0.1)\r\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (1.26.18)\r\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (6.1.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object_detection==0.1) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object_detection==0.1) (2.10)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (23.5.26)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (0.5.4)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (3.10.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (16.0.6)\r\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (3.3.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (69.0.3)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (2.4.0)\r\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (1.14.1)\r\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (2.15.1)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (2.15.0)\r\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object_detection==0.1) (0.1.8)\r\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.10/site-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (0.5.1)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /opt/conda/lib/python3.10/site-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (0.3.0)\r\n",
      "Requirement already satisfied: rsa>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (4.9)\r\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval->tf-models-official>=2.5.1->object_detection==0.1) (1.2.2)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (8.1.7)\r\n",
      "Requirement already satisfied: etils>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (1.6.0)\r\n",
      "Requirement already satisfied: promise in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (2.3)\r\n",
      "Requirement already satisfied: tensorflow-metadata in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.14.0)\r\n",
      "Requirement already satisfied: toml in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.10.2)\r\n",
      "Requirement already satisfied: array-record>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.5.0)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (0.42.0)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (2023.12.2)\r\n",
      "Requirement already satisfied: importlib_resources in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (6.1.1)\r\n",
      "Requirement already satisfied: zipp in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (3.17.0)\r\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (1.62.0)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (4.2.4)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object_detection==0.1) (1.3.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object_detection==0.1) (3.2.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (1.2.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (3.5.2)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (3.0.1)\r\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (0.5.1)\r\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.10/site-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (1.3)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (1.3.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (2.1.3)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (3.2.2)\r\n",
      "Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tf_models_official-2.15.0-py2.py3-none-any.whl (2.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\r\n",
      "Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\r\n",
      "Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.2/426.2 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pyarrow-9.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.3/35.3 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading gin_config-0.5.0-py3-none-any.whl (61 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading immutabledict-4.2.0-py3-none-any.whl (4.7 kB)\r\n",
      "Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\r\n",
      "Building wheels for collected packages: object_detection, avro-python3, dill, seqeval\r\n",
      "  Building wheel for object_detection (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for object_detection: filename=object_detection-0.1-py3-none-any.whl size=21878671 sha256=dd315b36e848fe6a34768a7115a32acab3276c4608a97c976bf504c908ca6f9c\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-hgo7s_km/wheels/e6/5c/1f/32444df4025257dccdc9eafab2d06b65752494ee9ca01a388c\r\n",
      "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43992 sha256=3879f2849b11a3fd4cc8f0305922f43e1be80e77d794c936b7a23a0844b7f248\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/bc/85/62/6cdd81c56f923946b401cecff38055b94c9b766927f7d8ca82\r\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78540 sha256=0de97bab167b70527a899c59464be1c8d95295a5e1d1e80dfb97f76df812c996\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\r\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=59545e593946c8d533aaa11868cdd1c82d2bd98016a7d0d24825b0641786fd32\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\r\n",
      "Successfully built object_detection avro-python3 dill seqeval\r\n",
      "Installing collected packages: gin-config, tf-slim, tensorflow-model-optimization, pyparsing, pyarrow, portalocker, immutabledict, dill, contextlib2, avro-python3, sacrebleu, seqeval, pycocotools, lvis, tf-models-official, object_detection\r\n",
      "  Attempting uninstall: pyparsing\r\n",
      "    Found existing installation: pyparsing 3.1.1\r\n",
      "    Uninstalling pyparsing-3.1.1:\r\n",
      "      Successfully uninstalled pyparsing-3.1.1\r\n",
      "  Attempting uninstall: pyarrow\r\n",
      "    Found existing installation: pyarrow 11.0.0\r\n",
      "    Uninstalling pyarrow-11.0.0:\r\n",
      "      Successfully uninstalled pyarrow-11.0.0\r\n",
      "  Attempting uninstall: dill\r\n",
      "    Found existing installation: dill 0.3.7\r\n",
      "    Uninstalling dill-0.3.7:\r\n",
      "      Successfully uninstalled dill-0.3.7\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cudf 23.8.0 requires cubinlinker, which is not installed.\r\n",
      "cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "cudf 23.8.0 requires ptxcompiler, which is not installed.\r\n",
      "cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "beatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.0.11 which is incompatible.\r\n",
      "cudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\r\n",
      "cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\r\n",
      "cudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "cudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 9.0.0 which is incompatible.\r\n",
      "cuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\r\n",
      "cuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\r\n",
      "dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\r\n",
      "dask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\r\n",
      "dask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\r\n",
      "multiprocess 0.70.15 requires dill>=0.3.7, but you have dill 0.3.1.1 which is incompatible.\r\n",
      "pathos 0.3.1 requires dill>=0.3.7, but you have dill 0.3.1.1 which is incompatible.\r\n",
      "pytoolconfig 1.3.1 requires packaging>=23.2, but you have packaging 21.3 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflowjs 4.16.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\r\n",
      "xarray 2024.1.0 requires packaging>=22, but you have packaging 21.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed avro-python3-1.10.2 contextlib2-21.6.0 dill-0.3.1.1 gin-config-0.5.0 immutabledict-4.2.0 lvis-0.5.3 object_detection-0.1 portalocker-2.8.2 pyarrow-9.0.0 pycocotools-2.0.7 pyparsing-2.4.7 sacrebleu-2.2.0 seqeval-1.2.2 tensorflow-model-optimization-0.8.0 tf-models-official-2.15.0 tf-slim-1.1.0\r\n"
     ]
    }
   ],
   "source": [
    "# Clone the tensorflow models repository if it doesn't already exist\n",
    "if \"models\" in pathlib.Path.cwd().parts:\n",
    "    while \"models\" in pathlib.Path.cwd().parts:\n",
    "        os.chdir('..')\n",
    "elif not pathlib.Path('models').exists():\n",
    "    # Install the Object Detection API\n",
    "    !git clone https://github.com/tensorflow/models.git\n",
    "    !cd models/research && protoc object_detection/protos/*.proto --python_out=.\n",
    "    !cd models/research && cp object_detection/packages/tf2/setup.py .\n",
    "    !cd models/research && python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2cf57c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:24:12.616508Z",
     "iopub.status.busy": "2024-03-08T08:24:12.615569Z",
     "iopub.status.idle": "2024-03-08T08:24:42.349320Z",
     "shell.execute_reply": "2024-03-08T08:24:42.348366Z"
    },
    "id": "b_mYXsDeJMsX",
    "outputId": "99925f28-8143-4f75-9a99-e2e87159bcc7",
    "papermill": {
     "duration": 29.773404,
     "end_time": "2024-03-08T08:24:42.351643",
     "exception": false,
     "start_time": "2024-03-08T08:24:12.578239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Fabric-Defect-Capstone-1 to tfrecord:: 100%|██████████| 789109/789109 [00:24<00:00, 31780.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Fabric-Defect-Capstone-1 in tfrecord:: 100%|██████████| 11/11 [00:01<00:00,  8.14it/s]\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/kaggle/working/')\n",
    "if hyper_params[\"dataset\"] == 0:\n",
    "    # dut\n",
    "    project = rf.workspace(\"ducks-zdbul\").project(\"fabric-defect-capstone\")\n",
    "    dataset = project.version(1).download(\"tfrecord\")\n",
    "elif hyper_params[\"dataset\"] == 1:\n",
    "    # tilda\n",
    "    project = rf.workspace(\"irvin-andersen\").project(\"tilda-fabric\")\n",
    "    dataset = project.version(2).download(\"tfrecord\")\n",
    "elif hyper_params[\"dataset\"] == 2:\n",
    "    # daffodil\n",
    "    project = rf.workspace(\"defect-detection-witqu\").project(\"fabric-defect-daffodil\")\n",
    "    dataset = project.version(1).download(\"tfrecord\")\n",
    "elif hyper_params[\"dataset\"] == 3:\n",
    "    # thesis\n",
    "    project = rf.workspace(\"ducks-zdbul\").project(\"fabric-defect-thesis-quv7v\")\n",
    "    dataset = project.version(1).download(\"tfrecord\")\n",
    "elif hyper_params[\"dataset\"] == 4:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c652f0",
   "metadata": {
    "id": "8N8ZG5fxFYD0",
    "papermill": {
     "duration": 0.096725,
     "end_time": "2024-03-08T08:24:42.502065",
     "exception": false,
     "start_time": "2024-03-08T08:24:42.405340",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab4ff6f",
   "metadata": {
    "id": "sZFFc8m4HIFH",
    "papermill": {
     "duration": 0.052829,
     "end_time": "2024-03-08T08:24:42.606935",
     "exception": false,
     "start_time": "2024-03-08T08:24:42.554106",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1660af3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:24:42.714985Z",
     "iopub.status.busy": "2024-03-08T08:24:42.714595Z",
     "iopub.status.idle": "2024-03-08T08:24:42.740836Z",
     "shell.execute_reply": "2024-03-08T08:24:42.739930Z"
    },
    "id": "p_NZkMjgHLNp",
    "papermill": {
     "duration": 0.082358,
     "end_time": "2024-03-08T08:24:42.742724",
     "exception": false,
     "start_time": "2024-03-08T08:24:42.660366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply(img, gt_boxes):\n",
    "    \"\"\"Randomly applying data augmentation methods to image and ground truth boxes.\n",
    "    inputs:\n",
    "        img = (height, width, depth)\n",
    "        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "            in normalized form [0, 1]\n",
    "    outputs:\n",
    "        modified_img = (final_height, final_width, depth)\n",
    "        modified_gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "            in normalized form [0, 1]\n",
    "    \"\"\"\n",
    "    # Color operations\n",
    "    # Randomly change hue, saturation, brightness and contrast of image\n",
    "    color_methods = [random_brightness, random_contrast, random_hue, random_saturation]\n",
    "    # Geometric operations\n",
    "    # Randomly sample a patch and flip horizontally image and ground truth boxes\n",
    "    geometric_methods = [patch, flip_horizontally]\n",
    "\n",
    "    for augmentation_method in geometric_methods + color_methods:\n",
    "        img, gt_boxes = randomly_apply_operation(augmentation_method, img, gt_boxes)\n",
    "\n",
    "    img = tf.clip_by_value(img, 0, 1)\n",
    "    return img, gt_boxes\n",
    "\n",
    "def get_random_bool():\n",
    "    \"\"\"Generating random boolean.\n",
    "    outputs:\n",
    "        random boolean 0d tensor\n",
    "    \"\"\"\n",
    "    return tf.greater(tf.random.uniform((), dtype=tf.float32), 0.5)\n",
    "\n",
    "def randomly_apply_operation(operation, img, gt_boxes, *args):\n",
    "    \"\"\"Randomly applying given method to image and ground truth boxes.\n",
    "    inputs:\n",
    "        operation = callable method\n",
    "        img = (height, width, depth)\n",
    "        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "    outputs:\n",
    "        modified_or_not_img = (final_height, final_width, depth)\n",
    "        modified_or_not_gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "    \"\"\"\n",
    "    return tf.cond(\n",
    "        get_random_bool(),\n",
    "        lambda: operation(img, gt_boxes, *args),\n",
    "        lambda: (img, gt_boxes)\n",
    "    )\n",
    "\n",
    "def random_brightness(img, gt_boxes, max_delta=0.12):\n",
    "    \"\"\"Randomly change brightness of the image.\n",
    "    inputs:\n",
    "        img = (height, width, depth)\n",
    "        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "    outputs:\n",
    "        modified_img = (height, width, depth)\n",
    "        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "    \"\"\"\n",
    "    return tf.image.random_brightness(img, max_delta), gt_boxes\n",
    "\n",
    "def random_contrast(img, gt_boxes, lower=0.5, upper=1.5):\n",
    "    \"\"\"Randomly change contrast of the image.\n",
    "    inputs:\n",
    "        img = (height, width, depth)\n",
    "        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "    outputs:\n",
    "        modified_img = (height, width, depth)\n",
    "        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "    \"\"\"\n",
    "    return tf.image.random_contrast(img, lower, upper), gt_boxes\n",
    "\n",
    "def random_hue(img, gt_boxes, max_delta=0.08):\n",
    "    \"\"\"Randomly change hue of the image.\n",
    "    inputs:\n",
    "        img = (height, width, depth)\n",
    "        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "    outputs:\n",
    "        modified_img = (height, width, depth)\n",
    "        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "    \"\"\"\n",
    "    return tf.image.random_hue(img, max_delta), gt_boxes\n",
    "\n",
    "def random_saturation(img, gt_boxes, lower=0.5, upper=1.5):\n",
    "    \"\"\"Randomly change saturation of the image.\n",
    "    inputs:\n",
    "        img = (height, width, depth)\n",
    "        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "    outputs:\n",
    "        modified_img = (height, width, depth)\n",
    "        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "    \"\"\"\n",
    "    return tf.image.random_saturation(img, lower, upper), gt_boxes\n",
    "\n",
    "def flip_horizontally(img, gt_boxes):\n",
    "    \"\"\"Flip image horizontally and adjust the ground truth boxes.\n",
    "    inputs:\n",
    "        img = (height, width, depth)\n",
    "        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "    outputs:\n",
    "        modified_img = (height, width, depth)\n",
    "        modified_gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "    \"\"\"\n",
    "    flipped_img = tf.image.flip_left_right(img)\n",
    "    flipped_gt_boxes = tf.stack([gt_boxes[..., 0],\n",
    "                                1.0 - gt_boxes[..., 3],\n",
    "                                gt_boxes[..., 2],\n",
    "                                1.0 - gt_boxes[..., 1]], -1)\n",
    "    return flipped_img, flipped_gt_boxes\n",
    "\n",
    "##############################################################################\n",
    "## Sample patch start\n",
    "##############################################################################\n",
    "\n",
    "def get_random_min_overlap():\n",
    "    \"\"\"Generating random minimum overlap value.\n",
    "    outputs:\n",
    "        min_overlap = random minimum overlap value 0d tensor\n",
    "    \"\"\"\n",
    "    overlaps = tf.constant([0.1, 0.3, 0.5, 0.7, 0.9], dtype=tf.float32)\n",
    "    i = tf.random.uniform((), minval=0, maxval=tf.shape(overlaps)[0], dtype=tf.int32)\n",
    "    return overlaps[i]\n",
    "\n",
    "def expand_image(img, gt_boxes, height, width):\n",
    "    \"\"\"Randomly expanding image and adjusting ground truth object coordinates.\n",
    "    inputs:\n",
    "        img = (height, width, depth)\n",
    "        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "        height = height of the image\n",
    "        width = width of the image\n",
    "    outputs:\n",
    "        img = (final_height, final_width, depth)\n",
    "        modified_gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "        final_height = final height of the image\n",
    "        final_width = final width of the image\n",
    "    \"\"\"\n",
    "    expansion_ratio = tf.random.uniform((), minval=1, maxval=4, dtype=tf.float32)\n",
    "    final_height, final_width = tf.round(height * expansion_ratio), tf.round(width * expansion_ratio)\n",
    "    pad_left = tf.round(tf.random.uniform((), minval=0, maxval=final_width - width, dtype=tf.float32))\n",
    "    pad_top = tf.round(tf.random.uniform((), minval=0, maxval=final_height - height, dtype=tf.float32))\n",
    "    pad_right = final_width - (width + pad_left)\n",
    "    pad_bottom = final_height - (height + pad_top)\n",
    "\n",
    "    mean, _ = tf.nn.moments(img, [0, 1])\n",
    "    expanded_image = tf.pad(img, ((pad_top, pad_bottom), (pad_left, pad_right), (0,0)), constant_values=-1)\n",
    "    expanded_image = tf.where(expanded_image == -1, mean, expanded_image)\n",
    "\n",
    "    min_max = tf.stack([-pad_top, -pad_left, pad_bottom+height, pad_right+width], -1) / [height, width, height, width]\n",
    "    modified_gt_boxes = renormalize_bboxes_with_min_max(gt_boxes, min_max)\n",
    "\n",
    "    return expanded_image, modified_gt_boxes\n",
    "\n",
    "def patch(img, gt_boxes):\n",
    "    \"\"\"Generating random patch and adjusting image and ground truth objects to this patch.\n",
    "    After this operation some of the ground truth boxes / objects could be removed from the image.\n",
    "    However, these objects are not excluded from the output, only the coordinates are changed as zero.\n",
    "    inputs:\n",
    "        img = (height, width, depth)\n",
    "        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "            in normalized form [0, 1]\n",
    "    outputs:\n",
    "        modified_img = (final_height, final_width, depth)\n",
    "        modified_gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "            in normalized form [0, 1]\n",
    "    \"\"\"\n",
    "    img_shape = tf.cast(tf.shape(img), dtype=tf.float32)\n",
    "    org_height, org_width = img_shape[0], img_shape[1]\n",
    "    # Randomly expand image and adjust bounding boxes\n",
    "    img, gt_boxes = randomly_apply_operation(expand_image, img, gt_boxes, org_height, org_width)\n",
    "    # Get random minimum overlap value\n",
    "    min_overlap = get_random_min_overlap()\n",
    "\n",
    "    begin, size, new_boundaries = tf.image.sample_distorted_bounding_box(\n",
    "        tf.shape(img),\n",
    "        # use_image_if_no_bounding_boxes=True, ### FIX:26/1/24\n",
    "        bounding_boxes=tf.expand_dims(gt_boxes, 0),\n",
    "        aspect_ratio_range=[0.5, 2.0],\n",
    "        min_object_covered=min_overlap)\n",
    "\n",
    "    img = tf.slice(img, begin, size)\n",
    "    img = tf.image.resize(img, (org_height, org_width))\n",
    "    gt_boxes = renormalize_bboxes_with_min_max(gt_boxes, new_boundaries[0, 0])\n",
    "\n",
    "    return img, gt_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d3f1d9",
   "metadata": {
    "id": "qQE2tvn-Fhil",
    "papermill": {
     "duration": 0.053043,
     "end_time": "2024-03-08T08:24:42.849193",
     "exception": false,
     "start_time": "2024-03-08T08:24:42.796150",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# bbox_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81b7f587",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:24:42.956541Z",
     "iopub.status.busy": "2024-03-08T08:24:42.956145Z",
     "iopub.status.idle": "2024-03-08T08:24:42.979490Z",
     "shell.execute_reply": "2024-03-08T08:24:42.978496Z"
    },
    "id": "knGVG_zdT4Sf",
    "papermill": {
     "duration": 0.080118,
     "end_time": "2024-03-08T08:24:42.981768",
     "exception": false,
     "start_time": "2024-03-08T08:24:42.901650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def non_max_suppression(pred_bboxes, pred_labels, **kwargs):\n",
    "    \"\"\"Applying non maximum suppression.\n",
    "    SSD uses non-maximum suppression to prune away boxes that have IOU overlap with previously selected boxes.\n",
    "    Details could be found on tensorflow documentation.\n",
    "    https://www.tensorflow.org/api_docs/python/tf/image/combined_non_max_suppression\n",
    "    inputs:\n",
    "        pred_bboxes = (batch_size, total_bboxes, total_labels, [y1, x1, y2, x2])\n",
    "            total_labels should be 1 for binary operations like in rpn\n",
    "        pred_labels = (batch_size, total_bboxes, total_labels)\n",
    "        **kwargs = other parameters\n",
    "\n",
    "    outputs:\n",
    "        nms_boxes = (batch_size, max_detections, [y1, x1, y2, x2])\n",
    "        nmsed_scores = (batch_size, max_detections)\n",
    "        nmsed_classes = (batch_size, max_detections)\n",
    "        valid_detections = (batch_size)\n",
    "            Only the top valid_detections[i] entries in nms_boxes[i], nms_scores[i] and nms_class[i] are valid.\n",
    "            The rest of the entries are zero paddings.\n",
    "    \"\"\"\n",
    "    return tf.image.combined_non_max_suppression(\n",
    "        pred_bboxes,\n",
    "        pred_labels,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "def generate_iou_map(bboxes, gt_boxes, transpose_perm=[0, 2, 1]):\n",
    "    \"\"\"Calculating intersection over union values for each ground truth boxes in a dynamic manner.\n",
    "    It is supported from 1d to 3d dimensions for bounding boxes.\n",
    "    Even if bboxes have different rank from gt_boxes it should be work.\n",
    "    inputs:\n",
    "        bboxes = (dynamic_dimension, [y1, x1, y2, x2])\n",
    "        gt_boxes = (dynamic_dimension, [y1, x1, y2, x2])\n",
    "        transpose_perm = (transpose_perm_order)\n",
    "            for 3d gt_boxes => [0, 2, 1]\n",
    "            The returned tensor's dimension i will correspond to the input dimension perm[i].\n",
    "\n",
    "    outputs:\n",
    "        iou_map = (dynamic_dimension, total_gt_boxes)\n",
    "            same rank with the gt_boxes\n",
    "    \"\"\"\n",
    "    gt_rank = tf.rank(gt_boxes)\n",
    "    gt_expand_axis = gt_rank - 2\n",
    "\n",
    "    bbox_y1, bbox_x1, bbox_y2, bbox_x2 = tf.split(bboxes, 4, axis=-1)\n",
    "    gt_y1, gt_x1, gt_y2, gt_x2 = tf.split(gt_boxes, 4, axis=-1)\n",
    "\n",
    "    # Calculate bbox and ground truth boxes areas\n",
    "    gt_area = tf.squeeze((gt_y2 - gt_y1) * (gt_x2 - gt_x1), axis=-1)\n",
    "    bbox_area = tf.squeeze((bbox_y2 - bbox_y1) * (bbox_x2 - bbox_x1), axis=-1)\n",
    "\n",
    "    x_top = tf.maximum(bbox_x1, tf.transpose(gt_x1, transpose_perm))\n",
    "    y_top = tf.maximum(bbox_y1, tf.transpose(gt_y1, transpose_perm))\n",
    "    x_bottom = tf.minimum(bbox_x2, tf.transpose(gt_x2, transpose_perm))\n",
    "    y_bottom = tf.minimum(bbox_y2, tf.transpose(gt_y2, transpose_perm))\n",
    "\n",
    "    # Calculate intersection area\n",
    "    intersection_area = tf.maximum(x_bottom - x_top, 0) * tf.maximum(y_bottom - y_top, 0)\n",
    "    # Calculate union area\n",
    "    union_area = (tf.expand_dims(bbox_area, -1) + tf.expand_dims(gt_area, gt_expand_axis) - intersection_area)\n",
    "    # Intersection over Union\n",
    "    return intersection_area / union_area\n",
    "\n",
    "def get_bboxes_from_deltas(prior_boxes, deltas):\n",
    "    \"\"\"Calculating bounding boxes for given bounding box and delta values.\n",
    "    inputs:\n",
    "        prior_boxes = (total_bboxes, [y1, x1, y2, x2])\n",
    "        deltas = (batch_size, total_bboxes, [delta_y, delta_x, delta_h, delta_w])\n",
    "\n",
    "    outputs:\n",
    "        final_boxes = (batch_size, total_bboxes, [y1, x1, y2, x2])\n",
    "    \"\"\"\n",
    "    all_pbox_width = prior_boxes[..., 3] - prior_boxes[..., 1]\n",
    "    all_pbox_height = prior_boxes[..., 2] - prior_boxes[..., 0]\n",
    "    all_pbox_ctr_x = prior_boxes[..., 1] + 0.5 * all_pbox_width\n",
    "    all_pbox_ctr_y = prior_boxes[..., 0] + 0.5 * all_pbox_height\n",
    "\n",
    "    all_bbox_width = tf.exp(deltas[..., 3]) * all_pbox_width\n",
    "    all_bbox_height = tf.exp(deltas[..., 2]) * all_pbox_height\n",
    "    all_bbox_ctr_x = (deltas[..., 1] * all_pbox_width) + all_pbox_ctr_x\n",
    "    all_bbox_ctr_y = (deltas[..., 0] * all_pbox_height) + all_pbox_ctr_y\n",
    "\n",
    "    # Calculate coordinates of predicted bounding box\n",
    "    y1 = all_bbox_ctr_y - (0.5 * all_bbox_height)\n",
    "    x1 = all_bbox_ctr_x - (0.5 * all_bbox_width)\n",
    "    y2 = all_bbox_height + y1\n",
    "    x2 = all_bbox_width + x1\n",
    "\n",
    "    return tf.stack([y1, x1, y2, x2], axis=-1)\n",
    "\n",
    "def get_deltas_from_bboxes(bboxes, gt_boxes):\n",
    "    \"\"\"Calculating bounding box deltas for given bounding box and ground truth boxes.\n",
    "    inputs:\n",
    "        bboxes = (total_bboxes, [y1, x1, y2, x2])\n",
    "        gt_boxes = (batch_size, total_bboxes, [y1, x1, y2, x2])\n",
    "\n",
    "    outputs:\n",
    "        final_deltas = (batch_size, total_bboxes, [delta_y, delta_x, delta_h, delta_w])\n",
    "    \"\"\"\n",
    "    bbox_width = bboxes[..., 3] - bboxes[..., 1]\n",
    "    bbox_height = bboxes[..., 2] - bboxes[..., 0]\n",
    "    bbox_ctr_x = bboxes[..., 1] + 0.5 * bbox_width\n",
    "    bbox_ctr_y = bboxes[..., 0] + 0.5 * bbox_height\n",
    "\n",
    "    try:\n",
    "        gt_width = gt_boxes[..., 3] - gt_boxes[..., 1]\n",
    "        gt_height = gt_boxes[..., 2] - gt_boxes[..., 0]\n",
    "        gt_ctr_x = gt_boxes[..., 1] + 0.5 * gt_width\n",
    "        gt_ctr_y = gt_boxes[..., 0] + 0.5 * gt_height\n",
    "    except:\n",
    "        tf.print(gt_boxes)\n",
    "        tf.print(gt_boxes.shape)\n",
    "\n",
    "    # tf.where(condition, x, y) where values in x is replaced with y if false\n",
    "    bbox_width = tf.where(tf.equal(bbox_width, 0), 1e-3, bbox_width)\n",
    "    bbox_height = tf.where(tf.equal(bbox_height, 0), 1e-3, bbox_height)\n",
    "\n",
    "    delta_x = tf.where(tf.equal(gt_width, 0), tf.zeros_like(gt_width), tf.truediv((gt_ctr_x - bbox_ctr_x), bbox_width)) # 0 or offset/bbox_wdith\n",
    "    delta_y = tf.where(tf.equal(gt_height, 0), tf.zeros_like(gt_height), tf.truediv((gt_ctr_y - bbox_ctr_y), bbox_height))\n",
    "    delta_w = tf.where(tf.equal(gt_width, 0), tf.zeros_like(gt_width), tf.math.log(gt_width / bbox_width)) # 0 or ln(gt_width/bbox_width)\n",
    "    delta_h = tf.where(tf.equal(gt_height, 0), tf.zeros_like(gt_height), tf.math.log(gt_height / bbox_height))\n",
    "    return tf.stack([delta_y, delta_x, delta_h, delta_w], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6e39752",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:24:43.090474Z",
     "iopub.status.busy": "2024-03-08T08:24:43.090112Z",
     "iopub.status.idle": "2024-03-08T08:24:43.100058Z",
     "shell.execute_reply": "2024-03-08T08:24:43.099140Z"
    },
    "id": "FngGpkXMT8F1",
    "papermill": {
     "duration": 0.065914,
     "end_time": "2024-03-08T08:24:43.101945",
     "exception": false,
     "start_time": "2024-03-08T08:24:43.036031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def renormalize_bboxes_with_min_max(bboxes, min_max):\n",
    "    \"\"\"Renormalizing given bounding boxes to the new boundaries.\n",
    "    r = (x - min) / (max - min)\n",
    "    inputs:\n",
    "        bboxes = (total_bboxes, [y1, x1, y2, x2])\n",
    "        min_max = ([y_min, x_min, y_max, x_max])\n",
    "\n",
    "    outputs:\n",
    "        normalized_bboxes = (total_bboxes, [y1, x1, y2, x2])\n",
    "            in normalized form [0, 1]\n",
    "    \"\"\"\n",
    "    y_min, x_min, y_max, x_max = tf.split(min_max, 4)\n",
    "    renomalized_bboxes = bboxes - tf.concat([y_min, x_min, y_min, x_min], -1)\n",
    "    renomalized_bboxes /= tf.concat([y_max-y_min, x_max-x_min, y_max-y_min, x_max-x_min], -1)\n",
    "    return tf.clip_by_value(renomalized_bboxes, 0, 1)\n",
    "\n",
    "def normalize_bboxes(bboxes, height, width):\n",
    "    \"\"\"Normalizing bounding boxes.\n",
    "    inputs:\n",
    "        bboxes = (batch_size, total_bboxes, [y1, x1, y2, x2])\n",
    "        height = image height\n",
    "        width = image width\n",
    "\n",
    "    outputs:\n",
    "        normalized_bboxes = (batch_size, total_bboxes, [y1, x1, y2, x2])\n",
    "            in normalized form [0, 1]\n",
    "    \"\"\"\n",
    "    y1 = bboxes[..., 0] / height\n",
    "    x1 = bboxes[..., 1] / width\n",
    "    y2 = bboxes[..., 2] / height\n",
    "    x2 = bboxes[..., 3] / width\n",
    "    return tf.stack([y1, x1, y2, x2], axis=-1)\n",
    "\n",
    "def denormalize_bboxes(bboxes, height, width):\n",
    "    \"\"\"Denormalizing bounding boxes.\n",
    "    inputs:\n",
    "        bboxes = (batch_size, total_bboxes, [y1, x1, y2, x2])\n",
    "            in normalized form [0, 1]\n",
    "        height = image height\n",
    "        width = image width\n",
    "\n",
    "    outputs:\n",
    "        denormalized_bboxes = (batch_size, total_bboxes, [y1, x1, y2, x2])\n",
    "    \"\"\"\n",
    "    y1 = bboxes[..., 0] * height\n",
    "    x1 = bboxes[..., 1] * width\n",
    "    y2 = bboxes[..., 2] * height\n",
    "    x2 = bboxes[..., 3] * width\n",
    "    return tf.round(tf.stack([y1, x1, y2, x2], axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6367f870",
   "metadata": {
    "id": "hRkoKNc-F1Yw",
    "papermill": {
     "duration": 0.053536,
     "end_time": "2024-03-08T08:24:43.209771",
     "exception": false,
     "start_time": "2024-03-08T08:24:43.156235",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3131cc9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:24:43.317968Z",
     "iopub.status.busy": "2024-03-08T08:24:43.317525Z",
     "iopub.status.idle": "2024-03-08T08:24:43.333489Z",
     "shell.execute_reply": "2024-03-08T08:24:43.332597Z"
    },
    "id": "ambu0h84FoUV",
    "papermill": {
     "duration": 0.07301,
     "end_time": "2024-03-08T08:24:43.335521",
     "exception": false,
     "start_time": "2024-03-08T08:24:43.262511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def draw_grid_map(img, grid_map, stride):\n",
    "    \"\"\"Drawing grid intersection on given image.\n",
    "    inputs:\n",
    "        img = (height, width, channels)\n",
    "        grid_map = (output_height * output_width, [y_index, x_index, y_index, x_index])\n",
    "            tiled x, y coordinates\n",
    "        stride = number of stride\n",
    "\n",
    "    outputs:\n",
    "        array = (height, width, channels)\n",
    "    \"\"\"\n",
    "    image = Image.fromarray(img)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    counter = 0\n",
    "    for grid in grid_map:\n",
    "        draw.rectangle((\n",
    "            grid[0] + stride // 2 - 2,\n",
    "            grid[1] + stride // 2 - 2,\n",
    "            grid[2] + stride // 2 + 2,\n",
    "            grid[3] + stride // 2 + 2), fill=(255, 255, 255, 0))\n",
    "        counter += 1\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "def draw_bboxes(imgs, bboxes):\n",
    "    \"\"\"Drawing bounding boxes on given images.\n",
    "    inputs:\n",
    "        imgs = (batch_size, height, width, channels)\n",
    "        bboxes = (batch_size, total_bboxes, [y1, x1, y2, x2])\n",
    "            in normalized form [0, 1]\n",
    "    \"\"\"\n",
    "    colors = tf.constant([[1, 0, 0, 1]], dtype=tf.float32)\n",
    "    imgs_with_bb = tf.image.draw_bounding_boxes(imgs, bboxes, colors)\n",
    "    plt.figure()\n",
    "    for img_with_bb in imgs_with_bb:\n",
    "        plt.imshow(img_with_bb)\n",
    "        plt.show()\n",
    "\n",
    "def draw_bboxes_with_labels(img, bboxes, label_indices, probs, labels):\n",
    "    \"\"\"Drawing bounding boxes with labels on given image.\n",
    "    inputs:\n",
    "        img = (height, width, channels)\n",
    "        bboxes = (total_bboxes, [y1, x1, y2, x2])\n",
    "            in denormalized form\n",
    "        label_indices = (total_bboxes)\n",
    "        probs = (total_bboxes)\n",
    "        labels = [labels string list]\n",
    "    \"\"\"\n",
    "    colors = tf.random.uniform((len(labels), 4), maxval=256, dtype=tf.int32)\n",
    "    image = tf.keras.preprocessing.image.array_to_img(img)\n",
    "    width, height = image.size\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for index, bbox in enumerate(bboxes):\n",
    "        y1, x1, y2, x2 = tf.split(bbox, 4)\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "        if width <= 0 or height <= 0:\n",
    "            continue\n",
    "        label_index = int(label_indices[index])\n",
    "        color = tuple(colors[label_index].numpy())\n",
    "        label_text = \"{0} {1:0.3f}\".format(labels[label_index], probs[index])\n",
    "        draw.text((x1 + 4, y1 + 2), label_text, fill=color)\n",
    "        draw.rectangle((x1, y1, x2, y2), outline=color, width=3)\n",
    "    #\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "def draw_predictions(dataset, pred_bboxes, pred_labels, pred_scores, labels, batch_size):\n",
    "    for batch_id, image_data in enumerate(dataset):\n",
    "        imgs, _, _ = image_data\n",
    "        img_size = imgs.shape[1]\n",
    "        start = batch_id * batch_size\n",
    "        end = start + batch_size\n",
    "        batch_bboxes, batch_labels, batch_scores = pred_bboxes[start:end], pred_labels[start:end], pred_scores[start:end]\n",
    "        for i, img in enumerate(imgs):\n",
    "            denormalized_bboxes = denormalize_bboxes(batch_bboxes[i], img_size, img_size)\n",
    "            draw_bboxes_with_labels(img, denormalized_bboxes, batch_labels[i], batch_scores[i], labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04630874",
   "metadata": {
    "id": "rZPgvuNbGMN_",
    "papermill": {
     "duration": 0.051735,
     "end_time": "2024-03-08T08:24:43.440315",
     "exception": false,
     "start_time": "2024-03-08T08:24:43.388580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# io_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3c8aa59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:24:43.547275Z",
     "iopub.status.busy": "2024-03-08T08:24:43.546912Z",
     "iopub.status.idle": "2024-03-08T08:24:43.553553Z",
     "shell.execute_reply": "2024-03-08T08:24:43.552691Z"
    },
    "id": "u9QDiqrrGLm3",
    "papermill": {
     "duration": 0.062532,
     "end_time": "2024-03-08T08:24:43.555463",
     "exception": false,
     "start_time": "2024-03-08T08:24:43.492931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_log_path(model_type, custom_postfix=\"\"):\n",
    "    \"\"\"Generating log path from model_type value for tensorboard.\n",
    "    inputs:\n",
    "        model_type = \"mobilenet_v2\"\n",
    "        custom_postfix = any custom string for log folder name\n",
    "\n",
    "    outputs:\n",
    "        log_path = tensorboard log path, for example: \"logs/mobilenet_v2/{date}\"\n",
    "    \"\"\"\n",
    "    return \"logs/{}{}/{}\".format(model_type, custom_postfix, datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "def get_model_path(model_type):\n",
    "    \"\"\"Generating model path from model_type value for save/load model weights.\n",
    "    inputs:\n",
    "        model_type = \"vgg16\", \"mobilenet_v2\"\n",
    "\n",
    "    outputs:\n",
    "        model_path = os model path, for example: \"trained/ssd_vgg16_model_weights.h5\"\n",
    "    \"\"\"\n",
    "    main_path = \"trained\"\n",
    "    if not os.path.exists(main_path):\n",
    "        os.makedirs(main_path)\n",
    "    model_path = os.path.join(main_path, \"ssd_{}_model_weights.h5\".format(model_type))\n",
    "    return model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e0d396",
   "metadata": {
    "id": "odgPsWcyGRBW",
    "papermill": {
     "duration": 0.053291,
     "end_time": "2024-03-08T08:24:43.661633",
     "exception": false,
     "start_time": "2024-03-08T08:24:43.608342",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# train_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d1bf1cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:24:43.769115Z",
     "iopub.status.busy": "2024-03-08T08:24:43.768734Z",
     "iopub.status.idle": "2024-03-08T08:24:43.781886Z",
     "shell.execute_reply": "2024-03-08T08:24:43.780934Z"
    },
    "id": "NFs1NL6aGQkU",
    "papermill": {
     "duration": 0.069478,
     "end_time": "2024-03-08T08:24:43.783837",
     "exception": false,
     "start_time": "2024-03-08T08:24:43.714359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scheduler(epoch):\n",
    "    \"\"\"Generating learning rate value for a given epoch.\n",
    "    inputs:\n",
    "        epoch = number of current epoch\n",
    "\n",
    "    outputs:\n",
    "        learning_rate = float learning rate value\n",
    "    \"\"\"\n",
    "    if epoch <= 75:\n",
    "        return hyper_params[\"lr\"]\n",
    "    elif epoch <= 100:\n",
    "        return hyper_params[\"lr\"]*1e-1\n",
    "    else:\n",
    "        return hyper_params[\"lr\"]*1e-2\n",
    "\n",
    "def get_step_size(total_items, batch_size):\n",
    "    \"\"\"Get step size for given total item size and batch size.\n",
    "    inputs:\n",
    "        total_items = number of total items\n",
    "        batch_size = number of batch size during training or validation\n",
    "\n",
    "    outputs:\n",
    "        step_size = number of step size for model training\n",
    "    \"\"\"\n",
    "    return math.ceil(total_items / batch_size)\n",
    "\n",
    "def calculate_actual_outputs(prior_boxes, gt_boxes, gt_labels, hyper_params):\n",
    "    \"\"\"Calculate ssd actual output values.\n",
    "    Batch operations supported.\n",
    "    inputs:\n",
    "        prior_boxes = (total_prior_boxes, [y1, x1, y2, x2])\n",
    "            these values in normalized format between [0, 1]\n",
    "        gt_boxes (batch_size, gt_box_size, [y1, x1, y2, x2])\n",
    "            these values in normalized format between [0, 1]\n",
    "        gt_labels (batch_size, gt_box_size)\n",
    "        hyper_params = dictionary\n",
    "\n",
    "    outputs:\n",
    "        bbox_deltas = (batch_size, total_bboxes, [delta_y, delta_x, delta_h, delta_w])\n",
    "        bbox_labels = (batch_size, total_bboxes, [0,0,...,0])\n",
    "            labels are one-hot encoded\n",
    "    \"\"\"\n",
    "    batch_size = tf.shape(gt_boxes)[0]\n",
    "    total_labels = hyper_params[\"total_labels\"]\n",
    "    iou_threshold = hyper_params[\"iou_threshold\"]\n",
    "    variances = hyper_params[\"variances\"]\n",
    "    # Number of default bbox\n",
    "    total_prior_boxes = prior_boxes.shape[0]\n",
    "    # Calculate iou values between each bboxes and ground truth boxes\n",
    "    iou_map = generate_iou_map(prior_boxes, gt_boxes)\n",
    "    # Get max index value for each row\n",
    "    max_indices_each_gt_box = tf.argmax(iou_map, axis=2, output_type=tf.int32)\n",
    "    # IoU map has iou values for every gt boxes and we merge these values column wise\n",
    "    merged_iou_map = tf.reduce_max(iou_map, axis=2)\n",
    "\n",
    "    pos_cond = tf.greater(merged_iou_map, iou_threshold)\n",
    "    gt_boxes_map = tf.gather(gt_boxes, max_indices_each_gt_box, batch_dims=1)\n",
    "    expanded_gt_boxes = tf.where(tf.expand_dims(pos_cond, -1), gt_boxes_map, tf.zeros_like(gt_boxes_map))\n",
    "    bbox_deltas = get_deltas_from_bboxes(prior_boxes, expanded_gt_boxes) / variances\n",
    "\n",
    "    gt_labels_map = tf.gather(gt_labels, max_indices_each_gt_box, batch_dims=1)\n",
    "    expanded_gt_labels = tf.where(pos_cond, gt_labels_map, tf.zeros_like(gt_labels_map))\n",
    "    bbox_labels = tf.one_hot(expanded_gt_labels, total_labels)\n",
    "    return bbox_deltas, bbox_labels\n",
    "\n",
    "\n",
    "def generator(dataset, prior_boxes, hyper_params):\n",
    "    \"\"\"Tensorflow data generator for fit method, yielding inputs and outputs.\n",
    "    inputs:\n",
    "        dataset = tf.data.Dataset, PaddedBatchDataset\n",
    "        prior_boxes = (total_prior_boxes, [y1, x1, y2, x2])\n",
    "            these values in normalized format between [0, 1]\n",
    "        hyper_params = dictionary\n",
    "\n",
    "    outputs:\n",
    "        yield inputs, outputs\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            for image_data in dataset:\n",
    "                img, gt_boxes, gt_labels = image_data\n",
    "                # Calculate outputs for training\n",
    "                actual_deltas, actual_labels = calculate_actual_outputs(prior_boxes, gt_boxes, gt_labels, hyper_params)\n",
    "                yield img, (actual_deltas, actual_labels)\n",
    "        except StopIteration:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42503e5",
   "metadata": {
    "id": "KZ9rhI9ZGEKQ",
    "papermill": {
     "duration": 0.053232,
     "end_time": "2024-03-08T08:24:43.890777",
     "exception": false,
     "start_time": "2024-03-08T08:24:43.837545",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# eval_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21d52432",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:24:44.000199Z",
     "iopub.status.busy": "2024-03-08T08:24:43.999827Z",
     "iopub.status.idle": "2024-03-08T08:24:44.019902Z",
     "shell.execute_reply": "2024-03-08T08:24:44.019144Z"
    },
    "id": "GIG-uml-F27J",
    "papermill": {
     "duration": 0.077323,
     "end_time": "2024-03-08T08:24:44.021666",
     "exception": false,
     "start_time": "2024-03-08T08:24:43.944343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_stats(labels):\n",
    "    \"\"\"Initialise statistics used in evaluation.\n",
    "    inputs:\n",
    "        labels (list)\n",
    "\n",
    "    outputs:\n",
    "        stats (dict)\n",
    "    \"\"\"\n",
    "    stats = {}\n",
    "    for i, label in enumerate(labels):\n",
    "        if i == 0: # first element is bg\n",
    "            continue\n",
    "        stats[i] = {\n",
    "            \"label\": label,\n",
    "            \"total\": 0,\n",
    "            \"tp\": [],\n",
    "            \"fp\": [],\n",
    "            \"scores\": [],\n",
    "        }\n",
    "    return stats\n",
    "\n",
    "def update_stats(pred_bboxes, pred_labels, pred_scores, gt_boxes, gt_labels, stats):\n",
    "    # Calculate iou values between predicted bboxes and ground truth boxes\n",
    "    iou_map = generate_iou_map(pred_bboxes, gt_boxes)\n",
    "    merged_iou_map = tf.reduce_max(iou_map, axis=-1)\n",
    "    max_indices_each_gt = tf.argmax(iou_map, axis=-1, output_type=tf.int32)\n",
    "    sorted_ids = tf.argsort(merged_iou_map, direction=\"DESCENDING\")\n",
    "\n",
    "    count_holder = tf.unique_with_counts(tf.reshape(gt_labels, (-1,)))\n",
    "    for i, gt_label in enumerate(count_holder[0]):\n",
    "        if gt_label == -1:\n",
    "            continue\n",
    "        gt_label = int(gt_label)\n",
    "        stats[gt_label][\"total\"] += int(count_holder[2][i])\n",
    "    for batch_id, m in enumerate(merged_iou_map):\n",
    "        true_labels = []\n",
    "        for i, sorted_id in enumerate(sorted_ids[batch_id]):\n",
    "            pred_label = pred_labels[batch_id, sorted_id]\n",
    "            if pred_label == 0:\n",
    "                continue\n",
    "\n",
    "            iou = merged_iou_map[batch_id, sorted_id]\n",
    "            gt_id = max_indices_each_gt[batch_id, sorted_id]\n",
    "            gt_label = int(gt_labels[batch_id, gt_id])\n",
    "            pred_label = int(pred_label)\n",
    "            score = pred_scores[batch_id, sorted_id]\n",
    "            stats[pred_label][\"scores\"].append(score)\n",
    "            stats[pred_label][\"tp\"].append(0)\n",
    "            stats[pred_label][\"fp\"].append(0)\n",
    "            if iou >= 0.5 and pred_label == gt_label and gt_id not in true_labels:\n",
    "                stats[pred_label][\"tp\"][-1] = 1\n",
    "                true_labels.append(gt_id)\n",
    "            else:\n",
    "                stats[pred_label][\"fp\"][-1] = 1\n",
    "    return stats\n",
    "\n",
    "def calculate_ap(recall, precision):\n",
    "    \"\"\"Calculate Average Precision (AP).\n",
    "    \"\"\"\n",
    "    ap = 0\n",
    "    for r in np.arange(0, 1.1, 0.1):\n",
    "        prec_rec = precision[recall >= r]\n",
    "        if len(prec_rec) > 0:\n",
    "            ap += np.amax(prec_rec)\n",
    "    # By definition AP = sum(max(precision whose recall is above r))/11\n",
    "    ap /= 11\n",
    "    return ap\n",
    "\n",
    "def calculate_mAP(stats):\n",
    "    aps = []\n",
    "    for label in stats:\n",
    "        label_stats = stats[label]\n",
    "        tp = np.array(label_stats[\"tp\"])\n",
    "        fp = np.array(label_stats[\"fp\"])\n",
    "        scores = np.array(label_stats[\"scores\"])\n",
    "        ids = np.argsort(-scores)\n",
    "        total = label_stats[\"total\"]\n",
    "        accumulated_tp = np.cumsum(tp[ids])\n",
    "        accumulated_fp = np.cumsum(fp[ids])\n",
    "        recall = accumulated_tp / total\n",
    "        precision = accumulated_tp / (accumulated_fp + accumulated_tp)\n",
    "        ap = calculate_ap(recall, precision)\n",
    "        stats[label][\"recall\"] = recall\n",
    "        stats[label][\"precision\"] = precision\n",
    "        stats[label][\"AP\"] = ap\n",
    "        aps.append(ap)\n",
    "    mAP = np.mean(aps)\n",
    "    return stats, mAP\n",
    "\n",
    "def evaluate_predictions(dataset, pred_bboxes, pred_labels, pred_scores, labels, batch_size):\n",
    "    stats = init_stats(labels)\n",
    "    for batch_id, image_data in enumerate(dataset):\n",
    "        imgs, gt_boxes, gt_labels = image_data\n",
    "        # try:\n",
    "        #     imgs, gt_boxes, gt_labels = image_data\n",
    "        # except:\n",
    "        #     imgs, gt_boxes, gt_labels = image_data[0], image_data[1][0], image_data[1][1]\n",
    "        start = batch_id * batch_size\n",
    "        end = start + batch_size\n",
    "        batch_bboxes, batch_labels, batch_scores = pred_bboxes[start:end], pred_labels[start:end], pred_scores[start:end]\n",
    "        stats = update_stats(batch_bboxes, batch_labels, batch_scores, gt_boxes, gt_labels, stats)\n",
    "    stats, mAP = calculate_mAP(stats)\n",
    "    print(\"mAP: {}\".format(float(mAP)))\n",
    "    return stats, mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7889d6a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:24:44.130822Z",
     "iopub.status.busy": "2024-03-08T08:24:44.130428Z",
     "iopub.status.idle": "2024-03-08T08:24:44.143267Z",
     "shell.execute_reply": "2024-03-08T08:24:44.142391Z"
    },
    "id": "T2QH8nntIUUq",
    "papermill": {
     "duration": 0.06925,
     "end_time": "2024-03-08T08:24:44.145101",
     "exception": false,
     "start_time": "2024-03-08T08:24:44.075851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MeanAveragePrecisionCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"Calculate Mean Average Precision (mAP) at the end of every epoch.\n",
    "    Early stop and saves model with best mAP.\n",
    "    \"\"\"\n",
    "    def __init__(self, val_data, val_steps, labels, prior_boxes, hyper_params, batch_size, patience, model_save_path, **kwargs):\n",
    "        super(MeanAveragePrecisionCallback, self).__init__(**kwargs)\n",
    "        self.val_data = val_data\n",
    "        self.val_steps = val_steps\n",
    "        self.labels = labels\n",
    "        self.prior_boxes = prior_boxes\n",
    "        self.hyper_params = hyper_params\n",
    "        self.batch_size = batch_size\n",
    "        self.best_mAP = 0.0\n",
    "        self.mAP_values = []  # To store mAP values at each epoch\n",
    "        self.patience = patience\n",
    "        self.wait = 0\n",
    "        self.model_save_path = model_save_path\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        ssd_decoder_model = get_decoder_model(self.model, self.prior_boxes, self.hyper_params)\n",
    "        pred_bboxes, pred_labels, pred_scores = ssd_decoder_model.predict(self.val_data, steps=self.val_steps, verbose=1)\n",
    "        stats, mAP = evaluate_predictions(self.val_data, pred_bboxes, pred_labels, pred_scores, self.labels, self.batch_size)\n",
    "        self.mAP_values.append(mAP)\n",
    "\n",
    "        if mAP > self.best_mAP:\n",
    "            self.wait = 0\n",
    "            self.best_mAP = mAP\n",
    "            self.model.save_weights(self.model_save_path)\n",
    "        else:\n",
    "            self.wait += 1\n",
    "\n",
    "        if self.wait >= self.patience:\n",
    "            print(f\"Early stopping at epoch {epoch + 1} due to lack of improvement.\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "    def on_train_begin(self, epoch, logs=None):\n",
    "        self.best_mAP = 0.0\n",
    "        self.wait = 0\n",
    "        self.mAP_values = []\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        print(f'\\nBest Mean Average Precision: {self.best_mAP}\\n')\n",
    "\n",
    "    def get_mAP_values(self):\n",
    "        return self.mAP_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0471f0b",
   "metadata": {
    "id": "BnvrtbMJGcah",
    "papermill": {
     "duration": 0.053782,
     "end_time": "2024-03-08T08:24:44.251965",
     "exception": false,
     "start_time": "2024-03-08T08:24:44.198183",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c9644b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:24:44.358959Z",
     "iopub.status.busy": "2024-03-08T08:24:44.358554Z",
     "iopub.status.idle": "2024-03-08T08:24:44.371637Z",
     "shell.execute_reply": "2024-03-08T08:24:44.370712Z"
    },
    "id": "eLt0sLKBGYj-",
    "papermill": {
     "duration": 0.069396,
     "end_time": "2024-03-08T08:24:44.373590",
     "exception": false,
     "start_time": "2024-03-08T08:24:44.304194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, Input, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "class SSDDecoder(Layer):\n",
    "    \"\"\"Generating bounding boxes and labels from ssd predictions.\n",
    "    First calculating the boxes from predicted deltas and label probs.\n",
    "    Then applied non max suppression and selecting top_n boxes by scores.\n",
    "    inputs:\n",
    "        pred_deltas = (batch_size, total_prior_boxes, [delta_y, delta_x, delta_h, delta_w])\n",
    "        pred_label_probs = (batch_size, total_prior_boxes, [0,0,...,0])\n",
    "    outputs:\n",
    "        pred_bboxes = (batch_size, top_n, [y1, x1, y2, x2])\n",
    "        pred_labels = (batch_size, top_n)\n",
    "            1 to total label number\n",
    "        pred_scores = (batch_size, top_n)\n",
    "    \"\"\"\n",
    "    def __init__(self, prior_boxes, variances, max_total_size=200, score_threshold=0.5, **kwargs):\n",
    "        super(SSDDecoder, self).__init__(**kwargs)\n",
    "        self.prior_boxes = prior_boxes\n",
    "        self.variances = variances\n",
    "        self.max_total_size = max_total_size\n",
    "        self.score_threshold = score_threshold\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(SSDDecoder, self).get_config()\n",
    "        config.update({\n",
    "            \"prior_boxes\": self.prior_boxes.numpy(),\n",
    "            \"variances\": self.variances,\n",
    "            \"max_total_size\": self.max_total_size,\n",
    "            \"score_threshold\": self.score_threshold\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs):\n",
    "        pred_deltas = inputs[0]\n",
    "        pred_label_probs = inputs[1]\n",
    "        batch_size = tf.shape(pred_deltas)[0]\n",
    "\n",
    "        pred_deltas *= self.variances\n",
    "        pred_bboxes = get_bboxes_from_deltas(self.prior_boxes, pred_deltas)\n",
    "\n",
    "        pred_labels_map = tf.expand_dims(tf.argmax(pred_label_probs, -1), -1)\n",
    "        pred_labels = tf.where(tf.not_equal(pred_labels_map, 0), pred_label_probs, tf.zeros_like(pred_label_probs))\n",
    "        # Reshape bboxes for non max suppression\n",
    "        pred_bboxes = tf.reshape(pred_bboxes, (batch_size, -1, 1, 4))\n",
    "\n",
    "        final_bboxes, final_scores, final_labels, _ = non_max_suppression(\n",
    "                                                                    pred_bboxes, pred_labels,\n",
    "                                                                    max_output_size_per_class=self.max_total_size,\n",
    "                                                                    max_total_size=self.max_total_size,\n",
    "                                                                    score_threshold=self.score_threshold)\n",
    "        return final_bboxes, final_labels, final_scores\n",
    "\n",
    "def get_decoder_model(base_model, prior_boxes, hyper_params):\n",
    "    \"\"\"Decoding ssd predictions to valid bounding boxes and labels.\n",
    "    inputs:\n",
    "        base_model = tf.keras.model, base ssd model\n",
    "        prior_boxes = (total_prior_boxes, [y1, x1, y2, x2])\n",
    "            these values in normalized format between [0, 1]\n",
    "        hyper_params = dictionary\n",
    "\n",
    "    outputs:\n",
    "        ssd_decoder_model = tf.keras.model\n",
    "    \"\"\"\n",
    "    bboxes, classes, scores = SSDDecoder(prior_boxes, hyper_params[\"variances\"])(base_model.output)\n",
    "    return Model(inputs=base_model.input, outputs=[bboxes, classes, scores])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e7b03d",
   "metadata": {
    "id": "mEFNZpWUGoyx",
    "papermill": {
     "duration": 0.052684,
     "end_time": "2024-03-08T08:24:44.479957",
     "exception": false,
     "start_time": "2024-03-08T08:24:44.427273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbc1d8ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:24:44.587351Z",
     "iopub.status.busy": "2024-03-08T08:24:44.586969Z",
     "iopub.status.idle": "2024-03-08T08:24:44.599982Z",
     "shell.execute_reply": "2024-03-08T08:24:44.599134Z"
    },
    "id": "c0N10FKZGnBk",
    "papermill": {
     "duration": 0.068601,
     "end_time": "2024-03-08T08:24:44.601790",
     "exception": false,
     "start_time": "2024-03-08T08:24:44.533189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, Input, Conv2D, MaxPool2D, Activation\n",
    "\n",
    "class HeadWrapper(Layer):\n",
    "    \"\"\"Merging all feature maps for detections.\n",
    "    inputs:\n",
    "        conv4_3 = (batch_size, (layer_shape x aspect_ratios), last_dimension)\n",
    "            ssd300 conv4_3 shape => (38 x 38 x 4) = 5776\n",
    "        conv7 = (batch_size, (layer_shape x aspect_ratios), last_dimension)\n",
    "            ssd300 conv7 shape => (19 x 19 x 6) = 2166\n",
    "        conv8_2 = (batch_size, (layer_shape x aspect_ratios), last_dimension)\n",
    "            ssd300 conv8_2 shape => (10 x 10 x 6) = 600\n",
    "        conv9_2 = (batch_size, (layer_shape x aspect_ratios), last_dimension)\n",
    "            ssd300 conv9_2 shape => (5 x 5 x 6) = 150\n",
    "        conv10_2 = (batch_size, (layer_shape x aspect_ratios), last_dimension)\n",
    "            ssd300 conv10_2 shape => (3 x 3 x 4) = 36\n",
    "        conv11_2 = (batch_size, (layer_shape x aspect_ratios), last_dimension)\n",
    "            ssd300 conv11_2 shape => (1 x 1 x 4) = 4\n",
    "                                           Total = 8732 default box\n",
    "\n",
    "    outputs:\n",
    "        merged_head = (batch_size, total_prior_boxes, last_dimension)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, last_dimension, **kwargs):\n",
    "        super(HeadWrapper, self).__init__(**kwargs)\n",
    "        self.last_dimension = last_dimension\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(HeadWrapper, self).get_config()\n",
    "        config.update({\"last_dimension\": self.last_dimension})\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs):\n",
    "        last_dimension = self.last_dimension\n",
    "        batch_size = tf.shape(inputs[0])[0]\n",
    "        outputs = []\n",
    "        for conv_layer in inputs:\n",
    "            outputs.append(tf.reshape(conv_layer, (batch_size, -1, last_dimension)))\n",
    "        return tf.concat(outputs, axis=1)\n",
    "\n",
    "def get_head_from_outputs(hyper_params, outputs):\n",
    "    \"\"\"Generating ssd bbox delta and label heads.\n",
    "    inputs:\n",
    "        hyper_params = dictionary\n",
    "        outputs = list of ssd layers output to be used for prediction\n",
    "\n",
    "    outputs:\n",
    "        pred_deltas = merged outputs for bbox delta head\n",
    "        pred_labels = merged outputs for bbox label head\n",
    "    \"\"\"\n",
    "    total_labels = hyper_params[\"total_labels\"]\n",
    "    # +1 for ratio 1\n",
    "    len_aspect_ratios = [len(x) + 1 for x in hyper_params[\"aspect_ratios\"]]\n",
    "    # print(len_aspect_ratios)\n",
    "    labels_head = []\n",
    "    boxes_head = []\n",
    "    for i, output in enumerate(outputs):\n",
    "        # print(i)\n",
    "        aspect_ratio = len_aspect_ratios[i]\n",
    "        labels_head.append(Conv2D(aspect_ratio * total_labels, (3, 3), padding=\"same\", name=\"{}_conv_label_output\".format(i+1))(output))\n",
    "        boxes_head.append(Conv2D(aspect_ratio * 4, (3, 3), padding=\"same\", name=\"{}_conv_boxes_output\".format(i+1))(output))\n",
    "\n",
    "    pred_labels = HeadWrapper(total_labels, name=\"labels_head\")(labels_head)\n",
    "    pred_labels = Activation(\"softmax\", name=\"conf\")(pred_labels)\n",
    "\n",
    "    pred_deltas = HeadWrapper(4, name=\"loc\")(boxes_head)\n",
    "    return pred_deltas, pred_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838f6f35",
   "metadata": {
    "id": "gJANTXL-HBrD",
    "papermill": {
     "duration": 0.051961,
     "end_time": "2024-03-08T08:24:44.709311",
     "exception": false,
     "start_time": "2024-03-08T08:24:44.657350",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16af240",
   "metadata": {
    "id": "FaalWXrEH4PN",
    "papermill": {
     "duration": 0.052266,
     "end_time": "2024-03-08T08:24:44.814786",
     "exception": false,
     "start_time": "2024-03-08T08:24:44.762520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ssd_loss: cross-entropy/focal and huber loss\n",
    "\n",
    "Focal loss for classification task and Huber loss for regression task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a095eda5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:24:44.923213Z",
     "iopub.status.busy": "2024-03-08T08:24:44.922878Z",
     "iopub.status.idle": "2024-03-08T08:24:44.941014Z",
     "shell.execute_reply": "2024-03-08T08:24:44.940050Z"
    },
    "id": "no7DmauDH51C",
    "papermill": {
     "duration": 0.075615,
     "end_time": "2024-03-08T08:24:44.942997",
     "exception": false,
     "start_time": "2024-03-08T08:24:44.867382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomLoss(object):\n",
    "    \"\"\"Composition of Focal and Huber losses.\"\"\"\n",
    "\n",
    "    def __init__(self, neg_pos_ratio, loc_loss_alpha,\n",
    "                 alpha,\n",
    "                 gamma,\n",
    "                 use_focal=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            neg_pos_ratio: a float number representing the negative to positive ratio.\n",
    "            loc_loss_alpha: a float number representing the localization loss.\n",
    "            alpha, gamma: a float number for Focal loss formula.\n",
    "        \"\"\"\n",
    "        self.neg_pos_ratio = tf.constant(neg_pos_ratio, dtype=tf.float32)\n",
    "        self.loc_loss_alpha = tf.constant(loc_loss_alpha, dtype=tf.float32)\n",
    "        self.alpha = tf.constant(alpha, dtype=tf.float32)\n",
    "        self.gamma = tf.constant(gamma, dtype=tf.float32)\n",
    "        self.use_focal = use_focal\n",
    "\n",
    "    def loc_loss_fn(self, actual_deltas, pred_deltas):\n",
    "        \"\"\"Calculating SSD localization loss value for only positive samples.\n",
    "        inputs:\n",
    "            actual_deltas = (batch_size, total_prior_boxes, [delta_y, delta_x, delta_h, delta_w])\n",
    "            pred_deltas = (batch_size, total_prior_boxes, [delta_y, delta_x, delta_h, delta_w])\n",
    "\n",
    "        outputs:\n",
    "            loc_loss = localization / bbox / regression loss value\n",
    "        \"\"\"\n",
    "        # Localization / bbox / regression loss calculation for all bboxes\n",
    "        loc_loss_fn = tf.losses.Huber(reduction=tf.losses.Reduction.NONE) # delta=1.0\n",
    "        loc_loss_for_all = loc_loss_fn(actual_deltas, pred_deltas)\n",
    "\n",
    "        # After tf 2.2.0 version, the huber calculates mean over the last axis\n",
    "        loc_loss_for_all = tf.cond(tf.greater(tf.rank(loc_loss_for_all), tf.constant(2)),\n",
    "                                   lambda: tf.reduce_sum(loc_loss_for_all, axis=-1),\n",
    "                                   lambda: loc_loss_for_all * tf.cast(tf.shape(pred_deltas)[-1], dtype=tf.float32))\n",
    "\n",
    "        # Creating Positive Mask\n",
    "        pos_cond = tf.reduce_any(tf.not_equal(actual_deltas, tf.constant(0.0)), axis=2)\n",
    "        pos_mask = tf.cast(pos_cond, dtype=tf.float32)\n",
    "        # Counting Total Positive Bounding Boxes\n",
    "        total_pos_bboxes = tf.reduce_sum(pos_mask, axis=1)\n",
    "\n",
    "        # Calculating Localization Loss for Positive Bounding Boxes\n",
    "        loc_loss = tf.reduce_sum(pos_mask * loc_loss_for_all, axis=-1)\n",
    "        # Handling Cases with No Positive Bounding Boxes\n",
    "        total_pos_bboxes = tf.where(tf.equal(total_pos_bboxes, tf.constant(0.0)), tf.constant(1.0), total_pos_bboxes)\n",
    "        # Final Localization Loss Calculation\n",
    "        loc_loss = loc_loss / total_pos_bboxes\n",
    "        return loc_loss * self.loc_loss_alpha\n",
    "\n",
    "    def conf_loss_fn(self, actual_labels, pred_labels):\n",
    "        \"\"\"Calculating SSD confidence loss value with hard negative mining as mentioned in the paper.\n",
    "        Replaced CategoricalCrossentropy with CategoricalFocalCrossentropy.\n",
    "        inputs:\n",
    "            actual_labels = (batch_size, total_prior_boxes, total_labels)\n",
    "            pred_labels = (batch_size, total_prior_boxes, total_labels)\n",
    "\n",
    "        outputs:\n",
    "            conf_loss = confidence / class / label loss value\n",
    "        \"\"\"\n",
    "        # tf.print(actual_labels) # one-hot\n",
    "        # tf.print(pred_labels) # float32\n",
    "\n",
    "        # Confidence / Label loss calculation for all labels\n",
    "        if self.use_focal:\n",
    "            conf_loss_fn = tf.keras.losses.CategoricalFocalCrossentropy(alpha=self.alpha, gamma=self.gamma, reduction=tf.losses.Reduction.NONE)\n",
    "            conf_loss_for_all = conf_loss_fn(actual_labels, pred_labels)\n",
    "            # tf.print(\"Confidence Loss:\", conf_loss_for_all)\n",
    "        else:\n",
    "            conf_loss_fn = tf.losses.CategoricalCrossentropy(reduction=tf.losses.Reduction.NONE)\n",
    "            conf_loss_for_all = conf_loss_fn(actual_labels, pred_labels)\n",
    "            # tf.print(\"Confidence Loss:\", conf_loss_for_all)\n",
    "\n",
    "        # Creating Positive Mask for non-background class\n",
    "        pos_cond = tf.reduce_any(tf.not_equal(actual_labels[..., 1:], tf.constant(0.0)), axis=2)\n",
    "        pos_mask = tf.cast(pos_cond, dtype=tf.float32)\n",
    "        # Counting Total Positive Bounding Boxes\n",
    "        total_pos_bboxes = tf.reduce_sum(pos_mask, axis=1)\n",
    "\n",
    "        # Hard negative mining\n",
    "        total_neg_bboxes = tf.cast(total_pos_bboxes * self.neg_pos_ratio, tf.int32)\n",
    "\n",
    "        masked_loss = conf_loss_for_all * actual_labels[..., 0]\n",
    "        sorted_loss = tf.argsort(masked_loss, direction=\"DESCENDING\")\n",
    "        sorted_loss = tf.argsort(sorted_loss)\n",
    "        neg_cond = tf.less(sorted_loss, tf.expand_dims(total_neg_bboxes, axis=1))\n",
    "        neg_mask = tf.cast(neg_cond, dtype=tf.float32)\n",
    "\n",
    "        final_mask = pos_mask + neg_mask\n",
    "        conf_loss = tf.reduce_sum(final_mask * conf_loss_for_all, axis=-1)\n",
    "        total_pos_bboxes = tf.where(tf.equal(total_pos_bboxes, tf.constant(0.0)), tf.constant(1.0), total_pos_bboxes)\n",
    "        conf_loss = conf_loss / total_pos_bboxes\n",
    "\n",
    "        return conf_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e36f3a",
   "metadata": {
    "id": "qpEJH16WFrWQ",
    "papermill": {
     "duration": 0.054222,
     "end_time": "2024-03-08T08:24:45.051999",
     "exception": false,
     "start_time": "2024-03-08T08:24:44.997777",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78af543c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:24:45.162209Z",
     "iopub.status.busy": "2024-03-08T08:24:45.161871Z",
     "iopub.status.idle": "2024-03-08T08:24:45.187772Z",
     "shell.execute_reply": "2024-03-08T08:24:45.186915Z"
    },
    "id": "1RSbUDlZFp-4",
    "papermill": {
     "duration": 0.08418,
     "end_time": "2024-03-08T08:24:45.189651",
     "exception": false,
     "start_time": "2024-03-08T08:24:45.105471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessing(image_data, final_height, final_width, augmentation_fn=None, evaluate=False):\n",
    "    \"\"\"Image resizing operation handled before batch operations.\n",
    "    inputs:\n",
    "        image_data = tensorflow dataset image_data\n",
    "        final_height = final image height after resizing\n",
    "        final_width = final image width after resizing\n",
    "\n",
    "    outputs:\n",
    "        img = (final_height, final_width, channels)\n",
    "        gt_boxes = (gt_box_size, [y1, x1, y2, x2])\n",
    "        gt_labels = (gt_box_size)\n",
    "    \"\"\"\n",
    "    img = image_data[\"image\"]\n",
    "    gt_boxes = image_data[\"objects\"][\"bbox\"]\n",
    "    gt_labels = tf.cast(image_data[\"objects\"][\"label\"] + 1, tf.int32)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(img, (final_height, final_width))\n",
    "    if evaluate:\n",
    "        not_diff = tf.logical_not(image_data[\"objects\"][\"is_difficult\"])\n",
    "        gt_boxes = gt_boxes[not_diff]\n",
    "        gt_labels = gt_labels[not_diff]\n",
    "    if augmentation_fn:\n",
    "        img, gt_boxes = augmentation_fn(img, gt_boxes)\n",
    "    return img, gt_boxes, gt_labels\n",
    "\n",
    "def tfr_preprocessing(image_data, final_height, final_width, augmentation_fn=None, evaluate=False):\n",
    "\n",
    "    img = image_data[\"image/encoded\"]\n",
    "    img = tf.io.decode_image(img, channels=3)\n",
    "    xmin = tf.sparse.to_dense(image_data['image/object/bbox/xmin'])\n",
    "    ymin = tf.sparse.to_dense(image_data['image/object/bbox/ymin'])\n",
    "    xmax = tf.sparse.to_dense(image_data['image/object/bbox/xmax'])\n",
    "    ymax = tf.sparse.to_dense(image_data['image/object/bbox/ymax'])\n",
    "    gt_boxes = tf.stack(\n",
    "        [ymin, xmin, ymax, xmax], axis=-1\n",
    "    )\n",
    "    gt_labels = tf.sparse.to_dense(image_data['image/object/class/label'])\n",
    "    # gt_labels +=1 # VOC has idx 0 but tfr does not\n",
    "    gt_labels = tf.cast(gt_labels, tf.int32)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img.set_shape([None,None,3])\n",
    "    img = tf.image.resize(img, (final_height, final_width))\n",
    "    if augmentation_fn:\n",
    "        img, gt_boxes = augmentation_fn(img, gt_boxes)\n",
    "\n",
    "    return img, gt_boxes, gt_labels\n",
    "\n",
    "def tfr_dataset(data_dir):\n",
    "\n",
    "    image_feature_description={\n",
    "      'image/encoded':tf.io.FixedLenFeature([],tf.string),\n",
    "      'image/object/bbox/xmin':tf.io.VarLenFeature(tf.float32),\n",
    "      'image/object/bbox/ymin':tf.io.VarLenFeature(tf.float32),\n",
    "      'image/object/bbox/xmax':tf.io.VarLenFeature(tf.float32),\n",
    "      'image/object/bbox/ymax':tf.io.VarLenFeature(tf.float32),\n",
    "      'image/object/class/label':tf.io.VarLenFeature(tf.int64),\n",
    "    }\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(filenames=data_dir)\n",
    "    count = 0\n",
    "    for record in dataset:\n",
    "        count += 1\n",
    "    parsed_dataset = dataset.map(lambda x: tf.io.parse_single_example(x, image_feature_description))\n",
    "\n",
    "    return parsed_dataset, count\n",
    "\n",
    "def get_dataset(name, split, data_dir=\"~/tensorflow_datasets\"):\n",
    "    \"\"\"Get tensorflow dataset split and info.\n",
    "    inputs:\n",
    "        name = name of the dataset, voc/2007, voc/2012, etc.\n",
    "        split = data split string, should be one of [\"train\", \"validation\", \"test\"]\n",
    "        data_dir = read/write path for tensorflow datasets\n",
    "\n",
    "    outputs:\n",
    "        dataset = tensorflow dataset split\n",
    "        info = tensorflow dataset info\n",
    "    \"\"\"\n",
    "    assert split in [\"train\", \"train+validation\", \"validation\", \"test\"]\n",
    "    dataset, info = tfds.load(name, split=split, data_dir=data_dir, with_info=True)\n",
    "    return dataset, info\n",
    "\n",
    "def get_total_item_size(info, split):\n",
    "    \"\"\"Get total item size for given split.\n",
    "    inputs:\n",
    "        info = tensorflow dataset info\n",
    "        split = data split string, should be one of [\"train\", \"validation\", \"test\"]\n",
    "\n",
    "    outputs:\n",
    "        total_item_size = number of total items\n",
    "    \"\"\"\n",
    "    assert split in [\"train\", \"train+validation\", \"validation\", \"test\"]\n",
    "    if split == \"train+validation\":\n",
    "        return info.splits[\"train\"].num_examples + info.splits[\"validation\"].num_examples\n",
    "    return info.splits[split].num_examples\n",
    "\n",
    "def tfr_labels(pbtxt_fname):\n",
    "\n",
    "    from object_detection.utils import label_map_util\n",
    "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
    "    categories = label_map_util.convert_label_map_to_categories(\n",
    "        label_map, max_num_classes=90, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "    print(categories)\n",
    "    labels = [item['name'] for item in categories]\n",
    "    return len(category_index.keys()), labels\n",
    "\n",
    "def get_labels(info):\n",
    "    \"\"\"Get label names list.\n",
    "    inputs:\n",
    "        info = tensorflow dataset info\n",
    "\n",
    "    outputs:\n",
    "        labels = [labels list]\n",
    "    \"\"\"\n",
    "    return info.features[\"labels\"].names\n",
    "\n",
    "def get_custom_imgs(custom_image_path):\n",
    "    \"\"\"Generating a list of images for given path.\n",
    "    inputs:\n",
    "        custom_image_path = folder of the custom images\n",
    "    outputs:\n",
    "        custom image list = [path1, path2]\n",
    "    \"\"\"\n",
    "    img_paths = []\n",
    "    for path, dir, filenames in os.walk(custom_image_path):\n",
    "        for filename in filenames:\n",
    "            img_paths.append(os.path.join(path, filename))\n",
    "        break\n",
    "    return img_paths\n",
    "\n",
    "def custom_data_generator(img_paths, final_height, final_width):\n",
    "    \"\"\"Yielding custom entities as dataset.\n",
    "    inputs:\n",
    "        img_paths = custom image paths\n",
    "        final_height = final image height after resizing\n",
    "        final_width = final image width after resizing\n",
    "    outputs:\n",
    "        img = (final_height, final_width, depth)\n",
    "        dummy_gt_boxes = (None, None)\n",
    "        dummy_gt_labels = (None, )\n",
    "    \"\"\"\n",
    "    for img_path in img_paths:\n",
    "        image = Image.open(img_path)\n",
    "        resized_image = image.resize((final_width, final_height), Image.LANCZOS)\n",
    "        img = np.array(resized_image)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "        yield img, tf.constant([[]], dtype=tf.float32), tf.constant([], dtype=tf.int32)\n",
    "\n",
    "def get_data_types():\n",
    "    \"\"\"Generating data types for tensorflow datasets.\n",
    "    outputs:\n",
    "        data types = output data types for (images, ground truth boxes, ground truth labels)\n",
    "    \"\"\"\n",
    "    return (tf.float32, tf.float32, tf.int32)\n",
    "\n",
    "def get_data_shapes():\n",
    "    \"\"\"Generating data shapes for tensorflow datasets.\n",
    "    outputs:\n",
    "        data shapes = output data shapes for (images, ground truth boxes, ground truth labels)\n",
    "    \"\"\"\n",
    "    return ([None, None, None], [None, None], [None,])\n",
    "\n",
    "def get_padding_values():\n",
    "    \"\"\"Generating padding values for missing values in batch for tensorflow datasets.\n",
    "    outputs:\n",
    "        padding values = padding values with dtypes for (images, ground truth boxes, ground truth labels)\n",
    "    \"\"\"\n",
    "    return (tf.constant(0, tf.float32), tf.constant(0, tf.float32), tf.constant(-1, tf.int32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204d23f5",
   "metadata": {
    "id": "amJ3m8RBjPU1",
    "papermill": {
     "duration": 0.052115,
     "end_time": "2024-03-08T08:24:45.295571",
     "exception": false,
     "start_time": "2024-03-08T08:24:45.243456",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# process Roboflow TFRecord\n",
    "\n",
    "\n",
    "As of now, this only accepts TFR directly from Roboflow with apply removed from preprocessing.\n",
    "\n",
    "Issue: use_image_if_no_bounding_boxes=True leads to missing prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8717a306",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:24:45.402613Z",
     "iopub.status.busy": "2024-03-08T08:24:45.402236Z",
     "iopub.status.idle": "2024-03-08T08:24:45.409849Z",
     "shell.execute_reply": "2024-03-08T08:24:45.408975Z"
    },
    "id": "Djg8OEQWCOxp",
    "papermill": {
     "duration": 0.063024,
     "end_time": "2024-03-08T08:24:45.411721",
     "exception": false,
     "start_time": "2024-03-08T08:24:45.348697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_for_nans(parsed_dataset, final_height, final_width):\n",
    "    for record in parsed_dataset:\n",
    "        img, gt_boxes, gt_labels = tfr_preprocessing(record, final_height, final_width)\n",
    "        gt_labels = tf.cast(gt_labels, tf.float32)\n",
    "\n",
    "        # Check for NaN values in the image tensor\n",
    "        img_has_nan = tf.reduce_any(tf.math.is_nan(img))\n",
    "\n",
    "        # Check for NaN values in the ground truth boxes tensor\n",
    "        gt_boxes_has_nan = tf.reduce_any(tf.math.is_nan(gt_boxes))\n",
    "\n",
    "        # Check for NaN values in the ground truth labels tensor\n",
    "        gt_labels_has_nan = tf.reduce_any(tf.math.is_nan(gt_labels))\n",
    "\n",
    "        # Print information if NaN values are found\n",
    "        if img_has_nan or gt_boxes_has_nan or gt_labels_has_nan:\n",
    "            print(\"NaN values found in the dataset!\")\n",
    "            print(\"Image has NaN values:\", img_has_nan.numpy())\n",
    "            print(\"Ground truth boxes have NaN values:\", gt_boxes_has_nan.numpy())\n",
    "            print(\"Ground truth labels have NaN values:\", gt_labels_has_nan.numpy())\n",
    "\n",
    "            # You can return or handle the information accordingly\n",
    "            return True\n",
    "\n",
    "    print(\"No NaN values found in the dataset.\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "895f13a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:24:45.521552Z",
     "iopub.status.busy": "2024-03-08T08:24:45.520717Z",
     "iopub.status.idle": "2024-03-08T08:24:46.541002Z",
     "shell.execute_reply": "2024-03-08T08:24:46.539912Z"
    },
    "id": "3uobVEH9Lidp",
    "outputId": "fe13c28a-4e54-43c7-b6ba-d6b343a8da6d",
    "papermill": {
     "duration": 1.07678,
     "end_time": "2024-03-08T08:24:46.543035",
     "exception": false,
     "start_time": "2024-03-08T08:24:45.466255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 1, 'name': 'Hole'}, {'id': 2, 'name': 'Knot'}, {'id': 3, 'name': 'Line'}, {'id': 4, 'name': 'Stain'}]\n",
      "5724 225\n",
      "4 ['bg', 'Hole', 'Knot', 'Line', 'Stain']\n",
      "([None, None, None], [None, None], [None]) (<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=int32, numpy=-1>)\n"
     ]
    }
   ],
   "source": [
    "# Train Parameters\n",
    "batch_size = hyper_params[\"batch_size\"]\n",
    "epochs = hyper_params[\"epochs\"]\n",
    "load_weights = False\n",
    "img_size = hyper_params[\"img_size\"] # determined by the backbone\n",
    "\n",
    "if hyper_params[\"dataset\"] == 0:\n",
    "    # dut\n",
    "    train_files='/kaggle/working/Fabric-Defect-Capstone-1/train/defects.tfrecord'\n",
    "    val_files='/kaggle/working/Fabric-Defect-Capstone-1/valid/defects.tfrecord'\n",
    "    test_files='/kaggle/working/Fabric-Defect-Capstone-1/test/defects.tfrecord'\n",
    "    num_classes, labels = tfr_labels('/kaggle/working/Fabric-Defect-Capstone-1/train/defects_label_map.pbtxt')\n",
    "elif hyper_params[\"dataset\"] == 1:\n",
    "    # tilda\n",
    "    train_files='/kaggle/working/TILDA-Fabric-2/train/Fabric.tfrecord'\n",
    "    val_files='/kaggle/working/TILDA-Fabric-2/valid/Fabric.tfrecord'\n",
    "    test_files='/kaggle/working/TILDA-Fabric-2/test/Fabric.tfrecord'\n",
    "    num_classes, labels = tfr_labels('//kaggle/working/TILDA-Fabric-2/train/Fabric_label_map.pbtxt')\n",
    "elif hyper_params[\"dataset\"] == 2:\n",
    "    # daffodil\n",
    "    train_files='/kaggle/working/Fabric-Defect-Daffodil-1/train/defects.tfrecord'\n",
    "    val_files='/kaggle/working/Fabric-Defect-Daffodil-1/valid/defects.tfrecord'\n",
    "    test_files='/kaggle/working/Fabric-Defect-Daffodil-1/test/defects.tfrecord'\n",
    "    num_classes, labels = tfr_labels('/kaggle/working/Fabric-Defect-Daffodil-1/train/defects_label_map.pbtxt')\n",
    "elif hyper_params[\"dataset\"] == 3:\n",
    "    # thesis\n",
    "    train_files='/kaggle/working/Fabric-Defect-Thesis-1/train/defects.tfrecord'\n",
    "    val_files='/kaggle/working/Fabric-Defect-Thesis-1/valid/defects.tfrecord'\n",
    "    test_files='/kaggle/working/Fabric-Defect-Thesis-1/test/defects.tfrecord'\n",
    "    num_classes, labels = tfr_labels('/kaggle/working/Fabric-Defect-Thesis-1/train/defects_label_map.pbtxt')\n",
    "elif hyper_params[\"dataset\"] == 4:\n",
    "    pass\n",
    "\n",
    "train_data, train_total_items = tfr_dataset(train_files)\n",
    "val_data, val_total_items = tfr_dataset(val_files)\n",
    "\n",
    "# check_for_nans(train_data, img_size, img_size)\n",
    "# check_for_nans(val_data, img_size, img_size)\n",
    "\n",
    "labels = [\"bg\"] + labels\n",
    "hyper_params[\"total_labels\"] = len(labels)\n",
    "print(train_total_items, val_total_items)\n",
    "print(num_classes, labels)\n",
    "\n",
    "train_data = train_data.map(lambda x : tfr_preprocessing(x, img_size, img_size))\n",
    "val_data = val_data.map(lambda x : tfr_preprocessing(x, img_size, img_size))\n",
    "\n",
    "data_shapes = get_data_shapes()\n",
    "padding_values = get_padding_values()\n",
    "print(data_shapes, padding_values)\n",
    "train_data = train_data.shuffle(batch_size*4).padded_batch(batch_size, padded_shapes=data_shapes, padding_values=padding_values)\n",
    "val_data = val_data.padded_batch(batch_size, padded_shapes=data_shapes, padding_values=padding_values)\n",
    "\n",
    "def transform(dataset):\n",
    "    autotune = tf.data.experimental.AUTOTUNE\n",
    "    dataset = dataset.apply(tf.data.experimental.ignore_errors())\n",
    "    dataset = dataset.repeat(epochs)\n",
    "    dataset = dataset.prefetch(autotune)\n",
    "    return dataset\n",
    "\n",
    "train_data = transform(train_data)\n",
    "\n",
    "ssd_train_feed = generator(train_data, prior_boxes, hyper_params)\n",
    "ssd_val_feed = generator(val_data, prior_boxes, hyper_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac4e97a",
   "metadata": {
    "id": "Nj-9WLjVHLhN",
    "papermill": {
     "duration": 0.054442,
     "end_time": "2024-03-08T08:24:46.651722",
     "exception": false,
     "start_time": "2024-03-08T08:24:46.597280",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d232d80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:24:46.761083Z",
     "iopub.status.busy": "2024-03-08T08:24:46.760319Z",
     "iopub.status.idle": "2024-03-08T08:24:53.358556Z",
     "shell.execute_reply": "2024-03-08T08:24:53.357503Z"
    },
    "id": "tootxTnvHA3t",
    "outputId": "405e64fe-a3f1-4472-e81e-ff22fd7eefcd",
    "papermill": {
     "duration": 6.794521,
     "end_time": "2024-03-08T08:24:53.500750",
     "exception": false,
     "start_time": "2024-03-08T08:24:46.706229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9406464/9406464 [==============================] - 1s 0us/step\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 640, 640, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)              (None, 320, 320, 32)         864       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalizati  (None, 320, 320, 32)         128       ['Conv1[0][0]']               \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)           (None, 320, 320, 32)         0         ['bn_Conv1[0][0]']            \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (D  (None, 320, 320, 32)         288       ['Conv1_relu[0][0]']          \n",
      " epthwiseConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN  (None, 320, 320, 32)         128       ['expanded_conv_depthwise[0][0\n",
      "  (BatchNormalization)                                              ]']                           \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_re  (None, 320, 320, 32)         0         ['expanded_conv_depthwise_BN[0\n",
      " lu (ReLU)                                                          ][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv_project (Con  (None, 320, 320, 16)         512       ['expanded_conv_depthwise_relu\n",
      " v2D)                                                               [0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (  (None, 320, 320, 16)         64        ['expanded_conv_project[0][0]'\n",
      " BatchNormalization)                                                ]                             \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)     (None, 320, 320, 96)         1536      ['expanded_conv_project_BN[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNo  (None, 320, 320, 96)         384       ['block_1_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)  (None, 320, 320, 96)         0         ['block_1_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D  (None, 321, 321, 96)         0         ['block_1_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_1_depthwise (Depthwi  (None, 160, 160, 96)         864       ['block_1_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (Batc  (None, 160, 160, 96)         384       ['block_1_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (Re  (None, 160, 160, 96)         0         ['block_1_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)    (None, 160, 160, 24)         2304      ['block_1_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchN  (None, 160, 160, 24)         96        ['block_1_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)     (None, 160, 160, 144)        3456      ['block_1_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNo  (None, 160, 160, 144)        576       ['block_2_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)  (None, 160, 160, 144)        0         ['block_2_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_depthwise (Depthwi  (None, 160, 160, 144)        1296      ['block_2_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (Batc  (None, 160, 160, 144)        576       ['block_2_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (Re  (None, 160, 160, 144)        0         ['block_2_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)    (None, 160, 160, 24)         3456      ['block_2_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchN  (None, 160, 160, 24)         96        ['block_2_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_2_add (Add)           (None, 160, 160, 24)         0         ['block_1_project_BN[0][0]',  \n",
      "                                                                     'block_2_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)     (None, 160, 160, 144)        3456      ['block_2_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNo  (None, 160, 160, 144)        576       ['block_3_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)  (None, 160, 160, 144)        0         ['block_3_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D  (None, 161, 161, 144)        0         ['block_3_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_3_depthwise (Depthwi  (None, 80, 80, 144)          1296      ['block_3_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (Batc  (None, 80, 80, 144)          576       ['block_3_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (Re  (None, 80, 80, 144)          0         ['block_3_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)    (None, 80, 80, 32)           4608      ['block_3_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchN  (None, 80, 80, 32)           128       ['block_3_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)     (None, 80, 80, 192)          6144      ['block_3_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNo  (None, 80, 80, 192)          768       ['block_4_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)  (None, 80, 80, 192)          0         ['block_4_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_depthwise (Depthwi  (None, 80, 80, 192)          1728      ['block_4_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (Batc  (None, 80, 80, 192)          768       ['block_4_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (Re  (None, 80, 80, 192)          0         ['block_4_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)    (None, 80, 80, 32)           6144      ['block_4_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchN  (None, 80, 80, 32)           128       ['block_4_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_4_add (Add)           (None, 80, 80, 32)           0         ['block_3_project_BN[0][0]',  \n",
      "                                                                     'block_4_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)     (None, 80, 80, 192)          6144      ['block_4_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNo  (None, 80, 80, 192)          768       ['block_5_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)  (None, 80, 80, 192)          0         ['block_5_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_depthwise (Depthwi  (None, 80, 80, 192)          1728      ['block_5_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (Batc  (None, 80, 80, 192)          768       ['block_5_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (Re  (None, 80, 80, 192)          0         ['block_5_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)    (None, 80, 80, 32)           6144      ['block_5_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchN  (None, 80, 80, 32)           128       ['block_5_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_5_add (Add)           (None, 80, 80, 32)           0         ['block_4_add[0][0]',         \n",
      "                                                                     'block_5_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)     (None, 80, 80, 192)          6144      ['block_5_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNo  (None, 80, 80, 192)          768       ['block_6_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)  (None, 80, 80, 192)          0         ['block_6_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D  (None, 81, 81, 192)          0         ['block_6_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_6_depthwise (Depthwi  (None, 40, 40, 192)          1728      ['block_6_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (Batc  (None, 40, 40, 192)          768       ['block_6_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (Re  (None, 40, 40, 192)          0         ['block_6_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)    (None, 40, 40, 64)           12288     ['block_6_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchN  (None, 40, 40, 64)           256       ['block_6_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)     (None, 40, 40, 384)          24576     ['block_6_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNo  (None, 40, 40, 384)          1536      ['block_7_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)  (None, 40, 40, 384)          0         ['block_7_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_depthwise (Depthwi  (None, 40, 40, 384)          3456      ['block_7_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (Batc  (None, 40, 40, 384)          1536      ['block_7_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (Re  (None, 40, 40, 384)          0         ['block_7_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)    (None, 40, 40, 64)           24576     ['block_7_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchN  (None, 40, 40, 64)           256       ['block_7_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_7_add (Add)           (None, 40, 40, 64)           0         ['block_6_project_BN[0][0]',  \n",
      "                                                                     'block_7_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)     (None, 40, 40, 384)          24576     ['block_7_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNo  (None, 40, 40, 384)          1536      ['block_8_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)  (None, 40, 40, 384)          0         ['block_8_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_depthwise (Depthwi  (None, 40, 40, 384)          3456      ['block_8_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (Batc  (None, 40, 40, 384)          1536      ['block_8_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (Re  (None, 40, 40, 384)          0         ['block_8_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)    (None, 40, 40, 64)           24576     ['block_8_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchN  (None, 40, 40, 64)           256       ['block_8_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_8_add (Add)           (None, 40, 40, 64)           0         ['block_7_add[0][0]',         \n",
      "                                                                     'block_8_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)     (None, 40, 40, 384)          24576     ['block_8_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNo  (None, 40, 40, 384)          1536      ['block_9_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)  (None, 40, 40, 384)          0         ['block_9_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_depthwise (Depthwi  (None, 40, 40, 384)          3456      ['block_9_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (Batc  (None, 40, 40, 384)          1536      ['block_9_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (Re  (None, 40, 40, 384)          0         ['block_9_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)    (None, 40, 40, 64)           24576     ['block_9_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchN  (None, 40, 40, 64)           256       ['block_9_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_9_add (Add)           (None, 40, 40, 64)           0         ['block_8_add[0][0]',         \n",
      "                                                                     'block_9_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)    (None, 40, 40, 384)          24576     ['block_9_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchN  (None, 40, 40, 384)          1536      ['block_10_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU  (None, 40, 40, 384)          0         ['block_10_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_10_depthwise (Depthw  (None, 40, 40, 384)          3456      ['block_10_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (Bat  (None, 40, 40, 384)          1536      ['block_10_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (R  (None, 40, 40, 384)          0         ['block_10_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)   (None, 40, 40, 96)           36864     ['block_10_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_10_project_BN (Batch  (None, 40, 40, 96)           384       ['block_10_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)    (None, 40, 40, 576)          55296     ['block_10_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchN  (None, 40, 40, 576)          2304      ['block_11_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU  (None, 40, 40, 576)          0         ['block_11_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_11_depthwise (Depthw  (None, 40, 40, 576)          5184      ['block_11_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (Bat  (None, 40, 40, 576)          2304      ['block_11_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (R  (None, 40, 40, 576)          0         ['block_11_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)   (None, 40, 40, 96)           55296     ['block_11_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_11_project_BN (Batch  (None, 40, 40, 96)           384       ['block_11_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_11_add (Add)          (None, 40, 40, 96)           0         ['block_10_project_BN[0][0]', \n",
      "                                                                     'block_11_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)    (None, 40, 40, 576)          55296     ['block_11_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchN  (None, 40, 40, 576)          2304      ['block_12_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU  (None, 40, 40, 576)          0         ['block_12_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_12_depthwise (Depthw  (None, 40, 40, 576)          5184      ['block_12_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (Bat  (None, 40, 40, 576)          2304      ['block_12_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (R  (None, 40, 40, 576)          0         ['block_12_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)   (None, 40, 40, 96)           55296     ['block_12_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_12_project_BN (Batch  (None, 40, 40, 96)           384       ['block_12_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_12_add (Add)          (None, 40, 40, 96)           0         ['block_11_add[0][0]',        \n",
      "                                                                     'block_12_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)    (None, 40, 40, 576)          55296     ['block_12_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchN  (None, 40, 40, 576)          2304      ['block_13_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU  (None, 40, 40, 576)          0         ['block_13_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2  (None, 41, 41, 576)          0         ['block_13_expand_relu[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block_13_depthwise (Depthw  (None, 20, 20, 576)          5184      ['block_13_pad[0][0]']        \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (Bat  (None, 20, 20, 576)          2304      ['block_13_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (R  (None, 20, 20, 576)          0         ['block_13_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)   (None, 20, 20, 160)          92160     ['block_13_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_13_project_BN (Batch  (None, 20, 20, 160)          640       ['block_13_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)    (None, 20, 20, 960)          153600    ['block_13_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchN  (None, 20, 20, 960)          3840      ['block_14_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU  (None, 20, 20, 960)          0         ['block_14_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_14_depthwise (Depthw  (None, 20, 20, 960)          8640      ['block_14_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (Bat  (None, 20, 20, 960)          3840      ['block_14_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (R  (None, 20, 20, 960)          0         ['block_14_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)   (None, 20, 20, 160)          153600    ['block_14_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_14_project_BN (Batch  (None, 20, 20, 160)          640       ['block_14_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_14_add (Add)          (None, 20, 20, 160)          0         ['block_13_project_BN[0][0]', \n",
      "                                                                     'block_14_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)    (None, 20, 20, 960)          153600    ['block_14_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchN  (None, 20, 20, 960)          3840      ['block_15_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU  (None, 20, 20, 960)          0         ['block_15_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_15_depthwise (Depthw  (None, 20, 20, 960)          8640      ['block_15_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (Bat  (None, 20, 20, 960)          3840      ['block_15_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (R  (None, 20, 20, 960)          0         ['block_15_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)   (None, 20, 20, 160)          153600    ['block_15_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_15_project_BN (Batch  (None, 20, 20, 160)          640       ['block_15_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_15_add (Add)          (None, 20, 20, 160)          0         ['block_14_add[0][0]',        \n",
      "                                                                     'block_15_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)    (None, 20, 20, 960)          153600    ['block_15_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchN  (None, 20, 20, 960)          3840      ['block_16_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU  (None, 20, 20, 960)          0         ['block_16_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_16_depthwise (Depthw  (None, 20, 20, 960)          8640      ['block_16_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (Bat  (None, 20, 20, 960)          3840      ['block_16_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (R  (None, 20, 20, 960)          0         ['block_16_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)   (None, 20, 20, 320)          307200    ['block_16_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_16_project_BN (Batch  (None, 20, 20, 320)          1280      ['block_16_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)             (None, 20, 20, 1280)         409600    ['block_16_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalizat  (None, 20, 20, 1280)         5120      ['Conv_1[0][0]']              \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " out_relu (ReLU)             (None, 20, 20, 1280)         0         ['Conv_1_bn[0][0]']           \n",
      "                                                                                                  \n",
      " extra1_1 (Conv2D)           (None, 20, 20, 256)          327936    ['out_relu[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 20, 20, 256)          1024      ['extra1_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)              (None, 20, 20, 256)          0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " extra1_2 (Conv2D)           (None, 10, 10, 512)          1180160   ['re_lu_7[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 10, 10, 512)          2048      ['extra1_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)              (None, 10, 10, 512)          0         ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " extra2_1 (Conv2D)           (None, 10, 10, 128)          65664     ['re_lu_8[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 10, 10, 128)          512       ['extra2_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)              (None, 10, 10, 128)          0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " extra2_2 (Conv2D)           (None, 5, 5, 256)            295168    ['re_lu_9[0][0]']             \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2  (None, 80, 80, 576)          0         ['block_13_expand_relu[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSamplin  (None, 80, 80, 1280)         0         ['out_relu[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSamplin  (None, 40, 40, 1280)         0         ['out_relu[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 5, 5, 256)            1024      ['extra2_2[0][0]']            \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " zero_conv (Conv2D)          (None, 80, 80, 256)          442624    ['block_6_expand_relu[0][0]'] \n",
      "                                                                                                  \n",
      " first_conv_upsampled (Conv  (None, 80, 80, 256)          1327360   ['up_sampling2d[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " second1_conv_upsampled (Co  (None, 80, 80, 256)          2949376   ['up_sampling2d_1[0][0]']     \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " first_conv (Conv2D)         (None, 40, 40, 256)          1327360   ['block_13_expand_relu[0][0]']\n",
      "                                                                                                  \n",
      " second2_conv_upsampled (Co  (None, 40, 40, 256)          2949376   ['up_sampling2d_2[0][0]']     \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)             (None, 5, 5, 256)            0         ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 80, 80, 256)          1024      ['zero_conv[0][0]']           \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 80, 80, 256)          1024      ['first_conv_upsampled[0][0]']\n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 80, 80, 256)          1024      ['second1_conv_upsampled[0][0]\n",
      " chNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 40, 40, 256)          1024      ['first_conv[0][0]']          \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 40, 40, 256)          1024      ['second2_conv_upsampled[0][0]\n",
      " chNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " extra3_1 (Conv2D)           (None, 5, 5, 128)            32896     ['re_lu_10[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                (None, 80, 80, 256)          0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)              (None, 80, 80, 256)          0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)              (None, 80, 80, 256)          0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)              (None, 40, 40, 256)          0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)              (None, 40, 40, 256)          0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, 5, 5, 128)            512       ['extra3_1[0][0]']            \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 80, 80, 768)          0         ['re_lu[0][0]',               \n",
      "                                                                     're_lu_1[0][0]',             \n",
      "                                                                     're_lu_2[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 40, 40, 512)          0         ['re_lu_4[0][0]',             \n",
      " )                                                                   're_lu_5[0][0]']             \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)             (None, 5, 5, 128)            0         ['batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " final_zero_conv (Conv2D)    (None, 80, 80, 256)          196864    ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " final_first_conv (Conv2D)   (None, 40, 40, 256)          131328    ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " extra3_2 (Conv2D)           (None, 3, 3, 256)            295168    ['re_lu_11[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)              (None, 80, 80, 256)          0         ['final_zero_conv[0][0]']     \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)              (None, 40, 40, 256)          0         ['final_first_conv[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, 3, 3, 256)            1024      ['extra3_2[0][0]']            \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 80, 80, 256)          1024      ['re_lu_3[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 40, 40, 256)          1024      ['re_lu_6[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)             (None, 3, 3, 256)            0         ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " 1_conv_label_output (Conv2  (None, 80, 80, 30)           69150     ['batch_normalization_3[0][0]'\n",
      " D)                                                                 ]                             \n",
      "                                                                                                  \n",
      " 2_conv_label_output (Conv2  (None, 40, 40, 30)           69150     ['batch_normalization_6[0][0]'\n",
      " D)                                                                 ]                             \n",
      "                                                                                                  \n",
      " 3_conv_label_output (Conv2  (None, 20, 20, 30)           345630    ['out_relu[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " 4_conv_label_output (Conv2  (None, 10, 10, 30)           138270    ['re_lu_8[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " 5_conv_label_output (Conv2  (None, 5, 5, 30)             69150     ['re_lu_10[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " 6_conv_label_output (Conv2  (None, 3, 3, 30)             69150     ['re_lu_12[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " 1_conv_boxes_output (Conv2  (None, 80, 80, 24)           55320     ['batch_normalization_3[0][0]'\n",
      " D)                                                                 ]                             \n",
      "                                                                                                  \n",
      " 2_conv_boxes_output (Conv2  (None, 40, 40, 24)           55320     ['batch_normalization_6[0][0]'\n",
      " D)                                                                 ]                             \n",
      "                                                                                                  \n",
      " 3_conv_boxes_output (Conv2  (None, 20, 20, 24)           276504    ['out_relu[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " 4_conv_boxes_output (Conv2  (None, 10, 10, 24)           110616    ['re_lu_8[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " 5_conv_boxes_output (Conv2  (None, 5, 5, 24)             55320     ['re_lu_10[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " 6_conv_boxes_output (Conv2  (None, 3, 3, 24)             55320     ['re_lu_12[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " labels_head (HeadWrapper)   (None, None, 5)              0         ['1_conv_label_output[0][0]', \n",
      "                                                                     '2_conv_label_output[0][0]', \n",
      "                                                                     '3_conv_label_output[0][0]', \n",
      "                                                                     '4_conv_label_output[0][0]', \n",
      "                                                                     '5_conv_label_output[0][0]', \n",
      "                                                                     '6_conv_label_output[0][0]'] \n",
      "                                                                                                  \n",
      " loc (HeadWrapper)           (None, None, 4)              0         ['1_conv_boxes_output[0][0]', \n",
      "                                                                     '2_conv_boxes_output[0][0]', \n",
      "                                                                     '3_conv_boxes_output[0][0]', \n",
      "                                                                     '4_conv_boxes_output[0][0]', \n",
      "                                                                     '5_conv_boxes_output[0][0]', \n",
      "                                                                     '6_conv_boxes_output[0][0]'] \n",
      "                                                                                                  \n",
      " conf (Activation)           (None, None, 5)              0         ['labels_head[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 15161476 (57.84 MB)\n",
      "Trainable params: 15120708 (57.68 MB)\n",
      "Non-trainable params: 40768 (159.25 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "ssd_custom_losses = CustomLoss(hyper_params[\"neg_pos_ratio\"], hyper_params[\"loc_loss_alpha\"], \n",
    "                               hyper_params[\"alpha\"], hyper_params[\"gamma\"], hyper_params[\"use_focal\"])\n",
    "\n",
    "ssd_model = get_model(hyper_params)\n",
    "ssd_model.compile(optimizer=Adam(learning_rate=hyper_params[\"lr\"]),\n",
    "                  loss=[ssd_custom_losses.loc_loss_fn, ssd_custom_losses.conf_loss_fn])\n",
    "init_model(ssd_model, img_size)\n",
    "\n",
    "ssd_model_path = get_model_path(backbone)\n",
    "if load_weights:\n",
    "    ssd_model.load_weights(ssd_model_path)\n",
    "ssd_log_path = get_log_path(backbone)\n",
    "\n",
    "ssd_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c7716f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:24:53.710378Z",
     "iopub.status.busy": "2024-03-08T08:24:53.709549Z",
     "iopub.status.idle": "2024-03-08T14:21:33.557501Z",
     "shell.execute_reply": "2024-03-08T14:21:33.556539Z"
    },
    "papermill": {
     "duration": 21405.203087,
     "end_time": "2024-03-08T14:21:38.808631",
     "exception": false,
     "start_time": "2024-03-08T08:24:53.605544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "716 29\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1709886323.137421      66 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 5s 111ms/step\n",
      "mAP: 0.0011080338137278388\n",
      "716/716 [==============================] - 406s 496ms/step - loss: 20.3456 - loc_loss: 3.7838 - conf_loss: 16.5618 - val_loss: 16.5138 - val_loc_loss: 3.2518 - val_conf_loss: 13.2620 - lr: 1.0000e-05\n",
      "Epoch 2/200\n",
      "29/29 [==============================] - 5s 113ms/step\n",
      "mAP: 0.0016943993517284724\n",
      "716/716 [==============================] - 344s 481ms/step - loss: 14.1940 - loc_loss: 3.1771 - conf_loss: 11.0168 - val_loss: 11.9680 - val_loc_loss: 2.8231 - val_conf_loss: 9.1449 - lr: 1.0000e-05\n",
      "Epoch 3/200\n",
      "29/29 [==============================] - 4s 110ms/step\n",
      "mAP: 0.0239149603418062\n",
      "716/716 [==============================] - 343s 479ms/step - loss: 11.2498 - loc_loss: 2.8846 - conf_loss: 8.3652 - val_loss: 9.6030 - val_loc_loss: 2.4918 - val_conf_loss: 7.1112 - lr: 1.0000e-05\n",
      "Epoch 4/200\n",
      "29/29 [==============================] - 5s 109ms/step\n",
      "mAP: 0.05592234499825648\n",
      "716/716 [==============================] - 296s 413ms/step - loss: 9.6266 - loc_loss: 2.7163 - conf_loss: 6.9103 - val_loss: 8.1215 - val_loc_loss: 2.2521 - val_conf_loss: 5.8694 - lr: 1.0000e-05\n",
      "Epoch 5/200\n",
      "29/29 [==============================] - 5s 110ms/step\n",
      "mAP: 0.11821818523518457\n",
      "716/716 [==============================] - 277s 387ms/step - loss: 8.5140 - loc_loss: 2.5969 - conf_loss: 5.9170 - val_loss: 6.9911 - val_loc_loss: 2.0736 - val_conf_loss: 4.9175 - lr: 1.0000e-05\n",
      "Epoch 6/200\n",
      "29/29 [==============================] - 5s 111ms/step\n",
      "mAP: 0.12939874360865858\n",
      "716/716 [==============================] - 268s 374ms/step - loss: 7.6737 - loc_loss: 2.4996 - conf_loss: 5.1741 - val_loss: 6.1810 - val_loc_loss: 1.9595 - val_conf_loss: 4.2215 - lr: 1.0000e-05\n",
      "Epoch 7/200\n",
      "29/29 [==============================] - 4s 110ms/step\n",
      "mAP: 0.13164808468166436\n",
      "716/716 [==============================] - 262s 366ms/step - loss: 6.9252 - loc_loss: 2.4086 - conf_loss: 4.5165 - val_loss: 5.5698 - val_loc_loss: 1.8789 - val_conf_loss: 3.6909 - lr: 1.0000e-05\n",
      "Epoch 8/200\n",
      "29/29 [==============================] - 5s 111ms/step\n",
      "mAP: 0.12763314891095892\n",
      "716/716 [==============================] - 260s 363ms/step - loss: 6.2874 - loc_loss: 2.3247 - conf_loss: 3.9627 - val_loss: 5.1101 - val_loc_loss: 1.8268 - val_conf_loss: 3.2833 - lr: 1.0000e-05\n",
      "Epoch 9/200\n",
      "29/29 [==============================] - 4s 110ms/step\n",
      "mAP: 0.14056295541595248\n",
      "716/716 [==============================] - 261s 364ms/step - loss: 5.8017 - loc_loss: 2.2464 - conf_loss: 3.5553 - val_loss: 4.7751 - val_loc_loss: 1.7670 - val_conf_loss: 3.0082 - lr: 1.0000e-05\n",
      "Epoch 10/200\n",
      "29/29 [==============================] - 5s 111ms/step\n",
      "mAP: 0.1544871984438471\n",
      "716/716 [==============================] - 259s 362ms/step - loss: 5.4477 - loc_loss: 2.1697 - conf_loss: 3.2780 - val_loss: 4.5375 - val_loc_loss: 1.7109 - val_conf_loss: 2.8266 - lr: 1.0000e-05\n",
      "Epoch 11/200\n",
      "29/29 [==============================] - 5s 111ms/step\n",
      "mAP: 0.16640729014823835\n",
      "716/716 [==============================] - 260s 363ms/step - loss: 5.1886 - loc_loss: 2.1030 - conf_loss: 3.0856 - val_loss: 4.2939 - val_loc_loss: 1.6567 - val_conf_loss: 2.6371 - lr: 1.0000e-05\n",
      "Epoch 12/200\n",
      "29/29 [==============================] - 5s 111ms/step\n",
      "mAP: 0.1420353160996559\n",
      "716/716 [==============================] - 260s 363ms/step - loss: 4.9988 - loc_loss: 2.0400 - conf_loss: 2.9588 - val_loss: 4.0994 - val_loc_loss: 1.5817 - val_conf_loss: 2.5176 - lr: 1.0000e-05\n",
      "Epoch 13/200\n",
      "29/29 [==============================] - 5s 110ms/step\n",
      "mAP: 0.18539647993417943\n",
      "716/716 [==============================] - 259s 362ms/step - loss: 4.8418 - loc_loss: 1.9744 - conf_loss: 2.8674 - val_loss: 3.9188 - val_loc_loss: 1.5138 - val_conf_loss: 2.4049 - lr: 1.0000e-05\n",
      "Epoch 14/200\n",
      "29/29 [==============================] - 5s 111ms/step\n",
      "mAP: 0.22779483515390742\n",
      "716/716 [==============================] - 259s 362ms/step - loss: 4.6880 - loc_loss: 1.9116 - conf_loss: 2.7764 - val_loss: 3.7514 - val_loc_loss: 1.4556 - val_conf_loss: 2.2958 - lr: 1.0000e-05\n",
      "Epoch 15/200\n",
      "29/29 [==============================] - 4s 108ms/step\n",
      "mAP: 0.24485816540278155\n",
      "716/716 [==============================] - 259s 361ms/step - loss: 4.5575 - loc_loss: 1.8559 - conf_loss: 2.7016 - val_loss: 3.6736 - val_loc_loss: 1.4333 - val_conf_loss: 2.2403 - lr: 1.0000e-05\n",
      "Epoch 16/200\n",
      "29/29 [==============================] - 4s 109ms/step\n",
      "mAP: 0.26838625805089217\n",
      "716/716 [==============================] - 259s 361ms/step - loss: 4.4395 - loc_loss: 1.8011 - conf_loss: 2.6384 - val_loss: 3.5659 - val_loc_loss: 1.3790 - val_conf_loss: 2.1869 - lr: 1.0000e-05\n",
      "Epoch 17/200\n",
      "29/29 [==============================] - 4s 110ms/step\n",
      "mAP: 0.2526477605878695\n",
      "716/716 [==============================] - 262s 365ms/step - loss: 4.3261 - loc_loss: 1.7499 - conf_loss: 2.5762 - val_loss: 3.4755 - val_loc_loss: 1.3307 - val_conf_loss: 2.1448 - lr: 1.0000e-05\n",
      "Epoch 18/200\n",
      "29/29 [==============================] - 4s 110ms/step\n",
      "mAP: 0.27650010489053695\n",
      "716/716 [==============================] - 258s 361ms/step - loss: 4.2352 - loc_loss: 1.7095 - conf_loss: 2.5257 - val_loss: 3.3888 - val_loc_loss: 1.2943 - val_conf_loss: 2.0946 - lr: 1.0000e-05\n",
      "Epoch 19/200\n",
      "29/29 [==============================] - 4s 111ms/step\n",
      "mAP: 0.3359136296549189\n",
      "716/716 [==============================] - 259s 361ms/step - loss: 4.1299 - loc_loss: 1.6603 - conf_loss: 2.4696 - val_loss: 3.3147 - val_loc_loss: 1.2534 - val_conf_loss: 2.0613 - lr: 1.0000e-05\n",
      "Epoch 20/200\n",
      "29/29 [==============================] - 4s 111ms/step\n",
      "mAP: 0.34559568382418426\n",
      "716/716 [==============================] - 260s 364ms/step - loss: 4.0418 - loc_loss: 1.6147 - conf_loss: 2.4270 - val_loss: 3.2496 - val_loc_loss: 1.2361 - val_conf_loss: 2.0136 - lr: 1.0000e-05\n",
      "Epoch 21/200\n",
      "29/29 [==============================] - 5s 112ms/step\n",
      "mAP: 0.35042647526071896\n",
      "716/716 [==============================] - 260s 364ms/step - loss: 3.9528 - loc_loss: 1.5733 - conf_loss: 2.3794 - val_loss: 3.1880 - val_loc_loss: 1.2079 - val_conf_loss: 1.9801 - lr: 1.0000e-05\n",
      "Epoch 22/200\n",
      "29/29 [==============================] - 5s 111ms/step\n",
      "mAP: 0.3583535006042634\n",
      "716/716 [==============================] - 261s 364ms/step - loss: 3.8725 - loc_loss: 1.5334 - conf_loss: 2.3391 - val_loss: 3.1326 - val_loc_loss: 1.1734 - val_conf_loss: 1.9592 - lr: 1.0000e-05\n",
      "Epoch 23/200\n",
      "29/29 [==============================] - 4s 109ms/step\n",
      "mAP: 0.3958171461719255\n",
      "716/716 [==============================] - 260s 363ms/step - loss: 3.7911 - loc_loss: 1.4920 - conf_loss: 2.2991 - val_loss: 3.0984 - val_loc_loss: 1.1608 - val_conf_loss: 1.9376 - lr: 1.0000e-05\n",
      "Epoch 24/200\n",
      "29/29 [==============================] - 4s 111ms/step\n",
      "mAP: 0.3693902965965833\n",
      "716/716 [==============================] - 260s 363ms/step - loss: 3.7247 - loc_loss: 1.4599 - conf_loss: 2.2648 - val_loss: 3.0359 - val_loc_loss: 1.1379 - val_conf_loss: 1.8980 - lr: 1.0000e-05\n",
      "Epoch 25/200\n",
      "29/29 [==============================] - 4s 110ms/step\n",
      "mAP: 0.40395369784651325\n",
      "716/716 [==============================] - 259s 362ms/step - loss: 3.6481 - loc_loss: 1.4237 - conf_loss: 2.2244 - val_loss: 3.0189 - val_loc_loss: 1.1253 - val_conf_loss: 1.8936 - lr: 1.0000e-05\n",
      "Epoch 26/200\n",
      "29/29 [==============================] - 4s 110ms/step\n",
      "mAP: 0.40835865704147245\n",
      "716/716 [==============================] - 259s 361ms/step - loss: 3.5896 - loc_loss: 1.3969 - conf_loss: 2.1927 - val_loss: 2.9570 - val_loc_loss: 1.0976 - val_conf_loss: 1.8595 - lr: 1.0000e-05\n",
      "Epoch 27/200\n",
      "29/29 [==============================] - 5s 109ms/step\n",
      "mAP: 0.4231022342657892\n",
      "716/716 [==============================] - 259s 362ms/step - loss: 3.5170 - loc_loss: 1.3593 - conf_loss: 2.1577 - val_loss: 2.9092 - val_loc_loss: 1.0860 - val_conf_loss: 1.8232 - lr: 1.0000e-05\n",
      "Epoch 28/200\n",
      "29/29 [==============================] - 4s 111ms/step\n",
      "mAP: 0.4005714343595723\n",
      "716/716 [==============================] - 259s 361ms/step - loss: 3.4583 - loc_loss: 1.3315 - conf_loss: 2.1268 - val_loss: 2.9266 - val_loc_loss: 1.0875 - val_conf_loss: 1.8391 - lr: 1.0000e-05\n",
      "Epoch 29/200\n",
      "29/29 [==============================] - 4s 110ms/step\n",
      "mAP: 0.38930269115281607\n",
      "716/716 [==============================] - 258s 361ms/step - loss: 3.3920 - loc_loss: 1.2995 - conf_loss: 2.0925 - val_loss: 2.8686 - val_loc_loss: 1.0648 - val_conf_loss: 1.8038 - lr: 1.0000e-05\n",
      "Epoch 30/200\n",
      "29/29 [==============================] - 4s 109ms/step\n",
      "mAP: 0.38243349435266266\n",
      "716/716 [==============================] - 258s 361ms/step - loss: 3.3336 - loc_loss: 1.2722 - conf_loss: 2.0615 - val_loss: 2.8556 - val_loc_loss: 1.0571 - val_conf_loss: 1.7985 - lr: 1.0000e-05\n",
      "Epoch 31/200\n",
      "29/29 [==============================] - 5s 110ms/step\n",
      "mAP: 0.4018960646706014\n",
      "716/716 [==============================] - 260s 363ms/step - loss: 3.2783 - loc_loss: 1.2428 - conf_loss: 2.0355 - val_loss: 2.8009 - val_loc_loss: 1.0140 - val_conf_loss: 1.7869 - lr: 1.0000e-05\n",
      "Epoch 32/200\n",
      "29/29 [==============================] - 4s 110ms/step\n",
      "mAP: 0.4205882342120645\n",
      "716/716 [==============================] - 260s 363ms/step - loss: 3.2280 - loc_loss: 1.2176 - conf_loss: 2.0104 - val_loss: 2.7951 - val_loc_loss: 1.0295 - val_conf_loss: 1.7656 - lr: 1.0000e-05\n",
      "Epoch 33/200\n",
      "29/29 [==============================] - 4s 110ms/step\n",
      "mAP: 0.43250677889137235\n",
      "716/716 [==============================] - 259s 362ms/step - loss: 3.1728 - loc_loss: 1.1889 - conf_loss: 1.9839 - val_loss: 2.7759 - val_loc_loss: 1.0238 - val_conf_loss: 1.7521 - lr: 1.0000e-05\n",
      "Epoch 34/200\n",
      "29/29 [==============================] - 5s 112ms/step\n",
      "mAP: 0.4443898873721813\n",
      "716/716 [==============================] - 259s 362ms/step - loss: 3.1220 - loc_loss: 1.1673 - conf_loss: 1.9546 - val_loss: 2.7679 - val_loc_loss: 1.0150 - val_conf_loss: 1.7529 - lr: 1.0000e-05\n",
      "Epoch 35/200\n",
      "29/29 [==============================] - 4s 110ms/step\n",
      "mAP: 0.4584231207834548\n",
      "716/716 [==============================] - 258s 361ms/step - loss: 3.0796 - loc_loss: 1.1451 - conf_loss: 1.9345 - val_loss: 2.7314 - val_loc_loss: 1.0066 - val_conf_loss: 1.7248 - lr: 1.0000e-05\n",
      "Epoch 36/200\n",
      "29/29 [==============================] - 4s 110ms/step\n",
      "mAP: 0.4441416974229474\n",
      "716/716 [==============================] - 260s 363ms/step - loss: 3.0262 - loc_loss: 1.1170 - conf_loss: 1.9091 - val_loss: 2.7233 - val_loc_loss: 0.9956 - val_conf_loss: 1.7277 - lr: 1.0000e-05\n",
      "Epoch 37/200\n",
      "29/29 [==============================] - 5s 112ms/step\n",
      "mAP: 0.4735595215384768\n",
      "716/716 [==============================] - 260s 364ms/step - loss: 2.9775 - loc_loss: 1.0973 - conf_loss: 1.8802 - val_loss: 2.6795 - val_loc_loss: 0.9841 - val_conf_loss: 1.6953 - lr: 1.0000e-05\n",
      "Epoch 38/200\n",
      "29/29 [==============================] - 4s 111ms/step\n",
      "mAP: 0.4783421790342929\n",
      "716/716 [==============================] - 261s 364ms/step - loss: 2.9373 - loc_loss: 1.0757 - conf_loss: 1.8616 - val_loss: 2.6568 - val_loc_loss: 0.9764 - val_conf_loss: 1.6804 - lr: 1.0000e-05\n",
      "Epoch 39/200\n",
      "29/29 [==============================] - 5s 109ms/step\n",
      "mAP: 0.45431028536627205\n",
      "716/716 [==============================] - 259s 361ms/step - loss: 2.8920 - loc_loss: 1.0551 - conf_loss: 1.8368 - val_loss: 2.6576 - val_loc_loss: 0.9767 - val_conf_loss: 1.6809 - lr: 1.0000e-05\n",
      "Epoch 40/200\n",
      "29/29 [==============================] - 5s 114ms/step\n",
      "mAP: 0.481969566698898\n",
      "716/716 [==============================] - 260s 363ms/step - loss: 2.8525 - loc_loss: 1.0369 - conf_loss: 1.8156 - val_loss: 2.5953 - val_loc_loss: 0.9487 - val_conf_loss: 1.6466 - lr: 1.0000e-05\n",
      "Epoch 41/200\n",
      "29/29 [==============================] - 4s 110ms/step\n",
      "mAP: 0.4776628402185986\n",
      "716/716 [==============================] - 261s 365ms/step - loss: 2.8064 - loc_loss: 1.0147 - conf_loss: 1.7917 - val_loss: 2.5820 - val_loc_loss: 0.9507 - val_conf_loss: 1.6312 - lr: 1.0000e-05\n",
      "Epoch 42/200\n",
      "29/29 [==============================] - 5s 112ms/step\n",
      "mAP: 0.4812001353518828\n",
      "716/716 [==============================] - 261s 364ms/step - loss: 2.7782 - loc_loss: 1.0005 - conf_loss: 1.7777 - val_loss: 2.6040 - val_loc_loss: 0.9659 - val_conf_loss: 1.6381 - lr: 1.0000e-05\n",
      "Epoch 43/200\n",
      "29/29 [==============================] - 5s 113ms/step\n",
      "mAP: 0.4459324946560579\n",
      "716/716 [==============================] - 260s 363ms/step - loss: 2.7375 - loc_loss: 0.9845 - conf_loss: 1.7531 - val_loss: 2.5681 - val_loc_loss: 0.9530 - val_conf_loss: 1.6151 - lr: 1.0000e-05\n",
      "Epoch 44/200\n",
      "29/29 [==============================] - 5s 111ms/step\n",
      "mAP: 0.46542503783235323\n",
      "716/716 [==============================] - 260s 364ms/step - loss: 2.6898 - loc_loss: 0.9630 - conf_loss: 1.7268 - val_loss: 2.5480 - val_loc_loss: 0.9347 - val_conf_loss: 1.6133 - lr: 1.0000e-05\n",
      "Epoch 45/200\n",
      "29/29 [==============================] - 5s 113ms/step\n",
      "mAP: 0.501493466110836\n",
      "716/716 [==============================] - 258s 361ms/step - loss: 2.6620 - loc_loss: 0.9471 - conf_loss: 1.7149 - val_loss: 2.5424 - val_loc_loss: 0.9266 - val_conf_loss: 1.6158 - lr: 1.0000e-05\n",
      "Epoch 46/200\n",
      "29/29 [==============================] - 4s 110ms/step\n",
      "mAP: 0.4858259850601748\n",
      "716/716 [==============================] - 258s 360ms/step - loss: 2.6118 - loc_loss: 0.9291 - conf_loss: 1.6827 - val_loss: 2.5345 - val_loc_loss: 0.9394 - val_conf_loss: 1.5951 - lr: 1.0000e-05\n",
      "Epoch 47/200\n",
      "29/29 [==============================] - 5s 115ms/step\n",
      "mAP: 0.5093872653668177\n",
      "716/716 [==============================] - 260s 364ms/step - loss: 2.5735 - loc_loss: 0.9135 - conf_loss: 1.6600 - val_loss: 2.5177 - val_loc_loss: 0.9228 - val_conf_loss: 1.5949 - lr: 1.0000e-05\n",
      "Epoch 48/200\n",
      "29/29 [==============================] - 4s 110ms/step\n",
      "mAP: 0.4852829794531336\n",
      "716/716 [==============================] - 259s 362ms/step - loss: 2.5357 - loc_loss: 0.8941 - conf_loss: 1.6416 - val_loss: 2.5294 - val_loc_loss: 0.9465 - val_conf_loss: 1.5829 - lr: 1.0000e-05\n",
      "Epoch 49/200\n",
      "29/29 [==============================] - 5s 113ms/step\n",
      "mAP: 0.49226281183682297\n",
      "716/716 [==============================] - 258s 361ms/step - loss: 2.5115 - loc_loss: 0.8833 - conf_loss: 1.6282 - val_loss: 2.4828 - val_loc_loss: 0.9181 - val_conf_loss: 1.5647 - lr: 1.0000e-05\n",
      "Epoch 50/200\n",
      "29/29 [==============================] - 4s 110ms/step\n",
      "mAP: 0.4842497300441635\n",
      "716/716 [==============================] - 258s 361ms/step - loss: 2.4704 - loc_loss: 0.8646 - conf_loss: 1.6058 - val_loss: 2.4737 - val_loc_loss: 0.9086 - val_conf_loss: 1.5651 - lr: 1.0000e-05\n",
      "Epoch 51/200\n",
      "29/29 [==============================] - 5s 114ms/step\n",
      "mAP: 0.48328174339143126\n",
      "716/716 [==============================] - 258s 361ms/step - loss: 2.4476 - loc_loss: 0.8553 - conf_loss: 1.5922 - val_loss: 2.4822 - val_loc_loss: 0.9188 - val_conf_loss: 1.5634 - lr: 1.0000e-05\n",
      "Epoch 52/200\n",
      "29/29 [==============================] - 4s 109ms/step\n",
      "mAP: 0.4774313811937777\n",
      "716/716 [==============================] - 260s 363ms/step - loss: 2.4068 - loc_loss: 0.8391 - conf_loss: 1.5676 - val_loss: 2.4590 - val_loc_loss: 0.9093 - val_conf_loss: 1.5497 - lr: 1.0000e-05\n",
      "Epoch 53/200\n",
      "29/29 [==============================] - 5s 112ms/step\n",
      "mAP: 0.4577645634339592\n",
      "716/716 [==============================] - 260s 364ms/step - loss: 2.3866 - loc_loss: 0.8292 - conf_loss: 1.5574 - val_loss: 2.4224 - val_loc_loss: 0.8912 - val_conf_loss: 1.5313 - lr: 1.0000e-05\n",
      "Epoch 54/200\n",
      "29/29 [==============================] - 4s 110ms/step\n",
      "mAP: 0.5039655050055065\n",
      "716/716 [==============================] - 259s 361ms/step - loss: 2.3523 - loc_loss: 0.8146 - conf_loss: 1.5377 - val_loss: 2.4180 - val_loc_loss: 0.8977 - val_conf_loss: 1.5204 - lr: 1.0000e-05\n",
      "Epoch 55/200\n",
      "29/29 [==============================] - 5s 113ms/step\n",
      "mAP: 0.48833686764160533\n",
      "716/716 [==============================] - 259s 361ms/step - loss: 2.3192 - loc_loss: 0.8013 - conf_loss: 1.5179 - val_loss: 2.4129 - val_loc_loss: 0.8821 - val_conf_loss: 1.5308 - lr: 1.0000e-05\n",
      "Epoch 56/200\n",
      "29/29 [==============================] - 4s 110ms/step\n",
      "mAP: 0.4807040807989087\n",
      "716/716 [==============================] - 260s 363ms/step - loss: 2.2928 - loc_loss: 0.7903 - conf_loss: 1.5025 - val_loss: 2.4308 - val_loc_loss: 0.8885 - val_conf_loss: 1.5423 - lr: 1.0000e-05\n",
      "Epoch 57/200\n",
      "29/29 [==============================] - 5s 113ms/step\n",
      "mAP: 0.46919070845016714\n",
      "716/716 [==============================] - 260s 364ms/step - loss: 2.2585 - loc_loss: 0.7755 - conf_loss: 1.4830 - val_loss: 2.4356 - val_loc_loss: 0.8990 - val_conf_loss: 1.5366 - lr: 1.0000e-05\n",
      "Epoch 58/200\n",
      "29/29 [==============================] - 4s 111ms/step\n",
      "mAP: 0.4954363987442608\n",
      "716/716 [==============================] - 259s 362ms/step - loss: 2.2390 - loc_loss: 0.7685 - conf_loss: 1.4706 - val_loss: 2.4249 - val_loc_loss: 0.8874 - val_conf_loss: 1.5376 - lr: 1.0000e-05\n",
      "Epoch 59/200\n",
      "29/29 [==============================] - 5s 112ms/step\n",
      "mAP: 0.47975011373894644\n",
      "716/716 [==============================] - 261s 364ms/step - loss: 2.2016 - loc_loss: 0.7529 - conf_loss: 1.4487 - val_loss: 2.4129 - val_loc_loss: 0.8906 - val_conf_loss: 1.5222 - lr: 1.0000e-05\n",
      "Epoch 60/200\n",
      "29/29 [==============================] - 4s 110ms/step\n",
      "mAP: 0.5027145070110471\n",
      "716/716 [==============================] - 258s 361ms/step - loss: 2.1769 - loc_loss: 0.7446 - conf_loss: 1.4323 - val_loss: 2.3702 - val_loc_loss: 0.8723 - val_conf_loss: 1.4980 - lr: 1.0000e-05\n",
      "Epoch 61/200\n",
      "29/29 [==============================] - 5s 111ms/step\n",
      "mAP: 0.5171739143312039\n",
      "716/716 [==============================] - 259s 362ms/step - loss: 2.1486 - loc_loss: 0.7326 - conf_loss: 1.4160 - val_loss: 2.3692 - val_loc_loss: 0.8642 - val_conf_loss: 1.5050 - lr: 1.0000e-05\n",
      "Epoch 62/200\n",
      "29/29 [==============================] - 4s 111ms/step\n",
      "mAP: 0.4923969781285938\n",
      "716/716 [==============================] - 258s 361ms/step - loss: 2.1164 - loc_loss: 0.7195 - conf_loss: 1.3969 - val_loss: 2.3636 - val_loc_loss: 0.8592 - val_conf_loss: 1.5044 - lr: 1.0000e-05\n",
      "Epoch 63/200\n",
      "29/29 [==============================] - 4s 109ms/step\n",
      "mAP: 0.47975295833134207\n",
      "716/716 [==============================] - 259s 362ms/step - loss: 2.0979 - loc_loss: 0.7131 - conf_loss: 1.3847 - val_loss: 2.3638 - val_loc_loss: 0.8536 - val_conf_loss: 1.5102 - lr: 1.0000e-05\n",
      "Epoch 64/200\n",
      "29/29 [==============================] - 4s 108ms/step\n",
      "mAP: 0.48061906715283165\n",
      "716/716 [==============================] - 258s 360ms/step - loss: 2.0662 - loc_loss: 0.6992 - conf_loss: 1.3670 - val_loss: 2.3582 - val_loc_loss: 0.8615 - val_conf_loss: 1.4967 - lr: 1.0000e-05\n",
      "Epoch 65/200\n",
      "29/29 [==============================] - 4s 109ms/step\n",
      "mAP: 0.4946693887844834\n",
      "716/716 [==============================] - 258s 360ms/step - loss: 2.0463 - loc_loss: 0.6916 - conf_loss: 1.3547 - val_loss: 2.3885 - val_loc_loss: 0.8755 - val_conf_loss: 1.5130 - lr: 1.0000e-05\n",
      "Epoch 66/200\n",
      "29/29 [==============================] - 4s 111ms/step\n",
      "mAP: 0.4967443936820216\n",
      "716/716 [==============================] - 260s 363ms/step - loss: 2.0095 - loc_loss: 0.6769 - conf_loss: 1.3326 - val_loss: 2.3673 - val_loc_loss: 0.8872 - val_conf_loss: 1.4800 - lr: 1.0000e-05\n",
      "Epoch 67/200\n",
      "29/29 [==============================] - 4s 111ms/step\n",
      "mAP: 0.4833958703782577\n",
      "716/716 [==============================] - 260s 363ms/step - loss: 1.9969 - loc_loss: 0.6741 - conf_loss: 1.3229 - val_loss: 2.3624 - val_loc_loss: 0.8678 - val_conf_loss: 1.4945 - lr: 1.0000e-05\n",
      "Epoch 68/200\n",
      "29/29 [==============================] - 5s 112ms/step\n",
      "mAP: 0.49117802013407286\n",
      "716/716 [==============================] - 260s 363ms/step - loss: 1.9759 - loc_loss: 0.6640 - conf_loss: 1.3119 - val_loss: 2.3572 - val_loc_loss: 0.8594 - val_conf_loss: 1.4978 - lr: 1.0000e-05\n",
      "Epoch 69/200\n",
      "29/29 [==============================] - 4s 110ms/step\n",
      "mAP: 0.48171892258885046\n",
      "716/716 [==============================] - 260s 364ms/step - loss: 1.9489 - loc_loss: 0.6547 - conf_loss: 1.2942 - val_loss: 2.3658 - val_loc_loss: 0.8698 - val_conf_loss: 1.4960 - lr: 1.0000e-05\n",
      "Epoch 70/200\n",
      "29/29 [==============================] - 4s 110ms/step\n",
      "mAP: 0.49462809139205327\n",
      "716/716 [==============================] - 259s 361ms/step - loss: 1.9263 - loc_loss: 0.6463 - conf_loss: 1.2800 - val_loss: 2.3292 - val_loc_loss: 0.8410 - val_conf_loss: 1.4882 - lr: 1.0000e-05\n",
      "Epoch 71/200\n",
      "29/29 [==============================] - 5s 111ms/step\n",
      "mAP: 0.5035802768750182\n",
      "716/716 [==============================] - 259s 362ms/step - loss: 1.9053 - loc_loss: 0.6389 - conf_loss: 1.2664 - val_loss: 2.3315 - val_loc_loss: 0.8348 - val_conf_loss: 1.4967 - lr: 1.0000e-05\n",
      "Epoch 72/200\n",
      "29/29 [==============================] - 5s 111ms/step\n",
      "mAP: 0.49037797066037725\n",
      "716/716 [==============================] - 261s 364ms/step - loss: 1.8774 - loc_loss: 0.6273 - conf_loss: 1.2501 - val_loss: 2.3122 - val_loc_loss: 0.8328 - val_conf_loss: 1.4794 - lr: 1.0000e-05\n",
      "Epoch 73/200\n",
      "29/29 [==============================] - 4s 110ms/step\n",
      "mAP: 0.47821429179772557\n",
      "716/716 [==============================] - 261s 365ms/step - loss: 1.8593 - loc_loss: 0.6229 - conf_loss: 1.2363 - val_loss: 2.3012 - val_loc_loss: 0.8258 - val_conf_loss: 1.4753 - lr: 1.0000e-05\n",
      "Epoch 74/200\n",
      "29/29 [==============================] - 5s 110ms/step\n",
      "mAP: 0.49346213856528653\n",
      "716/716 [==============================] - 259s 362ms/step - loss: 1.8414 - loc_loss: 0.6170 - conf_loss: 1.2244 - val_loss: 2.3470 - val_loc_loss: 0.8650 - val_conf_loss: 1.4820 - lr: 1.0000e-05\n",
      "Epoch 75/200\n",
      "29/29 [==============================] - 5s 111ms/step\n",
      "mAP: 0.509050278010759\n",
      "716/716 [==============================] - 259s 362ms/step - loss: 1.8206 - loc_loss: 0.6079 - conf_loss: 1.2127 - val_loss: 2.3623 - val_loc_loss: 0.8446 - val_conf_loss: 1.5177 - lr: 1.0000e-05\n",
      "Epoch 76/200\n",
      "29/29 [==============================] - 5s 111ms/step\n",
      "mAP: 0.5100352034816764\n",
      "716/716 [==============================] - 262s 365ms/step - loss: 1.7914 - loc_loss: 0.5973 - conf_loss: 1.1942 - val_loss: 2.3645 - val_loc_loss: 0.8522 - val_conf_loss: 1.5124 - lr: 1.0000e-05\n",
      "Epoch 77/200\n",
      "29/29 [==============================] - 5s 113ms/step\n",
      "mAP: 0.5137734532557034\n",
      "716/716 [==============================] - 259s 362ms/step - loss: 1.7399 - loc_loss: 0.5802 - conf_loss: 1.1597 - val_loss: 2.3341 - val_loc_loss: 0.8382 - val_conf_loss: 1.4959 - lr: 1.0000e-06\n",
      "Epoch 78/200\n",
      "29/29 [==============================] - 5s 111ms/step\n",
      "mAP: 0.515591525808753\n",
      "716/716 [==============================] - 260s 363ms/step - loss: 1.7361 - loc_loss: 0.5746 - conf_loss: 1.1614 - val_loss: 2.3291 - val_loc_loss: 0.8345 - val_conf_loss: 1.4946 - lr: 1.0000e-06\n",
      "Epoch 79/200\n",
      "29/29 [==============================] - 4s 111ms/step\n",
      "mAP: 0.4997780510364892\n",
      "716/716 [==============================] - 259s 362ms/step - loss: 1.7252 - loc_loss: 0.5704 - conf_loss: 1.1548 - val_loss: 2.3250 - val_loc_loss: 0.8371 - val_conf_loss: 1.4879 - lr: 1.0000e-06\n",
      "Epoch 80/200\n",
      "29/29 [==============================] - 4s 109ms/step\n",
      "mAP: 0.5009601422460166\n",
      "716/716 [==============================] - 261s 365ms/step - loss: 1.7197 - loc_loss: 0.5678 - conf_loss: 1.1519 - val_loss: 2.3268 - val_loc_loss: 0.8368 - val_conf_loss: 1.4900 - lr: 1.0000e-06\n",
      "Epoch 81/200\n",
      "29/29 [==============================] - 5s 110ms/step\n",
      "mAP: 0.5097706503322446\n",
      "Early stopping at epoch 81 due to lack of improvement.\n",
      "716/716 [==============================] - 258s 361ms/step - loss: 1.7181 - loc_loss: 0.5681 - conf_loss: 1.1499 - val_loss: 2.3259 - val_loc_loss: 0.8376 - val_conf_loss: 1.4882 - lr: 1.0000e-06\n",
      "\n",
      "Best Mean Average Precision: 0.5171739143312039\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Moved under mAP_callback\n",
    "# checkpoint_callback = ModelCheckpoint(ssd_model_path, monitor=\"val_loss\", save_best_only=True, save_weights_only=True)\n",
    "learning_rate_callback = LearningRateScheduler(scheduler, verbose=0)\n",
    "tensorboard_callback = TensorBoard(log_dir=ssd_log_path)\n",
    "step_size_train = get_step_size(train_total_items, batch_size)\n",
    "step_size_val = get_step_size(val_total_items, batch_size)\n",
    "print(step_size_train, step_size_val)\n",
    "# mAP_callback both early stopping and checkpoint\n",
    "mAP_callback = MeanAveragePrecisionCallback(val_data, step_size_val, labels, prior_boxes, hyper_params,\n",
    "                                            batch_size, hyper_params[\"patience\"], ssd_model_path)\n",
    "\n",
    "history = ssd_model.fit(ssd_train_feed,\n",
    "              steps_per_epoch=step_size_train,\n",
    "              validation_data=ssd_val_feed,\n",
    "              validation_steps=step_size_val,\n",
    "              epochs=epochs,\n",
    "              callbacks=[tensorboard_callback, learning_rate_callback, mAP_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaede17",
   "metadata": {
    "id": "nVPhU6-xkSF5",
    "papermill": {
     "duration": 5.259334,
     "end_time": "2024-03-08T14:21:49.292072",
     "exception": false,
     "start_time": "2024-03-08T14:21:44.032738",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78a9eeb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T14:21:59.916835Z",
     "iopub.status.busy": "2024-03-08T14:21:59.916405Z",
     "iopub.status.idle": "2024-03-08T14:22:00.779546Z",
     "shell.execute_reply": "2024-03-08T14:22:00.778490Z"
    },
    "id": "i4HPimys1Wfv",
    "outputId": "8a3f1181-dab6-4ba3-cc33-8ba831fcbcd5",
    "papermill": {
     "duration": 6.236981,
     "end_time": "2024-03-08T14:22:00.782024",
     "exception": false,
     "start_time": "2024-03-08T14:21:54.545043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7a9849ca00>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(history.history['loc_loss'])\n",
    "plt.plot(history.history['val_loc_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loc loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "\n",
    "plt.figure(3)\n",
    "plt.plot(history.history['conf_loss'])\n",
    "plt.plot(history.history['val_conf_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('conf loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fdc4c90e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T14:22:11.372347Z",
     "iopub.status.busy": "2024-03-08T14:22:11.371432Z",
     "iopub.status.idle": "2024-03-08T14:22:11.613350Z",
     "shell.execute_reply": "2024-03-08T14:22:11.612233Z"
    },
    "id": "-YoXADJikWs6",
    "outputId": "1e1b16d9-d778-4723-c4f5-0019c3ca2b05",
    "papermill": {
     "duration": 5.501627,
     "end_time": "2024-03-08T14:22:11.615567",
     "exception": false,
     "start_time": "2024-03-08T14:22:06.113940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epoch')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mAP_values = mAP_callback.get_mAP_values()\n",
    "plt.plot(mAP_values)\n",
    "plt.title('mAP')\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e12a620a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T14:22:22.434960Z",
     "iopub.status.busy": "2024-03-08T14:22:22.434080Z",
     "iopub.status.idle": "2024-03-08T14:22:22.441070Z",
     "shell.execute_reply": "2024-03-08T14:22:22.440016Z"
    },
    "id": "KDTcajkTw4DG",
    "outputId": "030daf33-17d5-476d-be7c-b700530746b0",
    "papermill": {
     "duration": 5.309308,
     "end_time": "2024-03-08T14:22:22.443426",
     "exception": false,
     "start_time": "2024-03-08T14:22:17.134118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/logs/mobilenet_v2/20240308-082452\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "logs = os.listdir(f\"/kaggle/working/logs/{backbone}/\")\n",
    "logs.sort()\n",
    "log_path = f\"/kaggle/working/logs/{backbone}/{logs[-1]}\"\n",
    "print(log_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4b7d636",
   "metadata": {
    "id": "hk0iUI8PreZR",
    "papermill": {
     "duration": 5.263434,
     "end_time": "2024-03-08T14:22:32.987440",
     "exception": false,
     "start_time": "2024-03-08T14:22:27.724006",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir \"/content/logs/mobilenet_v2/20240129-090642\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d12fbe7",
   "metadata": {
    "id": "yNKy8TbeM4AA",
    "papermill": {
     "duration": 5.233466,
     "end_time": "2024-03-08T14:22:43.578236",
     "exception": false,
     "start_time": "2024-03-08T14:22:38.344770",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# predictor (test mAP + FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "109fc68a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T14:22:54.127810Z",
     "iopub.status.busy": "2024-03-08T14:22:54.127399Z",
     "iopub.status.idle": "2024-03-08T14:22:54.237624Z",
     "shell.execute_reply": "2024-03-08T14:22:54.236577Z"
    },
    "id": "h9sYYPOeNoy0",
    "outputId": "edd51b01-3a04-4ae0-f34f-a299341fe279",
    "papermill": {
     "duration": 5.416067,
     "end_time": "2024-03-08T14:22:54.239957",
     "exception": false,
     "start_time": "2024-03-08T14:22:48.823890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n"
     ]
    }
   ],
   "source": [
    "evaluate = True\n",
    "use_custom_images = False\n",
    "custom_image_path = \"data/images/\"\n",
    "\n",
    "test_data, total_items = tfr_dataset(test_files)\n",
    "print(total_items)\n",
    "\n",
    "data_types = get_data_types()\n",
    "data_shapes = get_data_shapes()\n",
    "padding_values = get_padding_values()\n",
    "\n",
    "if use_custom_images:\n",
    "    img_paths = get_custom_imgs(custom_image_path)\n",
    "    total_items = len(img_paths)\n",
    "    test_data = tf.data.Dataset.from_generator(lambda: custom_data_generator(\n",
    "                                               img_paths, img_size, img_size), data_types, data_shapes)\n",
    "else:\n",
    "    test_data = test_data.map(lambda x : tfr_preprocessing(x, img_size, img_size))\n",
    "\n",
    "test_data = test_data.padded_batch(batch_size, padded_shapes=data_shapes, padding_values=padding_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94526455",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T14:23:04.732066Z",
     "iopub.status.busy": "2024-03-08T14:23:04.731664Z",
     "iopub.status.idle": "2024-03-08T14:23:17.979946Z",
     "shell.execute_reply": "2024-03-08T14:23:17.978902Z"
    },
    "id": "LGcBVI4Gn_Mz",
    "outputId": "b16156c7-b28a-4f39-d45b-e43c77a29911",
    "papermill": {
     "duration": 18.467157,
     "end_time": "2024-03-08T14:23:17.982159",
     "exception": false,
     "start_time": "2024-03-08T14:22:59.515002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 3s 110ms/step\n",
      "Total time taken: 2.9942033290863037 seconds\n",
      "Frames Per Second (FPS): 38.74152395502078\n",
      "mAP: 0.5774243421829859\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "ssd_model = get_model(hyper_params)\n",
    "ssd_model_path = get_model_path(backbone)\n",
    "ssd_model.load_weights(ssd_model_path)\n",
    "ssd_decoder_model = get_decoder_model(ssd_model, prior_boxes, hyper_params)\n",
    "\n",
    "step_size = get_step_size(total_items, batch_size)\n",
    "\n",
    "start_time = time.time()\n",
    "pred_bboxes, pred_labels, pred_scores = ssd_decoder_model.predict(test_data, steps=step_size, verbose=1)\n",
    "end_time = time.time()\n",
    "total_time_taken = end_time - start_time\n",
    "\n",
    "# Calculate Frames Per Second (FPS)\n",
    "fps = total_items / total_time_taken\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total time taken: {total_time_taken} seconds\")\n",
    "print(f\"Frames Per Second (FPS): {fps}\")\n",
    "\n",
    "if evaluate:\n",
    "    stats, mAP = evaluate_predictions(test_data, pred_bboxes, pred_labels, pred_scores, labels, batch_size)\n",
    "else:\n",
    "    draw_predictions(test_data, pred_bboxes, pred_labels, pred_scores, labels, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93375574",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T14:23:28.487137Z",
     "iopub.status.busy": "2024-03-08T14:23:28.486158Z",
     "iopub.status.idle": "2024-03-08T14:23:28.492538Z",
     "shell.execute_reply": "2024-03-08T14:23:28.491638Z"
    },
    "id": "nn03Kvkm3UlW",
    "outputId": "ac17429f-b376-46f3-c914-e8f61d998170",
    "papermill": {
     "duration": 5.315548,
     "end_time": "2024-03-08T14:23:28.494852",
     "exception": false,
     "start_time": "2024-03-08T14:23:23.179304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hole\n",
      "Total: 47\n",
      "Total Predictions 46\n",
      "Correct Predictions: 39\n",
      "Knot\n",
      "Total: 25\n",
      "Total Predictions 19\n",
      "Correct Predictions: 16\n",
      "Line\n",
      "Total: 36\n",
      "Total Predictions 33\n",
      "Correct Predictions: 9\n",
      "Stain\n",
      "Total: 46\n",
      "Total Predictions 48\n",
      "Correct Predictions: 34\n"
     ]
    }
   ],
   "source": [
    "for i in stats:\n",
    "    print(stats[i]['label'])\n",
    "    print('Total:', stats[i]['total'])\n",
    "    print('Total Predictions', len(stats[i]['tp']))\n",
    "    print('Correct Predictions:', stats[i]['tp'].count(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ce18c33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T14:23:38.991994Z",
     "iopub.status.busy": "2024-03-08T14:23:38.991098Z",
     "iopub.status.idle": "2024-03-08T14:23:39.012661Z",
     "shell.execute_reply": "2024-03-08T14:23:39.011641Z"
    },
    "papermill": {
     "duration": 5.279969,
     "end_time": "2024-03-08T14:23:39.014786",
     "exception": false,
     "start_time": "2024-03-08T14:23:33.734817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'label': 'Hole',\n",
       "  'total': 47,\n",
       "  'tp': [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  'fp': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'scores': [0.96555257,\n",
       "   0.9650437,\n",
       "   0.6541565,\n",
       "   0.99490875,\n",
       "   0.9120127,\n",
       "   0.9901545,\n",
       "   0.6549193,\n",
       "   0.85285693,\n",
       "   0.7228738,\n",
       "   0.9683327,\n",
       "   0.73079485,\n",
       "   0.9597136,\n",
       "   0.77564234,\n",
       "   0.8158219,\n",
       "   0.97342616,\n",
       "   0.9949698,\n",
       "   0.61651397,\n",
       "   0.8785824,\n",
       "   0.99725336,\n",
       "   0.98461837,\n",
       "   0.9990096,\n",
       "   0.5820515,\n",
       "   0.99448156,\n",
       "   0.9958331,\n",
       "   0.929604,\n",
       "   0.9875388,\n",
       "   0.99849296,\n",
       "   0.98189205,\n",
       "   0.99412584,\n",
       "   0.91550803,\n",
       "   0.9641001,\n",
       "   0.73989904,\n",
       "   0.99801433,\n",
       "   0.66806513,\n",
       "   0.9600308,\n",
       "   0.50147074,\n",
       "   0.9308506,\n",
       "   0.5428222,\n",
       "   0.5751453,\n",
       "   0.58974695,\n",
       "   0.6209809,\n",
       "   0.9996972,\n",
       "   0.9865763,\n",
       "   0.99366164,\n",
       "   0.92705876,\n",
       "   0.98328847],\n",
       "  'recall': array([0.0212766 , 0.04255319, 0.06382979, 0.08510638, 0.10638298,\n",
       "         0.12765957, 0.12765957, 0.14893617, 0.17021277, 0.19148936,\n",
       "         0.21276596, 0.23404255, 0.25531915, 0.27659574, 0.29787234,\n",
       "         0.31914894, 0.34042553, 0.36170213, 0.38297872, 0.40425532,\n",
       "         0.42553191, 0.44680851, 0.46808511, 0.4893617 , 0.5106383 ,\n",
       "         0.53191489, 0.55319149, 0.57446809, 0.59574468, 0.59574468,\n",
       "         0.61702128, 0.61702128, 0.63829787, 0.65957447, 0.68085106,\n",
       "         0.68085106, 0.68085106, 0.70212766, 0.72340426, 0.74468085,\n",
       "         0.76595745, 0.76595745, 0.78723404, 0.80851064, 0.80851064,\n",
       "         0.82978723]),\n",
       "  'precision': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 0.85714286, 0.875     , 0.88888889, 0.9       ,\n",
       "         0.90909091, 0.91666667, 0.92307692, 0.92857143, 0.93333333,\n",
       "         0.9375    , 0.94117647, 0.94444444, 0.94736842, 0.95      ,\n",
       "         0.95238095, 0.95454545, 0.95652174, 0.95833333, 0.96      ,\n",
       "         0.96153846, 0.96296296, 0.96428571, 0.96551724, 0.93333333,\n",
       "         0.93548387, 0.90625   , 0.90909091, 0.91176471, 0.91428571,\n",
       "         0.88888889, 0.86486486, 0.86842105, 0.87179487, 0.875     ,\n",
       "         0.87804878, 0.85714286, 0.86046512, 0.86363636, 0.84444444,\n",
       "         0.84782609]),\n",
       "  'AP': 0.7762943618735594},\n",
       " 2: {'label': 'Knot',\n",
       "  'total': 25,\n",
       "  'tp': [1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1],\n",
       "  'fp': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "  'scores': [0.8997295,\n",
       "   0.99143773,\n",
       "   0.6696154,\n",
       "   0.93157476,\n",
       "   0.99328583,\n",
       "   0.8278462,\n",
       "   0.9896554,\n",
       "   0.995269,\n",
       "   0.7750047,\n",
       "   0.92312443,\n",
       "   0.6249975,\n",
       "   0.66843885,\n",
       "   0.88290393,\n",
       "   0.9802311,\n",
       "   0.93917227,\n",
       "   0.834222,\n",
       "   0.74706453,\n",
       "   0.89933455,\n",
       "   0.9543987],\n",
       "  'recall': array([0.04, 0.08, 0.12, 0.16, 0.2 , 0.24, 0.28, 0.32, 0.36, 0.4 , 0.44,\n",
       "         0.48, 0.48, 0.48, 0.52, 0.52, 0.56, 0.6 , 0.64]),\n",
       "  'precision': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 0.92307692, 0.85714286, 0.86666667,\n",
       "         0.8125    , 0.82352941, 0.83333333, 0.84210526]),\n",
       "  'AP': 0.6098883572567784},\n",
       " 3: {'label': 'Line',\n",
       "  'total': 36,\n",
       "  'tp': [1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1],\n",
       "  'fp': [0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0],\n",
       "  'scores': [0.7945937,\n",
       "   0.52887297,\n",
       "   0.7156101,\n",
       "   0.90860605,\n",
       "   0.6493521,\n",
       "   0.6263639,\n",
       "   0.92651784,\n",
       "   0.5792327,\n",
       "   0.5582627,\n",
       "   0.78035617,\n",
       "   0.6256904,\n",
       "   0.7410068,\n",
       "   0.74439937,\n",
       "   0.859088,\n",
       "   0.99302566,\n",
       "   0.7332792,\n",
       "   0.5127332,\n",
       "   0.64672595,\n",
       "   0.675463,\n",
       "   0.53960913,\n",
       "   0.60580665,\n",
       "   0.5869427,\n",
       "   0.9769677,\n",
       "   0.57727134,\n",
       "   0.9110326,\n",
       "   0.5064487,\n",
       "   0.6252319,\n",
       "   0.74595326,\n",
       "   0.9869223,\n",
       "   0.74399287,\n",
       "   0.65700394,\n",
       "   0.70643353,\n",
       "   0.9923685],\n",
       "  'recall': array([0.02777778, 0.05555556, 0.08333333, 0.11111111, 0.11111111,\n",
       "         0.13888889, 0.16666667, 0.16666667, 0.19444444, 0.19444444,\n",
       "         0.19444444, 0.22222222, 0.22222222, 0.22222222, 0.22222222,\n",
       "         0.22222222, 0.22222222, 0.22222222, 0.22222222, 0.22222222,\n",
       "         0.22222222, 0.25      , 0.25      , 0.25      , 0.25      ,\n",
       "         0.25      , 0.25      , 0.25      , 0.25      , 0.25      ,\n",
       "         0.25      , 0.25      , 0.25      ]),\n",
       "  'precision': array([1.        , 1.        , 1.        , 1.        , 0.8       ,\n",
       "         0.83333333, 0.85714286, 0.75      , 0.77777778, 0.7       ,\n",
       "         0.63636364, 0.66666667, 0.61538462, 0.57142857, 0.53333333,\n",
       "         0.5       , 0.47058824, 0.44444444, 0.42105263, 0.4       ,\n",
       "         0.38095238, 0.40909091, 0.39130435, 0.375     , 0.36      ,\n",
       "         0.34615385, 0.33333333, 0.32142857, 0.31034483, 0.3       ,\n",
       "         0.29032258, 0.28125   , 0.27272727]),\n",
       "  'AP': 0.2424242424242424},\n",
       " 4: {'label': 'Stain',\n",
       "  'total': 46,\n",
       "  'tp': [1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1],\n",
       "  'fp': [0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0],\n",
       "  'scores': [0.99771166,\n",
       "   0.501836,\n",
       "   0.510944,\n",
       "   0.7300808,\n",
       "   0.96168125,\n",
       "   0.8252589,\n",
       "   0.6498495,\n",
       "   0.9983292,\n",
       "   0.8281612,\n",
       "   0.9709439,\n",
       "   0.9796338,\n",
       "   0.9961281,\n",
       "   0.55280626,\n",
       "   0.9225919,\n",
       "   0.9980951,\n",
       "   0.8823896,\n",
       "   0.80126727,\n",
       "   0.7948084,\n",
       "   0.97919923,\n",
       "   0.95803815,\n",
       "   0.9382989,\n",
       "   0.99613696,\n",
       "   0.6665409,\n",
       "   0.6154107,\n",
       "   0.52722913,\n",
       "   0.73898154,\n",
       "   0.59817207,\n",
       "   0.98883367,\n",
       "   0.97576886,\n",
       "   0.99600106,\n",
       "   0.9273899,\n",
       "   0.99473745,\n",
       "   0.99840075,\n",
       "   0.9848701,\n",
       "   0.54288805,\n",
       "   0.7281812,\n",
       "   0.92122567,\n",
       "   0.9994937,\n",
       "   0.65647596,\n",
       "   0.9998441,\n",
       "   0.8161202,\n",
       "   0.97230124,\n",
       "   0.84671116,\n",
       "   0.99972063,\n",
       "   0.9291784,\n",
       "   0.57615244,\n",
       "   0.841353,\n",
       "   0.98411787],\n",
       "  'recall': array([0.02173913, 0.04347826, 0.06521739, 0.08695652, 0.10869565,\n",
       "         0.13043478, 0.15217391, 0.17391304, 0.19565217, 0.2173913 ,\n",
       "         0.23913043, 0.26086957, 0.26086957, 0.2826087 , 0.30434783,\n",
       "         0.32608696, 0.34782609, 0.36956522, 0.39130435, 0.41304348,\n",
       "         0.43478261, 0.45652174, 0.47826087, 0.5       , 0.52173913,\n",
       "         0.54347826, 0.56521739, 0.56521739, 0.56521739, 0.58695652,\n",
       "         0.58695652, 0.60869565, 0.63043478, 0.65217391, 0.67391304,\n",
       "         0.67391304, 0.67391304, 0.69565217, 0.69565217, 0.69565217,\n",
       "         0.69565217, 0.69565217, 0.69565217, 0.69565217, 0.69565217,\n",
       "         0.7173913 , 0.7173913 , 0.73913043]),\n",
       "  'precision': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 0.92307692, 0.92857143, 0.93333333,\n",
       "         0.9375    , 0.94117647, 0.94444444, 0.94736842, 0.95      ,\n",
       "         0.95238095, 0.95454545, 0.95652174, 0.95833333, 0.96      ,\n",
       "         0.96153846, 0.96296296, 0.92857143, 0.89655172, 0.9       ,\n",
       "         0.87096774, 0.875     , 0.87878788, 0.88235294, 0.88571429,\n",
       "         0.86111111, 0.83783784, 0.84210526, 0.82051282, 0.8       ,\n",
       "         0.7804878 , 0.76190476, 0.74418605, 0.72727273, 0.71111111,\n",
       "         0.7173913 , 0.70212766, 0.70833333]),\n",
       "  'AP': 0.6810904071773636}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98907a6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T14:23:49.775362Z",
     "iopub.status.busy": "2024-03-08T14:23:49.774364Z",
     "iopub.status.idle": "2024-03-08T14:23:49.778763Z",
     "shell.execute_reply": "2024-03-08T14:23:49.777838Z"
    },
    "id": "itzp-sJcSswM",
    "papermill": {
     "duration": 5.305665,
     "end_time": "2024-03-08T14:23:49.780683",
     "exception": false,
     "start_time": "2024-03-08T14:23:44.475018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# draw_predictions(test_data, pred_bboxes, pred_labels, pred_scores, labels, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358d1463",
   "metadata": {
    "id": "fWtZLX68Zx4-",
    "papermill": {
     "duration": 5.335641,
     "end_time": "2024-03-08T14:24:00.325375",
     "exception": false,
     "start_time": "2024-03-08T14:23:54.989734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21710.755469,
   "end_time": "2024-03-08T14:24:08.466742",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-08T08:22:17.711273",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
