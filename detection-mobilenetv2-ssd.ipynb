{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a5a5f24",
   "metadata": {
    "id": "y1von-1uFPIV",
    "papermill": {
     "duration": 0.016998,
     "end_time": "2024-02-26T02:03:06.338335",
     "exception": false,
     "start_time": "2024-02-26T02:03:06.321337",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# FPN, PAFPN, BiFPN with MobileNetV2\n",
    "\n",
    "Github repo:\n",
    "https://github.com/FurkanOM/tf-ssd/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34a68dd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:03:06.372638Z",
     "iopub.status.busy": "2024-02-26T02:03:06.372283Z",
     "iopub.status.idle": "2024-02-26T02:03:21.263787Z",
     "shell.execute_reply": "2024-02-26T02:03:21.262734Z"
    },
    "papermill": {
     "duration": 14.911528,
     "end_time": "2024-02-26T02:03:21.266347",
     "exception": false,
     "start_time": "2024-02-26T02:03:06.354819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 02:03:08.068302: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-26 02:03:08.068418: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-26 02:03:08.193084: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pathlib\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c871f6b",
   "metadata": {
    "papermill": {
     "duration": 0.017352,
     "end_time": "2024-02-26T02:03:21.300821",
     "exception": false,
     "start_time": "2024-02-26T02:03:21.283469",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# anchor_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9909bf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:03:21.336944Z",
     "iopub.status.busy": "2024-02-26T02:03:21.335857Z",
     "iopub.status.idle": "2024-02-26T02:03:21.353367Z",
     "shell.execute_reply": "2024-02-26T02:03:21.352475Z"
    },
    "id": "D9N9T9kpDwjD",
    "papermill": {
     "duration": 0.037689,
     "end_time": "2024-02-26T02:03:21.355471",
     "exception": false,
     "start_time": "2024-02-26T02:03:21.317782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Generate Anchor Boxes.\n",
    "\"\"\"\n",
    "\n",
    "def get_scale_for_nth_feature_map(k, m=6, scale_min=0.2, scale_max=0.9):\n",
    "    \"\"\"Calculating scale value for nth feature map using the given method in the paper.\n",
    "    inputs:\n",
    "        k = nth feature map for scale calculation\n",
    "        m = length of all using feature maps for detections, 6 for ssd300\n",
    "\n",
    "    outputs:\n",
    "        scale = calculated scale value for given index\n",
    "    \"\"\"\n",
    "    # [0.2, 0.34, 0.48, 0.62, 0.76, 0.9, 1.04]\n",
    "    return scale_min + ((scale_max - scale_min) / (m - 1)) * (k - 1)\n",
    "\n",
    "def generate_base_prior_boxes(aspect_ratios, feature_map_index, total_feature_map, hyper_params):\n",
    "    \"\"\"Generating top left prior boxes for given stride, height and width pairs of different aspect ratios.\n",
    "    These prior boxes same with the anchors in Faster-RCNN.\n",
    "    inputs:\n",
    "        aspect_ratios = for all feature map shapes + 1 for ratio 1\n",
    "        feature_map_index = nth feature maps for scale calculation\n",
    "        total_feature_map = length of all using feature map for detections, 6 for ssd300\n",
    "\n",
    "    outputs:\n",
    "        base_prior_boxes = (prior_box_count, [y1, x1, y2, x2])\n",
    "    \"\"\"\n",
    "    # print(feature_map_index)\n",
    "    if hyper_params[\"use_custom_scale\"]:    \n",
    "        current_scale = hyper_params[\"scale\"][feature_map_index-1]\n",
    "        next_scale = hyper_params[\"scale\"][feature_map_index]\n",
    "    else:\n",
    "        current_scale = get_scale_for_nth_feature_map(feature_map_index, m=total_feature_map, \n",
    "                                                      scale_min=hyper_params[\"scale_min\"], scale_max=hyper_params[\"scale_max\"])\n",
    "        next_scale = get_scale_for_nth_feature_map(feature_map_index + 1, m=total_feature_map, \n",
    "                                                   scale_min=hyper_params[\"scale_min\"], scale_max=hyper_params[\"scale_max\"])\n",
    "    print(current_scale, next_scale)\n",
    "    base_prior_boxes = []\n",
    "    for aspect_ratio in aspect_ratios:\n",
    "        height = current_scale / tf.sqrt(aspect_ratio)\n",
    "        width = current_scale * tf.sqrt(aspect_ratio)\n",
    "        base_prior_boxes.append([-height/2, -width/2, height/2, width/2])\n",
    "#         print(height, width)\n",
    "    # 1 extra pair for ratio 1\n",
    "    height = width = tf.sqrt(current_scale * next_scale)\n",
    "#     print(height, width)\n",
    "    base_prior_boxes.append([-height/2, -width/2, height/2, width/2])\n",
    "    return tf.cast(base_prior_boxes, dtype=tf.float32)\n",
    "\n",
    "def generate_prior_boxes(feature_map_shapes, aspect_ratios, hyper_params):\n",
    "    \"\"\"Generating top left prior boxes for given stride, height and width pairs of different aspect ratios.\n",
    "    These prior boxes same with the anchors in Faster-RCNN.\n",
    "    Aspect ratio is the width to height ratio.\n",
    "    inputs:\n",
    "        feature_map_shapes = for all feature map output size\n",
    "        aspect_ratios = for all feature map shapes + 1 for ratio 1\n",
    "\n",
    "    outputs:\n",
    "        prior_boxes = (total_prior_boxes, [y1, x1, y2, x2])\n",
    "            these values in normalized format between [0, 1]\n",
    "    \"\"\"\n",
    "    prior_boxes = []\n",
    "    for i, feature_map_shape in enumerate(feature_map_shapes):\n",
    "        print(feature_map_shape)\n",
    "        base_prior_boxes = generate_base_prior_boxes(aspect_ratios[i], i+1, len(feature_map_shapes), hyper_params)\n",
    "        print(base_prior_boxes)\n",
    "\n",
    "        stride = 1 / feature_map_shape\n",
    "        # Create linearly spaced arrays of x and y coordinates\n",
    "        grid_coords = tf.cast(tf.range(0, feature_map_shape) / feature_map_shape + stride / 2, dtype=tf.float32)\n",
    "        grid_x, grid_y = tf.meshgrid(grid_coords, grid_coords)\n",
    "        flat_grid_x, flat_grid_y = tf.reshape(grid_x, (-1, )), tf.reshape(grid_y, (-1, ))\n",
    "\n",
    "        grid_map = tf.stack([flat_grid_y, flat_grid_x, flat_grid_y, flat_grid_x], -1)\n",
    "\n",
    "        prior_boxes_for_feature_map = tf.reshape(base_prior_boxes, (1, -1, 4)) + tf.reshape(grid_map, (-1, 1, 4))\n",
    "        prior_boxes_for_feature_map = tf.reshape(prior_boxes_for_feature_map, (-1, 4))\n",
    "        prior_boxes.append(prior_boxes_for_feature_map)\n",
    "        \n",
    "    prior_boxes = tf.concat(prior_boxes, axis=0)\n",
    "    # print(prior_boxes)\n",
    "    return tf.clip_by_value(prior_boxes, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d20872",
   "metadata": {
    "id": "Stm5EzBc79ca",
    "papermill": {
     "duration": 0.016284,
     "end_time": "2024-02-26T02:03:21.388642",
     "exception": false,
     "start_time": "2024-02-26T02:03:21.372358",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aef9999",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:03:21.423634Z",
     "iopub.status.busy": "2024-02-26T02:03:21.423285Z",
     "iopub.status.idle": "2024-02-26T02:03:21.427507Z",
     "shell.execute_reply": "2024-02-26T02:03:21.426620Z"
    },
    "papermill": {
     "duration": 0.024192,
     "end_time": "2024-02-26T02:03:21.429443",
     "exception": false,
     "start_time": "2024-02-26T02:03:21.405251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "backbone = \"mobilenet_v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2691c05f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:03:21.464142Z",
     "iopub.status.busy": "2024-02-26T02:03:21.463817Z",
     "iopub.status.idle": "2024-02-26T02:03:23.754468Z",
     "shell.execute_reply": "2024-02-26T02:03:23.753405Z"
    },
    "id": "AE1YUdJu7_HW",
    "papermill": {
     "duration": 2.310837,
     "end_time": "2024-02-26T02:03:23.756739",
     "exception": false,
     "start_time": "2024-02-26T02:03:21.445902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img_size': 640,\n",
       " 'feature_map_shapes': [160, 80, 40, 20, 10, 5, 3],\n",
       " 'aspect_ratios': [[1.0, 2.0, 0.5, 5.0, 0.2],\n",
       "  [1.0, 2.0, 0.5, 5.0, 0.2],\n",
       "  [1.0, 2.0, 0.5, 5.0, 0.2],\n",
       "  [1.0, 2.0, 0.5, 5.0, 0.2],\n",
       "  [1.0, 2.0, 0.5, 5.0, 0.2],\n",
       "  [1.0, 2.0, 0.5, 5.0, 0.2],\n",
       "  [1.0, 2.0, 0.5, 5.0, 0.2]],\n",
       " 'use_custom_scale': False,\n",
       " 'scale_min': 0.05,\n",
       " 'scale_max': 0.9,\n",
       " 'scale': [0.05, 0.1, 0.2, 0.4, 0.6, 0.8, 1.2],\n",
       " 'trainable': True,\n",
       " 'num_trainable': None,\n",
       " 'detection': 'BiFPN',\n",
       " 'feature_fusion': None,\n",
       " 'dataset': 0,\n",
       " 'iou_threshold': 0.5,\n",
       " 'neg_pos_ratio': 3,\n",
       " 'loc_loss_alpha': 1,\n",
       " 'variances': [0.1, 0.1, 0.2, 0.2],\n",
       " 'use_focal': False,\n",
       " 'alpha': 2.0,\n",
       " 'gamma': 0.25,\n",
       " 'batch_size': 8,\n",
       " 'epochs': 200,\n",
       " 'lr': 1e-05,\n",
       " 'patience': 20}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n",
      "0.05 0.19166666666666665\n",
      "tf.Tensor(\n",
      "[[-0.025      -0.025       0.025       0.025     ]\n",
      " [-0.01767767 -0.03535534  0.01767767  0.03535534]\n",
      " [-0.03535534 -0.01767767  0.03535534  0.01767767]\n",
      " [-0.01118034 -0.0559017   0.01118034  0.0559017 ]\n",
      " [-0.0559017  -0.01118034  0.0559017   0.01118034]\n",
      " [-0.04894725 -0.04894725  0.04894725  0.04894725]], shape=(6, 4), dtype=float32)\n",
      "80\n",
      "0.19166666666666665 0.3333333333333333\n",
      "tf.Tensor(\n",
      "[[-0.09583333 -0.09583333  0.09583333  0.09583333]\n",
      " [-0.0677644  -0.13552879  0.0677644   0.13552879]\n",
      " [-0.1355288  -0.06776439  0.1355288   0.06776439]\n",
      " [-0.04285797 -0.21428983  0.04285797  0.21428983]\n",
      " [-0.21428984 -0.04285797  0.21428984  0.04285797]\n",
      " [-0.12638126 -0.12638126  0.12638126  0.12638126]], shape=(6, 4), dtype=float32)\n",
      "40\n",
      "0.3333333333333333 0.475\n",
      "tf.Tensor(\n",
      "[[-0.16666667 -0.16666667  0.16666667  0.16666667]\n",
      " [-0.11785114 -0.23570226  0.11785114  0.23570226]\n",
      " [-0.23570228 -0.11785113  0.23570228  0.11785113]\n",
      " [-0.07453561 -0.37267798  0.07453561  0.37267798]\n",
      " [-0.372678   -0.0745356   0.372678    0.0745356 ]\n",
      " [-0.1989556  -0.1989556   0.1989556   0.1989556 ]], shape=(6, 4), dtype=float32)\n",
      "20\n",
      "0.475 0.6166666666666667\n",
      "tf.Tensor(\n",
      "[[-0.2375     -0.2375      0.2375      0.2375    ]\n",
      " [-0.16793786 -0.33587572  0.16793786  0.33587572]\n",
      " [-0.33587572 -0.16793786  0.33587572  0.16793786]\n",
      " [-0.10621323 -0.53106606  0.10621323  0.53106606]\n",
      " [-0.5310661  -0.10621323  0.5310661   0.10621323]\n",
      " [-0.27060887 -0.27060887  0.27060887  0.27060887]], shape=(6, 4), dtype=float32)\n",
      "10\n",
      "0.6166666666666667 0.7583333333333333\n",
      "tf.Tensor(\n",
      "[[-0.30833334 -0.30833334  0.30833334  0.30833334]\n",
      " [-0.2180246  -0.4360492   0.2180246   0.4360492 ]\n",
      " [-0.4360492  -0.2180246   0.4360492   0.2180246 ]\n",
      " [-0.13789088 -0.68945426  0.13789088  0.68945426]\n",
      " [-0.6894543  -0.13789086  0.6894543   0.13789086]\n",
      " [-0.34192064 -0.34192064  0.34192064  0.34192064]], shape=(6, 4), dtype=float32)\n",
      "5\n",
      "0.7583333333333333 0.9\n",
      "tf.Tensor(\n",
      "[[-0.37916666 -0.37916666  0.37916666  0.37916666]\n",
      " [-0.26811132 -0.53622264  0.26811132  0.53622264]\n",
      " [-0.53622264 -0.26811132  0.53622264  0.26811132]\n",
      " [-0.16956851 -0.84784234  0.16956851  0.84784234]\n",
      " [-0.84784245 -0.16956848  0.84784245  0.16956848]\n",
      " [-0.4130678  -0.4130678   0.4130678   0.4130678 ]], shape=(6, 4), dtype=float32)\n",
      "3\n",
      "0.9 1.0416666666666667\n",
      "tf.Tensor(\n",
      "[[-0.45       -0.45        0.45        0.45      ]\n",
      " [-0.31819806 -0.63639605  0.31819806  0.63639605]\n",
      " [-0.6363961  -0.31819803  0.6363961   0.31819803]\n",
      " [-0.20124613 -1.0062305   0.20124613  1.0062305 ]\n",
      " [-1.0062306  -0.20124611  1.0062306   0.20124611]\n",
      " [-0.4841229  -0.4841229   0.4841229   0.4841229 ]], shape=(6, 4), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(204804, 4), dtype=float32, numpy=\n",
       "array([[0.        , 0.        , 0.028125  , 0.028125  ],\n",
       "       [0.        , 0.        , 0.02080267, 0.03848034],\n",
       "       [0.        , 0.        , 0.03848034, 0.02080267],\n",
       "       ...,\n",
       "       [0.6320872 , 0.        , 1.        , 1.        ],\n",
       "       [0.        , 0.63208723, 1.        , 1.        ],\n",
       "       [0.3492104 , 0.3492104 , 1.        , 1.        ]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SSD = {\n",
    "#     \"mobilenet_v2\": {\n",
    "#         \"img_size\": 1024,\n",
    "#         \"feature_map_shapes\": [128,64,32,16,8,4],\n",
    "#         \"aspect_ratios\": [[1., 2., 1./2., 5., 1./5.],\n",
    "#                           [1., 2., 1./2., 5., 1./5.],\n",
    "#                           [1., 2., 1./2., 5., 1./5.],\n",
    "#                           [1., 2., 1./2., 5., 1./5.],\n",
    "#                           [1., 2., 1./2., 5., 1./5.],\n",
    "#                           [1., 2., 1./2., 5., 1./5.]],\n",
    "#         \"use_custom_scale\": False,\n",
    "#         \"scale_min\": 0.05,\n",
    "#         \"scale_max\": 0.5,\n",
    "#         \"scale\": [0.05, 0.1, 0.2, 0.4, 0.6, 0.8, 1.2],\n",
    "#         \"trainable\": True,\n",
    "#         \"num_trainable\": None\n",
    "#     },\n",
    "    \"mobilenet_v2\": {\n",
    "        \"img_size\": 640,\n",
    "        \"feature_map_shapes\": [160,80,40,20,10,5,3],\n",
    "        \"aspect_ratios\": [[1., 2., 1./2., 5., 1./5.],\n",
    "                          [1., 2., 1./2., 5., 1./5.],\n",
    "                          [1., 2., 1./2., 5., 1./5.],\n",
    "                          [1., 2., 1./2., 5., 1./5.],\n",
    "                          [1., 2., 1./2., 5., 1./5.],\n",
    "                          [1., 2., 1./2., 5., 1./5.],\n",
    "                          [1., 2., 1./2., 5., 1./5.]],\n",
    "        \"use_custom_scale\": False,\n",
    "        \"scale_min\": 0.05,\n",
    "        \"scale_max\": 0.9,\n",
    "        \"scale\": [0.05, 0.1, 0.2, 0.4, 0.6, 0.8, 1.2],\n",
    "        \"trainable\": True,\n",
    "        \"num_trainable\": None\n",
    "    },\n",
    "#     \"mobilenet_v2\": {\n",
    "#         \"img_size\": 300,\n",
    "#         \"feature_map_shapes\": [38, 19, 10, 5, 3, 2],\n",
    "#         \"aspect_ratios\": [[1., 2., 1./2., 5., 1./5.],\n",
    "#                           [1., 2., 1./2., 5., 1./5.],\n",
    "#                           [1., 2., 1./2., 5., 1./5.],\n",
    "#                           [1., 2., 1./2., 5., 1./5.],\n",
    "#                           [1., 2., 1./2., 5., 1./5.],\n",
    "#                           [1., 2., 1./2., 5., 1./5.]],\n",
    "#         \"use_custom_scale\": False,\n",
    "#         \"scale_min\": 0.05,\n",
    "#         \"scale_max\": 0.5,\n",
    "#         \"scale\": [0.05, 0.1, 0.2, 0.4, 0.6, 0.8, 1.2],\n",
    "#         \"trainable\": True,\n",
    "#         \"num_trainable\": None\n",
    "#     },\n",
    "}\n",
    "\n",
    "def get_hyper_params(backbone, **kwargs):\n",
    "    \"\"\"Generating hyper params in a dynamic way.\n",
    "    inputs:\n",
    "        **kwargs = any value could be updated in the hyper_params\n",
    "\n",
    "    outputs:\n",
    "        hyper_params = dictionary\n",
    "    \"\"\"\n",
    "    hyper_params = SSD[backbone]\n",
    "    hyper_params[\"detection\"] = \"BiFPN\" # None / \"FPN\" / \"BiFPN\" / \"PAFPN\" / \"NASFPN\"\n",
    "    hyper_params[\"feature_fusion\"] = None \n",
    "    hyper_params[\"dataset\"] = 0 # dut, tilda, daffodil, thesis, combined\n",
    "    hyper_params[\"iou_threshold\"] = 0.5\n",
    "    hyper_params[\"neg_pos_ratio\"] = 3 # neg:pos 3:1 ratio\n",
    "    hyper_params[\"loc_loss_alpha\"] = 1 # weight for the localization loss\n",
    "    hyper_params[\"variances\"] = [0.1, 0.1, 0.2, 0.2]\n",
    "    hyper_params[\"use_focal\"] = False\n",
    "    hyper_params[\"alpha\"] = 2.0\n",
    "    hyper_params[\"gamma\"] = 0.25\n",
    "    hyper_params[\"batch_size\"] = 8\n",
    "    hyper_params[\"epochs\"] = 200\n",
    "    hyper_params[\"lr\"] = 1e-5\n",
    "    hyper_params[\"patience\"] = 20\n",
    "    # overwrite any parameters\n",
    "    for key, value in kwargs.items():\n",
    "        if key in hyper_params and value:\n",
    "            hyper_params[key] = value\n",
    "\n",
    "    return hyper_params\n",
    "\n",
    "hyper_params = get_hyper_params(backbone)\n",
    "display(hyper_params)\n",
    "\n",
    "# We calculate prior boxes for one time and use it for all operations because of the all images are the same sizes\n",
    "prior_boxes = generate_prior_boxes(hyper_params[\"feature_map_shapes\"], hyper_params[\"aspect_ratios\"], hyper_params)\n",
    "display(prior_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98bf3c20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:03:23.793817Z",
     "iopub.status.busy": "2024-02-26T02:03:23.793446Z",
     "iopub.status.idle": "2024-02-26T02:03:23.800947Z",
     "shell.execute_reply": "2024-02-26T02:03:23.799832Z"
    },
    "papermill": {
     "duration": 0.029484,
     "end_time": "2024-02-26T02:03:23.804056",
     "exception": false,
     "start_time": "2024-02-26T02:03:23.774572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sanity Check \n",
    "assert isinstance(hyper_params[\"dataset\"], int) and -1 < hyper_params[\"dataset\"] < 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49189080",
   "metadata": {
    "id": "nmkV2S7HGtZ8",
    "papermill": {
     "duration": 0.023469,
     "end_time": "2024-02-26T02:03:23.851555",
     "exception": false,
     "start_time": "2024-02-26T02:03:23.828086",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MobileNetV2 SSD\n",
    "\n",
    "Specified backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bc0bc29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:03:23.891793Z",
     "iopub.status.busy": "2024-02-26T02:03:23.891417Z",
     "iopub.status.idle": "2024-02-26T02:03:23.899001Z",
     "shell.execute_reply": "2024-02-26T02:03:23.898087Z"
    },
    "id": "qLVgx-fklhgd",
    "papermill": {
     "duration": 0.028636,
     "end_time": "2024-02-26T02:03:23.901415",
     "exception": false,
     "start_time": "2024-02-26T02:03:23.872779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conv_layer(filter, kernel_size,\n",
    "               layer, strides=1,\n",
    "               padding='same',\n",
    "               activation='linear',\n",
    "               name='conv2d',pool=False,\n",
    "               poolsize=2,poolstride=2,conv=True):\n",
    "    if conv == True:\n",
    "        layer = tf.keras.layers.Conv2D(filters=filter,\n",
    "                                    kernel_size=kernel_size,\n",
    "                                    strides=strides,\n",
    "                                    activation=activation,\n",
    "                                    padding=padding,\n",
    "                                    name=name,\n",
    "                                    kernel_initializer='he_normal')(layer)\n",
    "        layer = tf.keras.layers.BatchNormalization()(layer)\n",
    "        layer = tf.keras.layers.ReLU()(layer)\n",
    "    elif pool == True:\n",
    "        layer=tf.keras.layers.MaxPool2D(pool_size=(poolsize, poolsize),\n",
    "                                        strides=poolstride, padding='same')(layer)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b4920f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:03:23.940665Z",
     "iopub.status.busy": "2024-02-26T02:03:23.940160Z",
     "iopub.status.idle": "2024-02-26T02:03:24.066337Z",
     "shell.execute_reply": "2024-02-26T02:03:24.065426Z"
    },
    "id": "yApDXEFhKhJb",
    "papermill": {
     "duration": 0.147033,
     "end_time": "2024-02-26T02:03:24.068686",
     "exception": false,
     "start_time": "2024-02-26T02:03:23.921653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def get_model(hyper_params):\n",
    "    \"\"\"Generating ssd model for hyper params.\n",
    "    inputs:\n",
    "        hyper_params = dictionary\n",
    "\n",
    "    outputs:\n",
    "        ssd_model = tf.keras.model\n",
    "    \"\"\"\n",
    "    img_size = hyper_params[\"img_size\"]\n",
    "    num_classes = hyper_params[\"total_labels\"]\n",
    "    base_model = MobileNetV2(include_top=False, input_shape=(img_size, img_size, 3))\n",
    "    \n",
    "    if hyper_params[\"trainable\"]:\n",
    "        base_model.trainable = True\n",
    "        if hyper_params[\"num_trainable\"] != None:\n",
    "            for layer in base_model.layers[:-hyper_params[\"num_trainable\"]]:\n",
    "                layer.trainable = False\n",
    "    else: base_model.trainable = False\n",
    "\n",
    "    input = base_model.input\n",
    "\n",
    "    zero_conv = base_model.get_layer(\"block_6_expand_relu\").output # 128x128x192\n",
    "    first_conv = base_model.get_layer(\"block_13_expand_relu\").output # 64x64x576\n",
    "    second_conv = base_model.output # 32x32x1280\n",
    "    \n",
    "    # first_conv = base_model.get_layer(\"block_13_expand_relu\").output # 19 x 19 x 576\n",
    "    # second_conv = base_model.output # 10 x 10 x 1280\n",
    "    \n",
    "    ############################ Extra Feature Layers Start ############################\n",
    "    extra1_1 = conv_layer(256, (1, 1), strides=(1, 1), padding=\"valid\", activation=\"relu\", name=\"extra1_1\", layer=second_conv)\n",
    "    extra1_2 = conv_layer(512, (3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\", name=\"extra1_2\", layer=extra1_1)\n",
    "\n",
    "    extra2_1 = conv_layer(128, (1, 1), strides=(1, 1), padding=\"valid\", activation=\"relu\", name=\"extra2_1\", layer=extra1_2)\n",
    "    extra2_2 = conv_layer(256, (3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\", name=\"extra2_2\", layer=extra2_1)\n",
    "\n",
    "    extra3_1 = conv_layer(128, (1, 1), strides=(1, 1), padding=\"valid\", activation=\"relu\", name=\"extra3_1\", layer=extra2_2)\n",
    "    extra3_2 = conv_layer(256, (3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\", name=\"extra3_2\", layer=extra3_1)\n",
    "    \n",
    "#     extra4_1 = conv_layer(128, (1, 1), strides=(1, 1), padding=\"valid\", activation=\"relu\", name=\"extra4_1\", layer=extra3_2)\n",
    "#     extra4_2 = conv_layer(256, (3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\", name=\"extra4_2\", layer=extra4_1)\n",
    "    ############################ Extra Feature Layers End ############################\n",
    "    \n",
    "    pred_deltas, pred_labels = get_head_from_outputs(hyper_params, [zero_conv, first_conv, second_conv, extra1_2, extra2_2, extra3_2])\n",
    "#     pred_deltas, pred_labels = get_head_from_outputs(hyper_params, [first_conv, second_conv, extra1_2, extra2_2, extra3_2, extra4_2])\n",
    "    return Model(inputs=input, outputs=[pred_deltas, pred_labels])\n",
    "\n",
    "def init_model(model, img_size):\n",
    "    \"\"\"Initializing model with dummy data for load weights with optimizer state and also graph construction.\n",
    "    inputs:\n",
    "        model = tf.keras.model\n",
    "\n",
    "    \"\"\"\n",
    "    model(tf.random.uniform((1, img_size, img_size, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6ec4c7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:03:24.105801Z",
     "iopub.status.busy": "2024-02-26T02:03:24.105280Z",
     "iopub.status.idle": "2024-02-26T02:03:24.125589Z",
     "shell.execute_reply": "2024-02-26T02:03:24.124650Z"
    },
    "papermill": {
     "duration": 0.041793,
     "end_time": "2024-02-26T02:03:24.128243",
     "exception": false,
     "start_time": "2024-02-26T02:03:24.086450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "FPN model for Keras.\n",
    "\n",
    "# Reference:\n",
    "- [Feature Pyramid Networks for Object Detection](\n",
    "    https://arxiv.org/abs/1612.03144)\n",
    "\n",
    "'''\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D, MaxPooling2D\n",
    "\n",
    "class FPN(tf.keras.Model):\n",
    "    def __init__(self, out_channels=256, **kwargs):\n",
    "        '''Feature Pyramid Networks.\n",
    "\n",
    "        inputs:\n",
    "            out_channels (int): the channels of pyramid feature maps.\n",
    "        '''\n",
    "        super(FPN, self).__init__(**kwargs)\n",
    "        self.out_channels = out_channels\n",
    "        self.fpn_c2p2 = Conv2D(out_channels, (1, 1),\n",
    "                              kernel_initializer='he_normal', name='fpn_c2p2')\n",
    "        self.fpn_c3p3 = Conv2D(out_channels, (1, 1),\n",
    "                              kernel_initializer='he_normal', name='fpn_c3p3')\n",
    "        self.fpn_c4p4 = Conv2D(out_channels, (1, 1),\n",
    "                              kernel_initializer='he_normal', name='fpn_c4p4')\n",
    "        self.fpn_c5p5 = Conv2D(out_channels, (1, 1),\n",
    "                              kernel_initializer='he_normal', name='fpn_c5p5')\n",
    "\n",
    "        self.fpn_p3upsampled = UpSampling2D(size=(2, 2), name='fpn_p3upsampled')\n",
    "        self.fpn_p4upsampled = UpSampling2D(size=(2, 2), name='fpn_p4upsampled')\n",
    "        self.fpn_p5upsampled = UpSampling2D(size=(2, 2), name='fpn_p5upsampled')\n",
    "\n",
    "\n",
    "        self.fpn_p2 = Conv2D(out_channels, (3, 3), padding=\"same\",\n",
    "                                    kernel_initializer='he_normal', name='fpn_p2')\n",
    "        self.fpn_p3 = Conv2D(out_channels, (3, 3), padding=\"same\",\n",
    "                                    kernel_initializer='he_normal', name='fpn_p3')\n",
    "        self.fpn_p4 = Conv2D(out_channels, (3, 3), padding=\"same\",\n",
    "                                    kernel_initializer='he_normal', name='fpn_p4')\n",
    "        self.fpn_p5 = Conv2D(out_channels, (3, 3), padding=\"same\",\n",
    "                                    kernel_initializer='he_normal', name='fpn_p5')\n",
    "\n",
    "#         self.fpn_p6 = MaxPooling2D(pool_size=(1, 1), strides=2, name='fpn_p6')\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        C2, C3, C4, C5 = inputs\n",
    "\n",
    "        P5 = self.fpn_c5p5(C5)\n",
    "        P4 = self.fpn_c4p4(C4) + self.fpn_p5upsampled(P5)\n",
    "        P3 = self.fpn_c3p3(C3) + self.fpn_p4upsampled(P4)\n",
    "        P2 = self.fpn_c2p2(C2) + self.fpn_p3upsampled(P3)\n",
    "\n",
    "        # Attach 3x3 conv to all P layers to get the final feature maps.\n",
    "        P2 = self.fpn_p2(P2)\n",
    "        P3 = self.fpn_p3(P3)\n",
    "        P4 = self.fpn_p4(P4)\n",
    "        P5 = self.fpn_p5(P5)\n",
    "\n",
    "        # Subsampling from P5 with stride of 2.\n",
    "#         P6 = self.fpn_p6(P5)\n",
    "\n",
    "        return [P2, P3, P4, P5]\n",
    "#         return [P2, P3, P4, P5, P6]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        C2_shape, C3_shape, C4_shape, C5_shape = input_shape\n",
    "\n",
    "        C2_shape, C3_shape, C4_shape, C5_shape = \\\n",
    "            C2_shape.as_list(), C3_shape.as_list(), C4_shape.as_list(), C5_shape.as_list()\n",
    "\n",
    "#         C6_shape = [C5_shape[0], (C5_shape[1] + 1) // 2, (C5_shape[2] + 1) // 2, self.out_channels]\n",
    "\n",
    "        C2_shape[-1] = self.out_channels\n",
    "        C3_shape[-1] = self.out_channels\n",
    "        C4_shape[-1] = self.out_channels\n",
    "        C5_shape[-1] = self.out_channels\n",
    "\n",
    "        return [tf.TensorShape(C2_shape),\n",
    "                tf.TensorShape(C3_shape),\n",
    "                tf.TensorShape(C4_shape),\n",
    "                tf.TensorShape(C5_shape),]\n",
    "#                 tf.TensorShape(C6_shape)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41ba872c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:03:24.174888Z",
     "iopub.status.busy": "2024-02-26T02:03:24.174535Z",
     "iopub.status.idle": "2024-02-26T02:03:24.187608Z",
     "shell.execute_reply": "2024-02-26T02:03:24.186639Z"
    },
    "papermill": {
     "duration": 0.040786,
     "end_time": "2024-02-26T02:03:24.189673",
     "exception": false,
     "start_time": "2024-02-26T02:03:24.148887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def get_fpnmodel(hyper_params):\n",
    "    \"\"\"Generating ssd model for hyper params.\n",
    "    inputs:\n",
    "        hyper_params = dictionary\n",
    "\n",
    "    outputs:\n",
    "        ssd_model = tf.keras.model\n",
    "    \"\"\"\n",
    "    img_size = hyper_params[\"img_size\"]\n",
    "    base_model = MobileNetV2(include_top=False, input_shape=(img_size, img_size, 3))\n",
    "    base_model.trainable = True\n",
    "\n",
    "    input = base_model.input\n",
    "\n",
    "    C2 = base_model.get_layer(\"block_3_expand_relu\").output\n",
    "    C3 = base_model.get_layer(\"block_6_expand_relu\").output\n",
    "    C4 = base_model.get_layer(\"block_13_expand_relu\").output\n",
    "    C5 = base_model.output\n",
    "\n",
    "    fpn = FPN()\n",
    "\n",
    "    P2, P3, P4, P5 = fpn([C2, C3, C4, C5])\n",
    "#     P2, P3, P4, P5, P6 = fpn([C2, C3, C4, C5])\n",
    "  \n",
    "    ############################ Extra Feature Layers Start ############################\n",
    "    extra1_1 = conv_layer(256, (1, 1), strides=(1, 1), padding=\"valid\", activation=\"relu\", name=\"extra1_1\", layer=C5)\n",
    "    extra1_2 = conv_layer(512, (3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\", name=\"extra1_2\", layer=extra1_1)\n",
    "\n",
    "    extra2_1 = conv_layer(128, (1, 1), strides=(1, 1), padding=\"valid\", activation=\"relu\", name=\"extra2_1\", layer=extra1_2)\n",
    "    extra2_2 = conv_layer(256, (3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\", name=\"extra2_2\", layer=extra2_1)\n",
    "\n",
    "    extra3_1 = conv_layer(128, (1, 1), strides=(1, 1), padding=\"valid\", activation=\"relu\", name=\"extra3_1\", layer=extra2_2)\n",
    "    extra3_2 = conv_layer(256, (3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\", name=\"extra3_2\", layer=extra3_1)\n",
    "    \n",
    "#     extra4_1 = conv_layer(128, (1, 1), strides=(1, 1), padding=\"valid\", activation=\"relu\", name=\"extra4_1\", layer=extra3_2)\n",
    "#     extra4_2 = conv_layer(256, (3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\", name=\"extra4_2\", layer=extra4_1)\n",
    "    \n",
    "    \n",
    "    pred_deltas, pred_labels = get_head_from_outputs(hyper_params, [P2, P3, P4, P5, extra1_2, extra2_2, extra3_2])\n",
    "#     pred_deltas, pred_labels = get_head_from_outputs(hyper_params, [P2, P3, P4, P5, P6])\n",
    "    return Model(inputs=input, outputs=[pred_deltas, pred_labels])\n",
    "\n",
    "def init_model(model, img_size=640):\n",
    "    \"\"\"Initializing model with dummy data for load weights with optimizer state and also graph construction.\n",
    "    inputs:\n",
    "        model = tf.keras.model\n",
    "\n",
    "    \"\"\"\n",
    "    model(tf.random.uniform((1, img_size, img_size, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6b795c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:03:24.331780Z",
     "iopub.status.busy": "2024-02-26T02:03:24.331159Z",
     "iopub.status.idle": "2024-02-26T02:03:24.355734Z",
     "shell.execute_reply": "2024-02-26T02:03:24.354935Z"
    },
    "papermill": {
     "duration": 0.045817,
     "end_time": "2024-02-26T02:03:24.357771",
     "exception": false,
     "start_time": "2024-02-26T02:03:24.311954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "PAFPN model for Keras.\n",
    "'''\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D, MaxPooling2D, Concatenate\n",
    "\n",
    "class PAFPN(tf.keras.Model):\n",
    "    def __init__(self, out_channels=256, **kwargs):\n",
    "        super(PAFPN, self).__init__(**kwargs)\n",
    "        self.out_channels = out_channels\n",
    "        self.fpn_c2p2 = Conv2D(out_channels, (1, 1),\n",
    "                              kernel_initializer='he_normal', name='fpn_c2p2')\n",
    "        self.fpn_c3p3 = Conv2D(out_channels, (1, 1),\n",
    "                              kernel_initializer='he_normal', name='fpn_c3p3')\n",
    "        self.fpn_c4p4 = Conv2D(out_channels, (1, 1),\n",
    "                              kernel_initializer='he_normal', name='fpn_c4p4')\n",
    "        self.fpn_c5p5 = Conv2D(out_channels, (1, 1),\n",
    "                              kernel_initializer='he_normal', name='fpn_c5p5')\n",
    "\n",
    "        self.fpn_p3upsampled = UpSampling2D(size=(2, 2), name='fpn_p3upsampled')\n",
    "        self.fpn_p4upsampled = UpSampling2D(size=(2, 2), name='fpn_p4upsampled')\n",
    "        self.fpn_p5upsampled = UpSampling2D(size=(2, 2), name='fpn_p5upsampled')\n",
    "\n",
    "        self.fpn_p2 = Conv2D(out_channels, (3, 3), padding=\"same\",\n",
    "                                    kernel_initializer='he_normal', name='fpn_p2')\n",
    "        self.fpn_p3 = Conv2D(out_channels, (3, 3), padding=\"same\",\n",
    "                                    kernel_initializer='he_normal', name='fpn_p3')\n",
    "        self.fpn_p4 = Conv2D(out_channels, (3, 3), padding=\"same\",\n",
    "                                    kernel_initializer='he_normal', name='fpn_p4')\n",
    "        self.fpn_p5 = Conv2D(out_channels, (3, 3), padding=\"same\",\n",
    "                                    kernel_initializer='he_normal', name='fpn_p5')\n",
    "\n",
    "        self.pafpn_n2downsampled = MaxPooling2D(pool_size=(2, 2), name='pafpn_n2downsampled')\n",
    "        self.pafpn_n3downsampled = MaxPooling2D(pool_size=(2, 2), name='pafpn_n3downsampled')\n",
    "        self.pafpn_n4downsampled = MaxPooling2D(pool_size=(2, 2), name='pafpn_n4downsampled')\n",
    "\n",
    "        self.pafpn_p2p3 = Concatenate(axis=-1)\n",
    "        self.pafpn_p3p4 = Concatenate(axis=-1)\n",
    "        self.pafpn_p4p5 = Concatenate(axis=-1)\n",
    "\n",
    "        self.pafpn_p2n2 = Conv2D(out_channels, (1, 1),\n",
    "                              kernel_initializer='he_normal', name='pafpn_p2n2')\n",
    "        self.pafpn_n2 = Conv2D(out_channels, (3, 3), padding=\"same\",\n",
    "                                    kernel_initializer='he_normal', name='pafpn_n2')\n",
    "        self.pafpn_p3n3 = Conv2D(out_channels, (1, 1),\n",
    "                              kernel_initializer='he_normal', name='pafpn_p3n3')\n",
    "        self.pafpn_n3 = Conv2D(out_channels, (3, 3), padding=\"same\",\n",
    "                                    kernel_initializer='he_normal', name='pafpn_n3')\n",
    "        self.pafpn_p4n4 = Conv2D(out_channels, (1, 1),\n",
    "                              kernel_initializer='he_normal', name='pafpn_p4n4')\n",
    "        self.pafpn_n4 = Conv2D(out_channels, (3, 3), padding=\"same\",\n",
    "                                    kernel_initializer='he_normal', name='pafpn_n4')\n",
    "        self.pafpn_p5n5 = Conv2D(out_channels, (1, 1),\n",
    "                              kernel_initializer='he_normal', name='pafpn_p5n5')\n",
    "        self.pafpn_n5 = Conv2D(out_channels, (3, 3), padding=\"same\",\n",
    "                                    kernel_initializer='he_normal', name='pafpn_n5')\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        C2, C3, C4, C5 = inputs\n",
    "\n",
    "        P5 = self.fpn_c5p5(C5)\n",
    "        P4 = self.fpn_c4p4(C4) + self.fpn_p5upsampled(P5)\n",
    "        P3 = self.fpn_c3p3(C3) + self.fpn_p4upsampled(P4)\n",
    "        P2 = self.fpn_c2p2(C2) + self.fpn_p3upsampled(P3)\n",
    "\n",
    "        # Attach 3x3 conv to all P layers to get the final feature maps.\n",
    "        P2 = self.fpn_p2(P2)\n",
    "        P3 = self.fpn_p3(P3)\n",
    "        P4 = self.fpn_p4(P4)\n",
    "        P5 = self.fpn_p5(P5)\n",
    "\n",
    "        N2 = self.pafpn_p2n2(P2)\n",
    "        P3 = self.pafpn_p2p3([self.pafpn_n2downsampled(N2), P3])\n",
    "        N3 = self.pafpn_p3n3(P3)\n",
    "        P4 = self.pafpn_p3p4([self.pafpn_n3downsampled(N3), P4])\n",
    "        N4 = self.pafpn_p4n4(P4)\n",
    "        P5 = self.pafpn_p4p5([self.pafpn_n4downsampled(N4), P5])\n",
    "        N5 = self.pafpn_p5n5(P5)\n",
    "\n",
    "        N2 = self.pafpn_n2(N2)\n",
    "        N3 = self.pafpn_n3(N3)\n",
    "        N4 = self.pafpn_n4(N4)\n",
    "        N5 = self.pafpn_n5(N5)\n",
    "\n",
    "        return [N2, N3, N4, N5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7da75e77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:03:24.393905Z",
     "iopub.status.busy": "2024-02-26T02:03:24.393084Z",
     "iopub.status.idle": "2024-02-26T02:03:24.401215Z",
     "shell.execute_reply": "2024-02-26T02:03:24.400261Z"
    },
    "papermill": {
     "duration": 0.027995,
     "end_time": "2024-02-26T02:03:24.403066",
     "exception": false,
     "start_time": "2024-02-26T02:03:24.375071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def get_pafpnmodel(hyper_params):\n",
    "    \"\"\"Generating ssd model for hyper params.\n",
    "    inputs:\n",
    "        hyper_params = dictionary\n",
    "\n",
    "    outputs:\n",
    "        ssd_model = tf.keras.model\n",
    "    \"\"\"\n",
    "    img_size = hyper_params[\"img_size\"]\n",
    "    base_model = MobileNetV2(include_top=False, input_shape=(img_size, img_size, 3))\n",
    "    base_model.trainable = True\n",
    "\n",
    "    input = base_model.input\n",
    "\n",
    "    C2 = base_model.get_layer(\"block_3_expand_relu\").output\n",
    "    C3 = base_model.get_layer(\"block_6_expand_relu\").output\n",
    "    C4 = base_model.get_layer(\"block_13_expand_relu\").output\n",
    "    C5 = base_model.output\n",
    "\n",
    "    pafpn = PAFPN()\n",
    "\n",
    "    N2, N3, N4, N5 = pafpn([C2, C3, C4, C5])\n",
    "    \n",
    "    ############################ Extra Feature Layers Start ############################\n",
    "    extra1_1 = conv_layer(256, (1, 1), strides=(1, 1), padding=\"valid\", activation=\"relu\", name=\"extra1_1\", layer=C5)\n",
    "    extra1_2 = conv_layer(512, (3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\", name=\"extra1_2\", layer=extra1_1)\n",
    "\n",
    "    extra2_1 = conv_layer(128, (1, 1), strides=(1, 1), padding=\"valid\", activation=\"relu\", name=\"extra2_1\", layer=extra1_2)\n",
    "    extra2_2 = conv_layer(256, (3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\", name=\"extra2_2\", layer=extra2_1)\n",
    "\n",
    "    extra3_1 = conv_layer(128, (1, 1), strides=(1, 1), padding=\"valid\", activation=\"relu\", name=\"extra3_1\", layer=extra2_2)\n",
    "    extra3_2 = conv_layer(256, (3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\", name=\"extra3_2\", layer=extra3_1)\n",
    "    ############################ Extra Feature Layers End ############################\n",
    "    \n",
    "    pred_deltas, pred_labels = get_head_from_outputs(hyper_params, [N2, N3, N4, N5, extra1_2, extra2_2, extra3_2])\n",
    "#     pred_deltas, pred_labels = get_head_from_outputs(hyper_params, [N2, N3, N4, N5])\n",
    "\n",
    "    return Model(inputs=input, outputs=[pred_deltas, pred_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c185a12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:03:24.440240Z",
     "iopub.status.busy": "2024-02-26T02:03:24.439956Z",
     "iopub.status.idle": "2024-02-26T02:03:24.472356Z",
     "shell.execute_reply": "2024-02-26T02:03:24.471643Z"
    },
    "papermill": {
     "duration": 0.053703,
     "end_time": "2024-02-26T02:03:24.474805",
     "exception": false,
     "start_time": "2024-02-26T02:03:24.421102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Implementations of BiFPN used in EfficientDet.\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "class BiFPNLayerNode(tf.keras.layers.Layer):\n",
    "    \"\"\"One node in BiFPN for features fusing.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 channels=64,\n",
    "                 kernel_size=3,\n",
    "                 depth_multiplier=1,\n",
    "                 name='BiFPN_node'):\n",
    "        \"\"\"Ininitialize node.\n",
    "\n",
    "        Args:\n",
    "            channels: an integer representing number of units inside the node.\n",
    "            kernel_size: an integer or tuple/list of 2 integers, specifying\n",
    "                the height and width of the 2D convolution window.\n",
    "            depth_multiplier: an integer representing depth multiplier for\n",
    "                separable convolution layer.\n",
    "            name: a string representing layer name.\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "        self.channels = channels\n",
    "        self.depth_multiplier = depth_multiplier\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "    def build(self, inputs):\n",
    "        self.w = self.add_weight(\n",
    "            shape=(len(inputs), self.channels),\n",
    "            initializer=\"ones\",\n",
    "            name='sum_weights',\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "        self.conv2d = tf.keras.layers.SeparableConv2D(\n",
    "            self.channels,\n",
    "            self.kernel_size,\n",
    "            padding='same',\n",
    "            depth_multiplier=self.depth_multiplier,\n",
    "            pointwise_initializer=tf.initializers.variance_scaling(),\n",
    "            depthwise_initializer=tf.initializers.variance_scaling(),\n",
    "            name='node_conv'\n",
    "        )\n",
    "\n",
    "        self.bn = tf.keras.layers.BatchNormalization()\n",
    "        self.act = tf.keras.layers.Activation(tf.nn.silu)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        \"\"\"Fuse features.\n",
    "\n",
    "        Args:\n",
    "            inputs: a list with length equal to self.w.shape[0] of feature maps\n",
    "                with equal shapes.\n",
    "\n",
    "        Returns:\n",
    "            A float tensor of fused features after applying convolution\n",
    "            with batch normalization and SiLU activation.\n",
    "        \"\"\"\n",
    "        norm = tf.math.reduce_sum(self.w, axis=0) + 1e-4\n",
    "        scaled_tensors = [inputs[i] * self.w[i] / norm for i in range(self.w.shape[0])]\n",
    "        w_sum = tf.math.add_n(scaled_tensors)\n",
    "        conv = self.conv2d(w_sum)\n",
    "        bn = self.bn(conv, training=training)\n",
    "        return self.act(bn)\n",
    "\n",
    "\n",
    "class BiFPNLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"One layer of BiFPN.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 channels=64,\n",
    "                 kernel_size=3,\n",
    "                 depth_multiplier=1,\n",
    "                 pooling_strategy='avg',\n",
    "                 name='BiFPN_Layer'):\n",
    "        \"\"\"Initialize BiFPN layer.\n",
    "\n",
    "        Args:\n",
    "            channels: an integer representing number of units inside each fusing node.\n",
    "            kernel_size: an integer or tuple/list of 2 integers, specifying\n",
    "                the height and width of the 2D convolution window.\n",
    "            depth_multiplier: an integer representing depth multiplier for\n",
    "                separable convolution layers in BiFPN nodes.\n",
    "            pooling_strategy: a string representing pooling strategy.\n",
    "                'avg' or 'max'. Otherwise the max pooling will be selected.\n",
    "            name: a string representing layer name.\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "        self.pooling_strategy = pooling_strategy\n",
    "\n",
    "        self.first_step_nodes = [BiFPNLayerNode(channels=channels,\n",
    "                                                kernel_size=kernel_size,\n",
    "                                                depth_multiplier=depth_multiplier,\n",
    "                                                name=f'step_1_level_{i}_node') for i in range(4, 7)]\n",
    "        self.second_step_nodes = [BiFPNLayerNode(channels=channels,\n",
    "                                                 kernel_size=kernel_size,\n",
    "                                                 depth_multiplier=depth_multiplier,\n",
    "                                                 name=f'step_2_level_{i}_node') for i in range(3, 8)]\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        \"\"\"Perfrom features fusing from different levels.\"\"\"\n",
    "\n",
    "        upscaled = self._upscale2d(inputs[-1])\n",
    "        first_step_outs = [self.first_step_nodes[-1]([inputs[-2], upscaled], training=training)]\n",
    "        for i in range(2):\n",
    "            upscaled = self._upscale2d(first_step_outs[i])\n",
    "            fused = self.first_step_nodes[1-i]([inputs[-3-i], upscaled])\n",
    "            first_step_outs.append(fused)\n",
    "\n",
    "        upscaled = self._upscale2d(first_step_outs[-1])\n",
    "        second_step_outs = [self.second_step_nodes[0]([inputs[0], upscaled])]\n",
    "        for i in range(1, 4):\n",
    "            downscaled = self._pool2d(second_step_outs[-1])\n",
    "            fused = self.second_step_nodes[i]([inputs[i], first_step_outs[3-i], downscaled], training=training)\n",
    "            second_step_outs.append(fused)\n",
    "        downscaled = self._pool2d(second_step_outs[-1])\n",
    "        fused = self.second_step_nodes[-1]([inputs[-1], downscaled])\n",
    "        second_step_outs.append(fused)\n",
    "\n",
    "        return second_step_outs\n",
    "\n",
    "    def _pool2d(self, inputs):\n",
    "        if self.pooling_strategy == 'avg':\n",
    "            return tf.keras.layers.AveragePooling2D()(inputs)\n",
    "        else:\n",
    "            return tf.keras.layers.MaxPool2D()(inputs)\n",
    "\n",
    "    def _upscale2d(self, inputs):\n",
    "        return tf.keras.layers.UpSampling2D()(inputs)\n",
    "\n",
    "\n",
    "class BiFPN(tf.keras.layers.Layer):\n",
    "    \"\"\"Bidirectional Feature Pyramid Network.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 channels=64,\n",
    "                 depth=3,\n",
    "                 kernel_size=3,\n",
    "                 depth_multiplier=1,\n",
    "                 pooling_strategy='avg',\n",
    "                 name='BiFPN'):\n",
    "        super().__init__(name=name)\n",
    "        \"\"\"Initialize BiFPN.\n",
    "\n",
    "        Args:\n",
    "            channels: an integer representing number of units inside each fusing node\n",
    "                and convolution layer.\n",
    "            depth: an integer representing number of BiFPN layers. depth > 0.\n",
    "            kernel_size: an integer or tuple/list of 2 integers, specifying\n",
    "                the height and width of the 2D convolution window.\n",
    "            depth_multiplier: an integer representing depth multiplier for\n",
    "                separable convolution layers in BiFPN nodes.\n",
    "            pooling_strategy: a string representing pooling strategy in BiFPN layers.\n",
    "                'avg' or 'max'. Otherwise the max pooling will be selected.\n",
    "            name: a string representing layer name.\n",
    "        \"\"\"\n",
    "        self.depth = depth\n",
    "        self.channels = channels\n",
    "        self.pooling_strategy = pooling_strategy\n",
    "\n",
    "        self.convs_1x1 = [tf.keras.layers.Conv2D(channels,\n",
    "                                                 1,\n",
    "                                                 padding='same',\n",
    "                                                 name=f'1x1_conv_level_{3+i}') for i in range(5)]\n",
    "\n",
    "        self.bns = [\n",
    "            tf.keras.layers.BatchNormalization(name=f'bn_level_{i}') for i in range(5)\n",
    "        ]\n",
    "        self.act = tf.keras.layers.Activation(tf.nn.silu)\n",
    "\n",
    "        self.bifpn_layers = [BiFPNLayer(channels=channels,\n",
    "                                        kernel_size=kernel_size,\n",
    "                                        depth_multiplier=depth_multiplier,\n",
    "                                        pooling_strategy=pooling_strategy,\n",
    "                                        name=f'BiFPN_Layer_{i}') for i in range(depth)]\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        assert len(inputs) == 5\n",
    "\n",
    "        squeezed = [self.convs_1x1[i](inputs[i]) for i in range(5)]\n",
    "        normalized = [self.bns[i](squeezed[i], training=training) for i in range(5)]\n",
    "        activated = [self.act(normalized[i]) for i in range(5)]\n",
    "        feature_maps = self.bifpn_layers[0](activated, training=training)\n",
    "        for layer in self.bifpn_layers[1:]:\n",
    "            feature_maps = layer(feature_maps, training=training)\n",
    "\n",
    "        return feature_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5193f837",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:03:24.518052Z",
     "iopub.status.busy": "2024-02-26T02:03:24.517562Z",
     "iopub.status.idle": "2024-02-26T02:03:24.537676Z",
     "shell.execute_reply": "2024-02-26T02:03:24.536647Z"
    },
    "papermill": {
     "duration": 0.041876,
     "end_time": "2024-02-26T02:03:24.539715",
     "exception": false,
     "start_time": "2024-02-26T02:03:24.497839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def get_bifpnmodel(hyper_params, channels=64,\n",
    "                 bifpn_depth=3,\n",
    "                 bifpn_kernel_size=3,\n",
    "                 bifpn_depth_multiplier=1,\n",
    "                 bifpn_pooling_strategy='avg',\n",
    "                 num_anchors=9,\n",
    "                 heads_depth=3,\n",
    "                 class_kernel_size=3,\n",
    "                 class_depth_multiplier=1,\n",
    "                 box_kernel_size=3,\n",
    "                 box_depth_multiplier=1):\n",
    "\n",
    "    img_size = hyper_params[\"img_size\"]\n",
    "    num_classes = hyper_params[\"total_labels\"]\n",
    "    base_model = MobileNetV2(include_top=False, input_shape=(img_size, img_size, 3))\n",
    "    base_model.trainable = True\n",
    "\n",
    "    input = base_model.input\n",
    "\n",
    "    C2 = base_model.get_layer(\"block_3_expand_relu\").output\n",
    "    C3 = base_model.get_layer(\"block_6_expand_relu\").output\n",
    "    C4 = base_model.get_layer(\"block_13_expand_relu\").output\n",
    "    C5 = base_model.output\n",
    "    C6 = AveragePooling2D(pool_size=(2, 2), padding='same')(C5)\n",
    "\n",
    "    bifpn = BiFPN(channels=channels,\n",
    "                  depth=bifpn_depth,\n",
    "                  kernel_size=bifpn_kernel_size,\n",
    "                  depth_multiplier=bifpn_depth_multiplier,\n",
    "                  pooling_strategy=bifpn_pooling_strategy)\n",
    "    \n",
    "    B2, B3, B4, B5, B6 = bifpn([C2,C3,C4,C5,C6], training=True)\n",
    "    \n",
    "    ############################ Extra Feature Layers Start ############################\n",
    "    extra1_1 = conv_layer(256, (1, 1), strides=(1, 1), padding=\"valid\", activation=\"relu\", name=\"extra1_1\", layer=C5)\n",
    "    extra1_2 = conv_layer(512, (3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\", name=\"extra1_2\", layer=extra1_1)\n",
    "\n",
    "    extra2_1 = conv_layer(128, (1, 1), strides=(1, 1), padding=\"valid\", activation=\"relu\", name=\"extra2_1\", layer=extra1_2)\n",
    "    extra2_2 = conv_layer(256, (3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\", name=\"extra2_2\", layer=extra2_1)\n",
    "\n",
    "    extra3_1 = conv_layer(128, (1, 1), strides=(1, 1), padding=\"valid\", activation=\"relu\", name=\"extra3_1\", layer=extra2_2)\n",
    "    extra3_2 = conv_layer(256, (3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\", name=\"extra3_2\", layer=extra3_1)\n",
    "    \n",
    "    pred_deltas, pred_labels = get_head_from_outputs(hyper_params, [B2, B3, B4, B5, extra1_2, extra2_2, extra3_2])\n",
    "    return Model(inputs=input, outputs=[pred_deltas, pred_labels])\n",
    "\n",
    "def init_model(model, img_size=640):\n",
    "    \"\"\"Initializing model with dummy data for load weights with optimizer state and also graph construction.\n",
    "    inputs:\n",
    "        model = tf.keras.model\n",
    "\n",
    "    \"\"\"\n",
    "    model(tf.random.uniform((1, img_size, img_size, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b42a55a",
   "metadata": {
    "papermill": {
     "duration": 0.017506,
     "end_time": "2024-02-26T02:03:24.575069",
     "exception": false,
     "start_time": "2024-02-26T02:03:24.557563",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Roboflow Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b050fef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:03:24.657475Z",
     "iopub.status.busy": "2024-02-26T02:03:24.657121Z",
     "iopub.status.idle": "2024-02-26T02:03:42.752407Z",
     "shell.execute_reply": "2024-02-26T02:03:42.751529Z"
    },
    "id": "vGmfrj73iUhb",
    "outputId": "5fa4234b-908f-46b4-97b6-b53d2fc919d2",
    "papermill": {
     "duration": 18.118458,
     "end_time": "2024-02-26T02:03:42.754700",
     "exception": false,
     "start_time": "2024-02-26T02:03:24.636242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\r\n",
      "  Downloading roboflow-1.1.19-py3-none-any.whl.metadata (9.3 kB)\r\n",
      "Collecting certifi==2023.7.22 (from roboflow)\r\n",
      "  Downloading certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\r\n",
      "Collecting chardet==4.0.0 (from roboflow)\r\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\r\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting cycler==0.10.0 (from roboflow)\r\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\r\n",
      "Collecting idna==2.10 (from roboflow)\r\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\r\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.4.5)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from roboflow) (3.7.4)\r\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.24.4)\r\n",
      "Collecting opencv-python-headless==4.8.0.74 (from roboflow)\r\n",
      "  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\r\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from roboflow) (9.5.0)\r\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from roboflow) (2.8.2)\r\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.0.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from roboflow) (2.31.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.16.0)\r\n",
      "Collecting supervision (from roboflow)\r\n",
      "  Downloading supervision-0.18.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.26.18)\r\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from roboflow) (4.66.1)\r\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from roboflow) (6.0.1)\r\n",
      "Requirement already satisfied: requests-toolbelt in /opt/conda/lib/python3.10/site-packages (from roboflow) (0.10.1)\r\n",
      "Collecting python-magic (from roboflow)\r\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (1.2.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (4.47.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (21.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (3.1.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->roboflow) (3.3.2)\r\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from supervision->roboflow) (0.7.1)\r\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from supervision->roboflow) (1.11.4)\r\n",
      "Downloading roboflow-1.1.19-py3-none-any.whl (70 kB)\r\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m70.2/70.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading certifi-2023.7.22-py3-none-any.whl (158 kB)\r\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\r\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\r\n",
      "Downloading supervision-0.18.0-py3-none-any.whl (86 kB)\r\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: python-magic, opencv-python-headless, idna, cycler, chardet, certifi, supervision, roboflow\r\n",
      "  Attempting uninstall: opencv-python-headless\r\n",
      "    Found existing installation: opencv-python-headless 4.9.0.80\r\n",
      "    Uninstalling opencv-python-headless-4.9.0.80:\r\n",
      "      Successfully uninstalled opencv-python-headless-4.9.0.80\r\n",
      "  Attempting uninstall: idna\r\n",
      "    Found existing installation: idna 3.6\r\n",
      "    Uninstalling idna-3.6:\r\n",
      "      Successfully uninstalled idna-3.6\r\n",
      "  Attempting uninstall: cycler\r\n",
      "    Found existing installation: cycler 0.12.1\r\n",
      "    Uninstalling cycler-0.12.1:\r\n",
      "      Successfully uninstalled cycler-0.12.1\r\n",
      "  Attempting uninstall: certifi\r\n",
      "    Found existing installation: certifi 2023.11.17\r\n",
      "    Uninstalling certifi-2023.11.17:\r\n",
      "      Successfully uninstalled certifi-2023.11.17\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "jupyterlab 4.0.11 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.0.2 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "osmnx 1.8.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflowjs 4.16.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed certifi-2023.7.22 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 python-magic-0.4.27 roboflow-1.1.19 supervision-0.18.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"YOUR API KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9889686e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:03:42.797856Z",
     "iopub.status.busy": "2024-02-26T02:03:42.797257Z",
     "iopub.status.idle": "2024-02-26T02:04:53.623152Z",
     "shell.execute_reply": "2024-02-26T02:04:53.621920Z"
    },
    "id": "hszpdXFNv3zP",
    "outputId": "8047d572-5a62-411c-9197-c9296ce74328",
    "papermill": {
     "duration": 70.850304,
     "end_time": "2024-02-26T02:04:53.625945",
     "exception": false,
     "start_time": "2024-02-26T02:03:42.775641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'models'...\r\n",
      "remote: Enumerating objects: 93146, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (3036/3036), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (1647/1647), done.\u001b[K\r\n",
      "remote: Total 93146 (delta 1418), reused 2937 (delta 1365), pack-reused 90110\u001b[K\r\n",
      "Receiving objects: 100% (93146/93146), 616.93 MiB | 30.40 MiB/s, done.\r\n",
      "Resolving deltas: 100% (66355/66355), done.\r\n",
      "Processing /kaggle/working/models/research\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\r\n",
      "\u001b[?25hCollecting avro-python3 (from object_detection==0.1)\r\n",
      "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: apache-beam in /opt/conda/lib/python3.10/site-packages (from object_detection==0.1) (2.46.0)\r\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from object_detection==0.1) (9.5.0)\r\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from object_detection==0.1) (5.1.0)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from object_detection==0.1) (3.7.4)\r\n",
      "Requirement already satisfied: Cython in /opt/conda/lib/python3.10/site-packages (from object_detection==0.1) (3.0.8)\r\n",
      "Collecting contextlib2 (from object_detection==0.1)\r\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\r\n",
      "Collecting tf-slim (from object_detection==0.1)\r\n",
      "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\r\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m352.1/352.1 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from object_detection==0.1) (1.16.0)\r\n",
      "Collecting pycocotools (from object_detection==0.1)\r\n",
      "  Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\r\n",
      "Collecting lvis (from object_detection==0.1)\r\n",
      "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from object_detection==0.1) (1.11.4)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from object_detection==0.1) (2.1.4)\r\n",
      "Collecting tf-models-official>=2.5.1 (from object_detection==0.1)\r\n",
      "  Downloading tf_models_official-2.15.0-py2.py3-none-any.whl.metadata (1.4 kB)\r\n",
      "Requirement already satisfied: tensorflow_io in /opt/conda/lib/python3.10/site-packages (from object_detection==0.1) (0.35.0)\r\n",
      "Requirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (from object_detection==0.1) (2.15.0)\r\n",
      "Collecting pyparsing==2.4.7 (from object_detection==0.1)\r\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\r\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting sacrebleu<=2.2.0 (from object_detection==0.1)\r\n",
      "  Downloading sacrebleu-2.2.0-py3-none-any.whl.metadata (55 kB)\r\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting portalocker (from sacrebleu<=2.2.0->object_detection==0.1)\r\n",
      "  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\r\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu<=2.2.0->object_detection==0.1) (2023.12.25)\r\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.9.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu<=2.2.0->object_detection==0.1) (1.24.4)\r\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.4.6)\r\n",
      "Collecting gin-config (from tf-models-official>=2.5.1->object_detection==0.1)\r\n",
      "  Downloading gin_config-0.5.0-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.115.0)\r\n",
      "Collecting immutabledict (from tf-models-official>=2.5.1->object_detection==0.1)\r\n",
      "  Downloading immutabledict-4.1.0-py3-none-any.whl.metadata (3.2 kB)\r\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (1.6.3)\r\n",
      "Requirement already satisfied: oauth2client in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.1.3)\r\n",
      "Requirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.8.0.74)\r\n",
      "Requirement already satisfied: psutil>=5.4.3 in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (5.9.3)\r\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (9.0.0)\r\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (6.0.1)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.1.99)\r\n",
      "Collecting seqeval (from tf-models-official>=2.5.1->object_detection==0.1)\r\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\r\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.9.4)\r\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.15.0)\r\n",
      "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official>=2.5.1->object_detection==0.1)\r\n",
      "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\r\n",
      "Requirement already satisfied: tensorflow-text~=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.15.0)\r\n",
      "Requirement already satisfied: tensorflow~=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.15.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->object_detection==0.1) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->object_detection==0.1) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->object_detection==0.1) (2023.4)\r\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from tf-slim->object_detection==0.1) (1.4.0)\r\n",
      "Requirement already satisfied: protobuf<4,>3.12.2 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (3.20.3)\r\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (1.7)\r\n",
      "Requirement already satisfied: orjson<4.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (3.9.10)\r\n",
      "Collecting dill<0.3.2,>=0.3.1.1 (from apache-beam->object_detection==0.1)\r\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\r\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: cloudpickle~=2.2.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (2.2.1)\r\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (1.9.3)\r\n",
      "Requirement already satisfied: fasteners<1.0,>=0.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (0.19)\r\n",
      "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (1.51.1)\r\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (2.7.3)\r\n",
      "Requirement already satisfied: httplib2<0.22.0,>=0.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (0.21.0)\r\n",
      "Requirement already satisfied: objsize<0.7.0,>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (0.6.1)\r\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (3.13.0)\r\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (1.23.0)\r\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (1.4.2)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (2.31.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (4.9.0)\r\n",
      "Requirement already satisfied: zstandard<1,>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object_detection==0.1) (0.22.0)\r\n",
      "Collecting pyarrow<10.0.0,>=3.0.0 (from apache-beam->object_detection==0.1)\r\n",
      "  Downloading pyarrow-9.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\r\n",
      "Requirement already satisfied: cycler>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from lvis->object_detection==0.1) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from lvis->object_detection==0.1) (1.4.5)\r\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /opt/conda/lib/python3.10/site-packages (from lvis->object_detection==0.1) (4.9.0.80)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->object_detection==0.1) (1.2.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->object_detection==0.1) (4.47.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->object_detection==0.1) (21.3)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.35.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_io->object_detection==0.1) (0.35.0)\r\n",
      "Requirement already satisfied: google-auth<3.0.0.dev0,>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (2.26.1)\r\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (0.1.1)\r\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (2.11.1)\r\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (3.0.1)\r\n",
      "Requirement already satisfied: docopt in /opt/conda/lib/python3.10/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object_detection==0.1) (0.6.2)\r\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (2023.7.22)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (4.66.1)\r\n",
      "Requirement already satisfied: python-slugify in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (8.0.1)\r\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (1.26.18)\r\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (6.1.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object_detection==0.1) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object_detection==0.1) (2.10)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (23.5.26)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (0.5.4)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (3.10.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (16.0.6)\r\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (3.3.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (69.0.3)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (2.4.0)\r\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (1.14.1)\r\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (2.15.1)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (2.15.0)\r\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object_detection==0.1) (0.1.8)\r\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.10/site-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (0.5.1)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /opt/conda/lib/python3.10/site-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (0.3.0)\r\n",
      "Requirement already satisfied: rsa>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (4.9)\r\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval->tf-models-official>=2.5.1->object_detection==0.1) (1.2.2)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (8.1.7)\r\n",
      "Requirement already satisfied: etils>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (1.6.0)\r\n",
      "Requirement already satisfied: promise in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (2.3)\r\n",
      "Requirement already satisfied: tensorflow-metadata in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.14.0)\r\n",
      "Requirement already satisfied: toml in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.10.2)\r\n",
      "Requirement already satisfied: array-record>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.5.0)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (0.42.0)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (2023.12.2)\r\n",
      "Requirement already satisfied: importlib_resources in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (6.1.1)\r\n",
      "Requirement already satisfied: zipp in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (3.17.0)\r\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (1.62.0)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (4.2.4)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object_detection==0.1) (1.3.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object_detection==0.1) (3.2.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (1.2.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (3.5.2)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (3.0.1)\r\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (0.5.1)\r\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.10/site-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (1.3)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (1.3.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (2.1.3)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (3.2.2)\r\n",
      "Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\r\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m116.6/116.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tf_models_official-2.15.0-py2.py3-none-any.whl (2.7 MB)\r\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\r\n",
      "Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\r\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m426.2/426.2 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pyarrow-9.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.3 MB)\r\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m35.3/35.3 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\r\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading gin_config-0.5.0-py3-none-any.whl (61 kB)\r\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading immutabledict-4.1.0-py3-none-any.whl (4.5 kB)\r\n",
      "Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\r\n",
      "Building wheels for collected packages: object_detection, avro-python3, dill, seqeval\r\n",
      "  Building wheel for object_detection (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for object_detection: filename=object_detection-0.1-py3-none-any.whl size=21878671 sha256=acb9d1776bfe35378be72746044f961dbbc3224201bf28b4ee77efcf8371b6b6\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-gs0wwt8b/wheels/e6/5c/1f/32444df4025257dccdc9eafab2d06b65752494ee9ca01a388c\r\n",
      "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43992 sha256=92a45a8767a93f85a7f104aa268ca6c350e14cf08fbba3124622d2fa4063a3de\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/bc/85/62/6cdd81c56f923946b401cecff38055b94c9b766927f7d8ca82\r\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78540 sha256=f7cf9242c30a97ae393a140a11c8d09175eb2e9cc3efdb2f110cbfe43a4d22d9\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\r\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=17fccd3ee1f88f07065b9666253f004168272edd8d00192d036c556ad060b0e4\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\r\n",
      "Successfully built object_detection avro-python3 dill seqeval\r\n",
      "Installing collected packages: gin-config, tf-slim, tensorflow-model-optimization, pyparsing, pyarrow, portalocker, immutabledict, dill, contextlib2, avro-python3, sacrebleu, seqeval, pycocotools, lvis, tf-models-official, object_detection\r\n",
      "  Attempting uninstall: pyparsing\r\n",
      "    Found existing installation: pyparsing 3.1.1\r\n",
      "    Uninstalling pyparsing-3.1.1:\r\n",
      "      Successfully uninstalled pyparsing-3.1.1\r\n",
      "  Attempting uninstall: pyarrow\r\n",
      "    Found existing installation: pyarrow 11.0.0\r\n",
      "    Uninstalling pyarrow-11.0.0:\r\n",
      "      Successfully uninstalled pyarrow-11.0.0\r\n",
      "  Attempting uninstall: dill\r\n",
      "    Found existing installation: dill 0.3.7\r\n",
      "    Uninstalling dill-0.3.7:\r\n",
      "      Successfully uninstalled dill-0.3.7\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cudf 23.8.0 requires cubinlinker, which is not installed.\r\n",
      "cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "cudf 23.8.0 requires ptxcompiler, which is not installed.\r\n",
      "cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "beatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.0.11 which is incompatible.\r\n",
      "cudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\r\n",
      "cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\r\n",
      "cudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "cudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 9.0.0 which is incompatible.\r\n",
      "cuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\r\n",
      "cuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\r\n",
      "dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\r\n",
      "dask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\r\n",
      "dask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\r\n",
      "multiprocess 0.70.15 requires dill>=0.3.7, but you have dill 0.3.1.1 which is incompatible.\r\n",
      "pathos 0.3.1 requires dill>=0.3.7, but you have dill 0.3.1.1 which is incompatible.\r\n",
      "pytoolconfig 1.3.1 requires packaging>=23.2, but you have packaging 21.3 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflowjs 4.16.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\r\n",
      "xarray 2024.1.0 requires packaging>=22, but you have packaging 21.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed avro-python3-1.10.2 contextlib2-21.6.0 dill-0.3.1.1 gin-config-0.5.0 immutabledict-4.1.0 lvis-0.5.3 object_detection-0.1 portalocker-2.8.2 pyarrow-9.0.0 pycocotools-2.0.7 pyparsing-2.4.7 sacrebleu-2.2.0 seqeval-1.2.2 tensorflow-model-optimization-0.8.0 tf-models-official-2.15.0 tf-slim-1.1.0\r\n"
     ]
    }
   ],
   "source": [
    "# Clone the tensorflow models repository if it doesn't already exist\n",
    "if \"models\" in pathlib.Path.cwd().parts:\n",
    "    while \"models\" in pathlib.Path.cwd().parts:\n",
    "        os.chdir('..')\n",
    "elif not pathlib.Path('models').exists():\n",
    "    # Install the Object Detection API\n",
    "    !git clone https://github.com/tensorflow/models.git\n",
    "    !cd models/research && protoc object_detection/protos/*.proto --python_out=.\n",
    "    !cd models/research && cp object_detection/packages/tf2/setup.py .\n",
    "    !cd models/research && python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45625dcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:04:53.701711Z",
     "iopub.status.busy": "2024-02-26T02:04:53.701322Z",
     "iopub.status.idle": "2024-02-26T02:05:22.985607Z",
     "shell.execute_reply": "2024-02-26T02:05:22.984474Z"
    },
    "id": "b_mYXsDeJMsX",
    "outputId": "99925f28-8143-4f75-9a99-e2e87159bcc7",
    "papermill": {
     "duration": 29.324661,
     "end_time": "2024-02-26T02:05:22.987801",
     "exception": false,
     "start_time": "2024-02-26T02:04:53.663140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Fabric-Defect-Capstone-1 to tfrecord:: 100%|| 789109/789109 [00:24<00:00, 32309.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Fabric-Defect-Capstone-1 in tfrecord:: 100%|| 11/11 [00:01<00:00,  7.61it/s]\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/kaggle/working/')\n",
    "if hyper_params[\"dataset\"] == 0:\n",
    "    # dut\n",
    "    project = rf.workspace(\"ducks-zdbul\").project(\"fabric-defect-capstone\")\n",
    "    dataset = project.version(1).download(\"tfrecord\")\n",
    "elif hyper_params[\"dataset\"] == 1:\n",
    "    # tilda\n",
    "    project = rf.workspace(\"irvin-andersen\").project(\"tilda-fabric\")\n",
    "    dataset = project.version(2).download(\"tfrecord\")\n",
    "elif hyper_params[\"dataset\"] == 2:\n",
    "    # daffodil\n",
    "    project = rf.workspace(\"defect-detection-witqu\").project(\"fabric-defect-daffodil\")\n",
    "    dataset = project.version(1).download(\"tfrecord\")\n",
    "elif hyper_params[\"dataset\"] == 3:\n",
    "    # thesis\n",
    "    project = rf.workspace(\"ducks-zdbul\").project(\"fabric-defect-thesis-quv7v\")\n",
    "    dataset = project.version(1).download(\"tfrecord\")\n",
    "elif hyper_params[\"dataset\"] == 4:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47e4510",
   "metadata": {
    "id": "8N8ZG5fxFYD0",
    "papermill": {
     "duration": 0.053173,
     "end_time": "2024-02-26T02:05:23.093977",
     "exception": false,
     "start_time": "2024-02-26T02:05:23.040804",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9908282b",
   "metadata": {
    "id": "sZFFc8m4HIFH",
    "papermill": {
     "duration": 0.053101,
     "end_time": "2024-02-26T02:05:23.200580",
     "exception": false,
     "start_time": "2024-02-26T02:05:23.147479",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca2db5c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:05:23.309527Z",
     "iopub.status.busy": "2024-02-26T02:05:23.309176Z",
     "iopub.status.idle": "2024-02-26T02:05:23.335640Z",
     "shell.execute_reply": "2024-02-26T02:05:23.334898Z"
    },
    "id": "p_NZkMjgHLNp",
    "papermill": {
     "duration": 0.08416,
     "end_time": "2024-02-26T02:05:23.337561",
     "exception": false,
     "start_time": "2024-02-26T02:05:23.253401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply(img, gt_boxes):\n",
    "    \"\"\"Randomly applying data augmentation methods to image and ground truth boxes.\n",
    "    inputs:\n",
    "        img = (height, width, depth)\n",
    "        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "            in normalized form [0, 1]\n",
    "    outputs:\n",
    "        modified_img = (final_height, final_width, depth)\n",
    "        modified_gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "            in normalized form [0, 1]\n",
    "    \"\"\"\n",
    "    # Color operations\n",
    "    # Randomly change hue, saturation, brightness and contrast of image\n",
    "    color_methods = [random_brightness, random_contrast, random_hue, random_saturation]\n",
    "    # Geometric operations\n",
    "    # Randomly sample a patch and flip horizontally image and ground truth boxes\n",
    "    geometric_methods = [patch, flip_horizontally]\n",
    "\n",
    "    for augmentation_method in geometric_methods + color_methods:\n",
    "        img, gt_boxes = randomly_apply_operation(augmentation_method, img, gt_boxes)\n",
    "\n",
    "    img = tf.clip_by_value(img, 0, 1)\n",
    "    return img, gt_boxes\n",
    "\n",
    "def get_random_bool():\n",
    "    \"\"\"Generating random boolean.\n",
    "    outputs:\n",
    "        random boolean 0d tensor\n",
    "    \"\"\"\n",
    "    return tf.greater(tf.random.uniform((), dtype=tf.float32), 0.5)\n",
    "\n",
    "def randomly_apply_operation(operation, img, gt_boxes, *args):\n",
    "    \"\"\"Randomly applying given method to image and ground truth boxes.\n",
    "    inputs:\n",
    "        operation = callable method\n",
    "        img = (height, width, depth)\n",
    "        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "    outputs:\n",
    "        modified_or_not_img = (final_height, final_width, depth)\n",
    "        modified_or_not_gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "    \"\"\"\n",
    "    return tf.cond(\n",
    "        get_random_bool(),\n",
    "        lambda: operation(img, gt_boxes, *args),\n",
    "        lambda: (img, gt_boxes)\n",
    "    )\n",
    "\n",
    "def random_brightness(img, gt_boxes, max_delta=0.12):\n",
    "    \"\"\"Randomly change brightness of the image.\n",
    "    inputs:\n",
    "        img = (height, width, depth)\n",
    "        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "    outputs:\n",
    "        modified_img = (height, width, depth)\n",
    "        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "    \"\"\"\n",
    "    return tf.image.random_brightness(img, max_delta), gt_boxes\n",
    "\n",
    "def random_contrast(img, gt_boxes, lower=0.5, upper=1.5):\n",
    "    \"\"\"Randomly change contrast of the image.\n",
    "    inputs:\n",
    "        img = (height, width, depth)\n",
    "        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "    outputs:\n",
    "        modified_img = (height, width, depth)\n",
    "        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "    \"\"\"\n",
    "    return tf.image.random_contrast(img, lower, upper), gt_boxes\n",
    "\n",
    "def random_hue(img, gt_boxes, max_delta=0.08):\n",
    "    \"\"\"Randomly change hue of the image.\n",
    "    inputs:\n",
    "        img = (height, width, depth)\n",
    "        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "    outputs:\n",
    "        modified_img = (height, width, depth)\n",
    "        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "    \"\"\"\n",
    "    return tf.image.random_hue(img, max_delta), gt_boxes\n",
    "\n",
    "def random_saturation(img, gt_boxes, lower=0.5, upper=1.5):\n",
    "    \"\"\"Randomly change saturation of the image.\n",
    "    inputs:\n",
    "        img = (height, width, depth)\n",
    "        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "    outputs:\n",
    "        modified_img = (height, width, depth)\n",
    "        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "    \"\"\"\n",
    "    return tf.image.random_saturation(img, lower, upper), gt_boxes\n",
    "\n",
    "def flip_horizontally(img, gt_boxes):\n",
    "    \"\"\"Flip image horizontally and adjust the ground truth boxes.\n",
    "    inputs:\n",
    "        img = (height, width, depth)\n",
    "        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "    outputs:\n",
    "        modified_img = (height, width, depth)\n",
    "        modified_gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "    \"\"\"\n",
    "    flipped_img = tf.image.flip_left_right(img)\n",
    "    flipped_gt_boxes = tf.stack([gt_boxes[..., 0],\n",
    "                                1.0 - gt_boxes[..., 3],\n",
    "                                gt_boxes[..., 2],\n",
    "                                1.0 - gt_boxes[..., 1]], -1)\n",
    "    return flipped_img, flipped_gt_boxes\n",
    "\n",
    "##############################################################################\n",
    "## Sample patch start\n",
    "##############################################################################\n",
    "\n",
    "def get_random_min_overlap():\n",
    "    \"\"\"Generating random minimum overlap value.\n",
    "    outputs:\n",
    "        min_overlap = random minimum overlap value 0d tensor\n",
    "    \"\"\"\n",
    "    overlaps = tf.constant([0.1, 0.3, 0.5, 0.7, 0.9], dtype=tf.float32)\n",
    "    i = tf.random.uniform((), minval=0, maxval=tf.shape(overlaps)[0], dtype=tf.int32)\n",
    "    return overlaps[i]\n",
    "\n",
    "def expand_image(img, gt_boxes, height, width):\n",
    "    \"\"\"Randomly expanding image and adjusting ground truth object coordinates.\n",
    "    inputs:\n",
    "        img = (height, width, depth)\n",
    "        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "        height = height of the image\n",
    "        width = width of the image\n",
    "    outputs:\n",
    "        img = (final_height, final_width, depth)\n",
    "        modified_gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "        final_height = final height of the image\n",
    "        final_width = final width of the image\n",
    "    \"\"\"\n",
    "    expansion_ratio = tf.random.uniform((), minval=1, maxval=4, dtype=tf.float32)\n",
    "    final_height, final_width = tf.round(height * expansion_ratio), tf.round(width * expansion_ratio)\n",
    "    pad_left = tf.round(tf.random.uniform((), minval=0, maxval=final_width - width, dtype=tf.float32))\n",
    "    pad_top = tf.round(tf.random.uniform((), minval=0, maxval=final_height - height, dtype=tf.float32))\n",
    "    pad_right = final_width - (width + pad_left)\n",
    "    pad_bottom = final_height - (height + pad_top)\n",
    "\n",
    "    mean, _ = tf.nn.moments(img, [0, 1])\n",
    "    expanded_image = tf.pad(img, ((pad_top, pad_bottom), (pad_left, pad_right), (0,0)), constant_values=-1)\n",
    "    expanded_image = tf.where(expanded_image == -1, mean, expanded_image)\n",
    "\n",
    "    min_max = tf.stack([-pad_top, -pad_left, pad_bottom+height, pad_right+width], -1) / [height, width, height, width]\n",
    "    modified_gt_boxes = renormalize_bboxes_with_min_max(gt_boxes, min_max)\n",
    "\n",
    "    return expanded_image, modified_gt_boxes\n",
    "\n",
    "def patch(img, gt_boxes):\n",
    "    \"\"\"Generating random patch and adjusting image and ground truth objects to this patch.\n",
    "    After this operation some of the ground truth boxes / objects could be removed from the image.\n",
    "    However, these objects are not excluded from the output, only the coordinates are changed as zero.\n",
    "    inputs:\n",
    "        img = (height, width, depth)\n",
    "        gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "            in normalized form [0, 1]\n",
    "    outputs:\n",
    "        modified_img = (final_height, final_width, depth)\n",
    "        modified_gt_boxes = (ground_truth_object_count, [y1, x1, y2, x2])\n",
    "            in normalized form [0, 1]\n",
    "    \"\"\"\n",
    "    img_shape = tf.cast(tf.shape(img), dtype=tf.float32)\n",
    "    org_height, org_width = img_shape[0], img_shape[1]\n",
    "    # Randomly expand image and adjust bounding boxes\n",
    "    img, gt_boxes = randomly_apply_operation(expand_image, img, gt_boxes, org_height, org_width)\n",
    "    # Get random minimum overlap value\n",
    "    min_overlap = get_random_min_overlap()\n",
    "\n",
    "    begin, size, new_boundaries = tf.image.sample_distorted_bounding_box(\n",
    "        tf.shape(img),\n",
    "        # use_image_if_no_bounding_boxes=True, ### FIX:26/1/24\n",
    "        bounding_boxes=tf.expand_dims(gt_boxes, 0),\n",
    "        aspect_ratio_range=[0.5, 2.0],\n",
    "        min_object_covered=min_overlap)\n",
    "\n",
    "    img = tf.slice(img, begin, size)\n",
    "    img = tf.image.resize(img, (org_height, org_width))\n",
    "    gt_boxes = renormalize_bboxes_with_min_max(gt_boxes, new_boundaries[0, 0])\n",
    "\n",
    "    return img, gt_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24c6637",
   "metadata": {
    "id": "qQE2tvn-Fhil",
    "papermill": {
     "duration": 0.052871,
     "end_time": "2024-02-26T02:05:23.443841",
     "exception": false,
     "start_time": "2024-02-26T02:05:23.390970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# bbox_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3aa54a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:05:23.554995Z",
     "iopub.status.busy": "2024-02-26T02:05:23.554353Z",
     "iopub.status.idle": "2024-02-26T02:05:23.577611Z",
     "shell.execute_reply": "2024-02-26T02:05:23.576638Z"
    },
    "id": "knGVG_zdT4Sf",
    "papermill": {
     "duration": 0.082088,
     "end_time": "2024-02-26T02:05:23.579888",
     "exception": false,
     "start_time": "2024-02-26T02:05:23.497800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def non_max_suppression(pred_bboxes, pred_labels, **kwargs):\n",
    "    \"\"\"Applying non maximum suppression.\n",
    "    SSD uses non-maximum suppression to prune away boxes that have IOU overlap with previously selected boxes.\n",
    "    Details could be found on tensorflow documentation.\n",
    "    https://www.tensorflow.org/api_docs/python/tf/image/combined_non_max_suppression\n",
    "    inputs:\n",
    "        pred_bboxes = (batch_size, total_bboxes, total_labels, [y1, x1, y2, x2])\n",
    "            total_labels should be 1 for binary operations like in rpn\n",
    "        pred_labels = (batch_size, total_bboxes, total_labels)\n",
    "        **kwargs = other parameters\n",
    "\n",
    "    outputs:\n",
    "        nms_boxes = (batch_size, max_detections, [y1, x1, y2, x2])\n",
    "        nmsed_scores = (batch_size, max_detections)\n",
    "        nmsed_classes = (batch_size, max_detections)\n",
    "        valid_detections = (batch_size)\n",
    "            Only the top valid_detections[i] entries in nms_boxes[i], nms_scores[i] and nms_class[i] are valid.\n",
    "            The rest of the entries are zero paddings.\n",
    "    \"\"\"\n",
    "    return tf.image.combined_non_max_suppression(\n",
    "        pred_bboxes,\n",
    "        pred_labels,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "def generate_iou_map(bboxes, gt_boxes, transpose_perm=[0, 2, 1]):\n",
    "    \"\"\"Calculating intersection over union values for each ground truth boxes in a dynamic manner.\n",
    "    It is supported from 1d to 3d dimensions for bounding boxes.\n",
    "    Even if bboxes have different rank from gt_boxes it should be work.\n",
    "    inputs:\n",
    "        bboxes = (dynamic_dimension, [y1, x1, y2, x2])\n",
    "        gt_boxes = (dynamic_dimension, [y1, x1, y2, x2])\n",
    "        transpose_perm = (transpose_perm_order)\n",
    "            for 3d gt_boxes => [0, 2, 1]\n",
    "            The returned tensor's dimension i will correspond to the input dimension perm[i].\n",
    "\n",
    "    outputs:\n",
    "        iou_map = (dynamic_dimension, total_gt_boxes)\n",
    "            same rank with the gt_boxes\n",
    "    \"\"\"\n",
    "    gt_rank = tf.rank(gt_boxes)\n",
    "    gt_expand_axis = gt_rank - 2\n",
    "\n",
    "    bbox_y1, bbox_x1, bbox_y2, bbox_x2 = tf.split(bboxes, 4, axis=-1)\n",
    "    gt_y1, gt_x1, gt_y2, gt_x2 = tf.split(gt_boxes, 4, axis=-1)\n",
    "\n",
    "    # Calculate bbox and ground truth boxes areas\n",
    "    gt_area = tf.squeeze((gt_y2 - gt_y1) * (gt_x2 - gt_x1), axis=-1)\n",
    "    bbox_area = tf.squeeze((bbox_y2 - bbox_y1) * (bbox_x2 - bbox_x1), axis=-1)\n",
    "\n",
    "    x_top = tf.maximum(bbox_x1, tf.transpose(gt_x1, transpose_perm))\n",
    "    y_top = tf.maximum(bbox_y1, tf.transpose(gt_y1, transpose_perm))\n",
    "    x_bottom = tf.minimum(bbox_x2, tf.transpose(gt_x2, transpose_perm))\n",
    "    y_bottom = tf.minimum(bbox_y2, tf.transpose(gt_y2, transpose_perm))\n",
    "\n",
    "    # Calculate intersection area\n",
    "    intersection_area = tf.maximum(x_bottom - x_top, 0) * tf.maximum(y_bottom - y_top, 0)\n",
    "    # Calculate union area\n",
    "    union_area = (tf.expand_dims(bbox_area, -1) + tf.expand_dims(gt_area, gt_expand_axis) - intersection_area)\n",
    "    # Intersection over Union\n",
    "    return intersection_area / union_area\n",
    "\n",
    "def get_bboxes_from_deltas(prior_boxes, deltas):\n",
    "    \"\"\"Calculating bounding boxes for given bounding box and delta values.\n",
    "    inputs:\n",
    "        prior_boxes = (total_bboxes, [y1, x1, y2, x2])\n",
    "        deltas = (batch_size, total_bboxes, [delta_y, delta_x, delta_h, delta_w])\n",
    "\n",
    "    outputs:\n",
    "        final_boxes = (batch_size, total_bboxes, [y1, x1, y2, x2])\n",
    "    \"\"\"\n",
    "    all_pbox_width = prior_boxes[..., 3] - prior_boxes[..., 1]\n",
    "    all_pbox_height = prior_boxes[..., 2] - prior_boxes[..., 0]\n",
    "    all_pbox_ctr_x = prior_boxes[..., 1] + 0.5 * all_pbox_width\n",
    "    all_pbox_ctr_y = prior_boxes[..., 0] + 0.5 * all_pbox_height\n",
    "\n",
    "    all_bbox_width = tf.exp(deltas[..., 3]) * all_pbox_width\n",
    "    all_bbox_height = tf.exp(deltas[..., 2]) * all_pbox_height\n",
    "    all_bbox_ctr_x = (deltas[..., 1] * all_pbox_width) + all_pbox_ctr_x\n",
    "    all_bbox_ctr_y = (deltas[..., 0] * all_pbox_height) + all_pbox_ctr_y\n",
    "\n",
    "    # Calculate coordinates of predicted bounding box\n",
    "    y1 = all_bbox_ctr_y - (0.5 * all_bbox_height)\n",
    "    x1 = all_bbox_ctr_x - (0.5 * all_bbox_width)\n",
    "    y2 = all_bbox_height + y1\n",
    "    x2 = all_bbox_width + x1\n",
    "\n",
    "    return tf.stack([y1, x1, y2, x2], axis=-1)\n",
    "\n",
    "def get_deltas_from_bboxes(bboxes, gt_boxes):\n",
    "    \"\"\"Calculating bounding box deltas for given bounding box and ground truth boxes.\n",
    "    inputs:\n",
    "        bboxes = (total_bboxes, [y1, x1, y2, x2])\n",
    "        gt_boxes = (batch_size, total_bboxes, [y1, x1, y2, x2])\n",
    "\n",
    "    outputs:\n",
    "        final_deltas = (batch_size, total_bboxes, [delta_y, delta_x, delta_h, delta_w])\n",
    "    \"\"\"\n",
    "    bbox_width = bboxes[..., 3] - bboxes[..., 1]\n",
    "    bbox_height = bboxes[..., 2] - bboxes[..., 0]\n",
    "    bbox_ctr_x = bboxes[..., 1] + 0.5 * bbox_width\n",
    "    bbox_ctr_y = bboxes[..., 0] + 0.5 * bbox_height\n",
    "\n",
    "    try:\n",
    "        gt_width = gt_boxes[..., 3] - gt_boxes[..., 1]\n",
    "        gt_height = gt_boxes[..., 2] - gt_boxes[..., 0]\n",
    "        gt_ctr_x = gt_boxes[..., 1] + 0.5 * gt_width\n",
    "        gt_ctr_y = gt_boxes[..., 0] + 0.5 * gt_height\n",
    "    except:\n",
    "        tf.print(gt_boxes)\n",
    "        tf.print(gt_boxes.shape)\n",
    "\n",
    "    # tf.where(condition, x, y) where values in x is replaced with y if false\n",
    "    bbox_width = tf.where(tf.equal(bbox_width, 0), 1e-3, bbox_width)\n",
    "    bbox_height = tf.where(tf.equal(bbox_height, 0), 1e-3, bbox_height)\n",
    "\n",
    "    delta_x = tf.where(tf.equal(gt_width, 0), tf.zeros_like(gt_width), tf.truediv((gt_ctr_x - bbox_ctr_x), bbox_width)) # 0 or offset/bbox_wdith\n",
    "    delta_y = tf.where(tf.equal(gt_height, 0), tf.zeros_like(gt_height), tf.truediv((gt_ctr_y - bbox_ctr_y), bbox_height))\n",
    "    delta_w = tf.where(tf.equal(gt_width, 0), tf.zeros_like(gt_width), tf.math.log(gt_width / bbox_width)) # 0 or ln(gt_width/bbox_width)\n",
    "    delta_h = tf.where(tf.equal(gt_height, 0), tf.zeros_like(gt_height), tf.math.log(gt_height / bbox_height))\n",
    "    return tf.stack([delta_y, delta_x, delta_h, delta_w], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cb4db15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:05:23.688416Z",
     "iopub.status.busy": "2024-02-26T02:05:23.688018Z",
     "iopub.status.idle": "2024-02-26T02:05:23.698671Z",
     "shell.execute_reply": "2024-02-26T02:05:23.697633Z"
    },
    "id": "FngGpkXMT8F1",
    "papermill": {
     "duration": 0.067312,
     "end_time": "2024-02-26T02:05:23.700850",
     "exception": false,
     "start_time": "2024-02-26T02:05:23.633538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def renormalize_bboxes_with_min_max(bboxes, min_max):\n",
    "    \"\"\"Renormalizing given bounding boxes to the new boundaries.\n",
    "    r = (x - min) / (max - min)\n",
    "    inputs:\n",
    "        bboxes = (total_bboxes, [y1, x1, y2, x2])\n",
    "        min_max = ([y_min, x_min, y_max, x_max])\n",
    "\n",
    "    outputs:\n",
    "        normalized_bboxes = (total_bboxes, [y1, x1, y2, x2])\n",
    "            in normalized form [0, 1]\n",
    "    \"\"\"\n",
    "    y_min, x_min, y_max, x_max = tf.split(min_max, 4)\n",
    "    renomalized_bboxes = bboxes - tf.concat([y_min, x_min, y_min, x_min], -1)\n",
    "    renomalized_bboxes /= tf.concat([y_max-y_min, x_max-x_min, y_max-y_min, x_max-x_min], -1)\n",
    "    return tf.clip_by_value(renomalized_bboxes, 0, 1)\n",
    "\n",
    "def normalize_bboxes(bboxes, height, width):\n",
    "    \"\"\"Normalizing bounding boxes.\n",
    "    inputs:\n",
    "        bboxes = (batch_size, total_bboxes, [y1, x1, y2, x2])\n",
    "        height = image height\n",
    "        width = image width\n",
    "\n",
    "    outputs:\n",
    "        normalized_bboxes = (batch_size, total_bboxes, [y1, x1, y2, x2])\n",
    "            in normalized form [0, 1]\n",
    "    \"\"\"\n",
    "    y1 = bboxes[..., 0] / height\n",
    "    x1 = bboxes[..., 1] / width\n",
    "    y2 = bboxes[..., 2] / height\n",
    "    x2 = bboxes[..., 3] / width\n",
    "    return tf.stack([y1, x1, y2, x2], axis=-1)\n",
    "\n",
    "def denormalize_bboxes(bboxes, height, width):\n",
    "    \"\"\"Denormalizing bounding boxes.\n",
    "    inputs:\n",
    "        bboxes = (batch_size, total_bboxes, [y1, x1, y2, x2])\n",
    "            in normalized form [0, 1]\n",
    "        height = image height\n",
    "        width = image width\n",
    "\n",
    "    outputs:\n",
    "        denormalized_bboxes = (batch_size, total_bboxes, [y1, x1, y2, x2])\n",
    "    \"\"\"\n",
    "    y1 = bboxes[..., 0] * height\n",
    "    x1 = bboxes[..., 1] * width\n",
    "    y2 = bboxes[..., 2] * height\n",
    "    x2 = bboxes[..., 3] * width\n",
    "    return tf.round(tf.stack([y1, x1, y2, x2], axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f43a803",
   "metadata": {
    "id": "hRkoKNc-F1Yw",
    "papermill": {
     "duration": 0.055967,
     "end_time": "2024-02-26T02:05:23.813352",
     "exception": false,
     "start_time": "2024-02-26T02:05:23.757385",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "642f168f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:05:23.930227Z",
     "iopub.status.busy": "2024-02-26T02:05:23.929291Z",
     "iopub.status.idle": "2024-02-26T02:05:23.947108Z",
     "shell.execute_reply": "2024-02-26T02:05:23.946386Z"
    },
    "id": "ambu0h84FoUV",
    "papermill": {
     "duration": 0.081242,
     "end_time": "2024-02-26T02:05:23.949053",
     "exception": false,
     "start_time": "2024-02-26T02:05:23.867811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def draw_grid_map(img, grid_map, stride):\n",
    "    \"\"\"Drawing grid intersection on given image.\n",
    "    inputs:\n",
    "        img = (height, width, channels)\n",
    "        grid_map = (output_height * output_width, [y_index, x_index, y_index, x_index])\n",
    "            tiled x, y coordinates\n",
    "        stride = number of stride\n",
    "\n",
    "    outputs:\n",
    "        array = (height, width, channels)\n",
    "    \"\"\"\n",
    "    image = Image.fromarray(img)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    counter = 0\n",
    "    for grid in grid_map:\n",
    "        draw.rectangle((\n",
    "            grid[0] + stride // 2 - 2,\n",
    "            grid[1] + stride // 2 - 2,\n",
    "            grid[2] + stride // 2 + 2,\n",
    "            grid[3] + stride // 2 + 2), fill=(255, 255, 255, 0))\n",
    "        counter += 1\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "def draw_bboxes(imgs, bboxes):\n",
    "    \"\"\"Drawing bounding boxes on given images.\n",
    "    inputs:\n",
    "        imgs = (batch_size, height, width, channels)\n",
    "        bboxes = (batch_size, total_bboxes, [y1, x1, y2, x2])\n",
    "            in normalized form [0, 1]\n",
    "    \"\"\"\n",
    "    colors = tf.constant([[1, 0, 0, 1]], dtype=tf.float32)\n",
    "    imgs_with_bb = tf.image.draw_bounding_boxes(imgs, bboxes, colors)\n",
    "    plt.figure()\n",
    "    for img_with_bb in imgs_with_bb:\n",
    "        plt.imshow(img_with_bb)\n",
    "        plt.show()\n",
    "\n",
    "def draw_bboxes_with_labels(img, bboxes, label_indices, probs, labels):\n",
    "    \"\"\"Drawing bounding boxes with labels on given image.\n",
    "    inputs:\n",
    "        img = (height, width, channels)\n",
    "        bboxes = (total_bboxes, [y1, x1, y2, x2])\n",
    "            in denormalized form\n",
    "        label_indices = (total_bboxes)\n",
    "        probs = (total_bboxes)\n",
    "        labels = [labels string list]\n",
    "    \"\"\"\n",
    "    colors = tf.random.uniform((len(labels), 4), maxval=256, dtype=tf.int32)\n",
    "    image = tf.keras.preprocessing.image.array_to_img(img)\n",
    "    width, height = image.size\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for index, bbox in enumerate(bboxes):\n",
    "        y1, x1, y2, x2 = tf.split(bbox, 4)\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "        if width <= 0 or height <= 0:\n",
    "            continue\n",
    "        label_index = int(label_indices[index])\n",
    "        color = tuple(colors[label_index].numpy())\n",
    "        label_text = \"{0} {1:0.3f}\".format(labels[label_index], probs[index])\n",
    "        draw.text((x1 + 4, y1 + 2), label_text, fill=color)\n",
    "        draw.rectangle((x1, y1, x2, y2), outline=color, width=3)\n",
    "    #\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "def draw_predictions(dataset, pred_bboxes, pred_labels, pred_scores, labels, batch_size):\n",
    "    for batch_id, image_data in enumerate(dataset):\n",
    "        imgs, _, _ = image_data\n",
    "        img_size = imgs.shape[1]\n",
    "        start = batch_id * batch_size\n",
    "        end = start + batch_size\n",
    "        batch_bboxes, batch_labels, batch_scores = pred_bboxes[start:end], pred_labels[start:end], pred_scores[start:end]\n",
    "        for i, img in enumerate(imgs):\n",
    "            denormalized_bboxes = denormalize_bboxes(batch_bboxes[i], img_size, img_size)\n",
    "            draw_bboxes_with_labels(img, denormalized_bboxes, batch_labels[i], batch_scores[i], labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b72b92",
   "metadata": {
    "id": "rZPgvuNbGMN_",
    "papermill": {
     "duration": 0.05337,
     "end_time": "2024-02-26T02:05:24.056037",
     "exception": false,
     "start_time": "2024-02-26T02:05:24.002667",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# io_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55fc268a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:05:24.167185Z",
     "iopub.status.busy": "2024-02-26T02:05:24.166852Z",
     "iopub.status.idle": "2024-02-26T02:05:24.173394Z",
     "shell.execute_reply": "2024-02-26T02:05:24.172498Z"
    },
    "id": "u9QDiqrrGLm3",
    "papermill": {
     "duration": 0.064201,
     "end_time": "2024-02-26T02:05:24.175409",
     "exception": false,
     "start_time": "2024-02-26T02:05:24.111208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_log_path(model_type, custom_postfix=\"\"):\n",
    "    \"\"\"Generating log path from model_type value for tensorboard.\n",
    "    inputs:\n",
    "        model_type = \"mobilenet_v2\"\n",
    "        custom_postfix = any custom string for log folder name\n",
    "\n",
    "    outputs:\n",
    "        log_path = tensorboard log path, for example: \"logs/mobilenet_v2/{date}\"\n",
    "    \"\"\"\n",
    "    return \"logs/{}{}/{}\".format(model_type, custom_postfix, datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "def get_model_path(model_type):\n",
    "    \"\"\"Generating model path from model_type value for save/load model weights.\n",
    "    inputs:\n",
    "        model_type = \"vgg16\", \"mobilenet_v2\"\n",
    "\n",
    "    outputs:\n",
    "        model_path = os model path, for example: \"trained/ssd_vgg16_model_weights.h5\"\n",
    "    \"\"\"\n",
    "    main_path = \"trained\"\n",
    "    if not os.path.exists(main_path):\n",
    "        os.makedirs(main_path)\n",
    "    model_path = os.path.join(main_path, \"ssd_{}_model_weights.h5\".format(model_type))\n",
    "    return model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c27f584",
   "metadata": {
    "id": "odgPsWcyGRBW",
    "papermill": {
     "duration": 0.056253,
     "end_time": "2024-02-26T02:05:24.286604",
     "exception": false,
     "start_time": "2024-02-26T02:05:24.230351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# train_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7cab8d84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:05:24.398090Z",
     "iopub.status.busy": "2024-02-26T02:05:24.397655Z",
     "iopub.status.idle": "2024-02-26T02:05:24.410270Z",
     "shell.execute_reply": "2024-02-26T02:05:24.409397Z"
    },
    "id": "NFs1NL6aGQkU",
    "papermill": {
     "duration": 0.070109,
     "end_time": "2024-02-26T02:05:24.412137",
     "exception": false,
     "start_time": "2024-02-26T02:05:24.342028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scheduler(epoch):\n",
    "    \"\"\"Generating learning rate value for a given epoch.\n",
    "    inputs:\n",
    "        epoch = number of current epoch\n",
    "\n",
    "    outputs:\n",
    "        learning_rate = float learning rate value\n",
    "    \"\"\"\n",
    "    if epoch < 75:\n",
    "        return hyper_params[\"lr\"]\n",
    "    elif epoch < 100:\n",
    "        return hyper_params[\"lr\"]*1e-1\n",
    "    else:\n",
    "        return hyper_params[\"lr\"]*1e-2\n",
    "\n",
    "def get_step_size(total_items, batch_size):\n",
    "    \"\"\"Get step size for given total item size and batch size.\n",
    "    inputs:\n",
    "        total_items = number of total items\n",
    "        batch_size = number of batch size during training or validation\n",
    "\n",
    "    outputs:\n",
    "        step_size = number of step size for model training\n",
    "    \"\"\"\n",
    "    return math.ceil(total_items / batch_size)\n",
    "\n",
    "def calculate_actual_outputs(prior_boxes, gt_boxes, gt_labels, hyper_params):\n",
    "    \"\"\"Calculate ssd actual output values.\n",
    "    Batch operations supported.\n",
    "    inputs:\n",
    "        prior_boxes = (total_prior_boxes, [y1, x1, y2, x2])\n",
    "            these values in normalized format between [0, 1]\n",
    "        gt_boxes (batch_size, gt_box_size, [y1, x1, y2, x2])\n",
    "            these values in normalized format between [0, 1]\n",
    "        gt_labels (batch_size, gt_box_size)\n",
    "        hyper_params = dictionary\n",
    "\n",
    "    outputs:\n",
    "        bbox_deltas = (batch_size, total_bboxes, [delta_y, delta_x, delta_h, delta_w])\n",
    "        bbox_labels = (batch_size, total_bboxes, [0,0,...,0])\n",
    "            labels are one-hot encoded\n",
    "    \"\"\"\n",
    "    batch_size = tf.shape(gt_boxes)[0]\n",
    "    total_labels = hyper_params[\"total_labels\"]\n",
    "    iou_threshold = hyper_params[\"iou_threshold\"]\n",
    "    variances = hyper_params[\"variances\"]\n",
    "    # Number of default bbox\n",
    "    total_prior_boxes = prior_boxes.shape[0]\n",
    "    # Calculate iou values between each bboxes and ground truth boxes\n",
    "    iou_map = generate_iou_map(prior_boxes, gt_boxes)\n",
    "    # Get max index value for each row\n",
    "    max_indices_each_gt_box = tf.argmax(iou_map, axis=2, output_type=tf.int32)\n",
    "    # IoU map has iou values for every gt boxes and we merge these values column wise\n",
    "    merged_iou_map = tf.reduce_max(iou_map, axis=2)\n",
    "\n",
    "    pos_cond = tf.greater(merged_iou_map, iou_threshold)\n",
    "    gt_boxes_map = tf.gather(gt_boxes, max_indices_each_gt_box, batch_dims=1)\n",
    "    expanded_gt_boxes = tf.where(tf.expand_dims(pos_cond, -1), gt_boxes_map, tf.zeros_like(gt_boxes_map))\n",
    "    bbox_deltas = get_deltas_from_bboxes(prior_boxes, expanded_gt_boxes) / variances\n",
    "\n",
    "    gt_labels_map = tf.gather(gt_labels, max_indices_each_gt_box, batch_dims=1)\n",
    "    expanded_gt_labels = tf.where(pos_cond, gt_labels_map, tf.zeros_like(gt_labels_map))\n",
    "    bbox_labels = tf.one_hot(expanded_gt_labels, total_labels)\n",
    "    return bbox_deltas, bbox_labels\n",
    "\n",
    "\n",
    "def generator(dataset, prior_boxes, hyper_params):\n",
    "    \"\"\"Tensorflow data generator for fit method, yielding inputs and outputs.\n",
    "    inputs:\n",
    "        dataset = tf.data.Dataset, PaddedBatchDataset\n",
    "        prior_boxes = (total_prior_boxes, [y1, x1, y2, x2])\n",
    "            these values in normalized format between [0, 1]\n",
    "        hyper_params = dictionary\n",
    "\n",
    "    outputs:\n",
    "        yield inputs, outputs\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            for image_data in dataset:\n",
    "                img, gt_boxes, gt_labels = image_data\n",
    "                # Calculate outputs for training\n",
    "                actual_deltas, actual_labels = calculate_actual_outputs(prior_boxes, gt_boxes, gt_labels, hyper_params)\n",
    "                yield img, (actual_deltas, actual_labels)\n",
    "        except StopIteration:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a403c1be",
   "metadata": {
    "id": "KZ9rhI9ZGEKQ",
    "papermill": {
     "duration": 0.053522,
     "end_time": "2024-02-26T02:05:24.519149",
     "exception": false,
     "start_time": "2024-02-26T02:05:24.465627",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# eval_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c289c4e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:05:24.627414Z",
     "iopub.status.busy": "2024-02-26T02:05:24.627057Z",
     "iopub.status.idle": "2024-02-26T02:05:24.647537Z",
     "shell.execute_reply": "2024-02-26T02:05:24.646749Z"
    },
    "id": "GIG-uml-F27J",
    "papermill": {
     "duration": 0.077171,
     "end_time": "2024-02-26T02:05:24.649390",
     "exception": false,
     "start_time": "2024-02-26T02:05:24.572219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_stats(labels):\n",
    "    \"\"\"Initialise statistics used in evaluation.\n",
    "    inputs:\n",
    "        labels (list)\n",
    "\n",
    "    outputs:\n",
    "        stats (dict)\n",
    "    \"\"\"\n",
    "    stats = {}\n",
    "    for i, label in enumerate(labels):\n",
    "        if i == 0: # first element is bg\n",
    "            continue\n",
    "        stats[i] = {\n",
    "            \"label\": label,\n",
    "            \"total\": 0,\n",
    "            \"tp\": [],\n",
    "            \"fp\": [],\n",
    "            \"scores\": [],\n",
    "        }\n",
    "    return stats\n",
    "\n",
    "def update_stats(pred_bboxes, pred_labels, pred_scores, gt_boxes, gt_labels, stats):\n",
    "    # Calculate iou values between predicted bboxes and ground truth boxes\n",
    "    iou_map = generate_iou_map(pred_bboxes, gt_boxes)\n",
    "    merged_iou_map = tf.reduce_max(iou_map, axis=-1)\n",
    "    max_indices_each_gt = tf.argmax(iou_map, axis=-1, output_type=tf.int32)\n",
    "    sorted_ids = tf.argsort(merged_iou_map, direction=\"DESCENDING\")\n",
    "\n",
    "    count_holder = tf.unique_with_counts(tf.reshape(gt_labels, (-1,)))\n",
    "    for i, gt_label in enumerate(count_holder[0]):\n",
    "        if gt_label == -1:\n",
    "            continue\n",
    "        gt_label = int(gt_label)\n",
    "        stats[gt_label][\"total\"] += int(count_holder[2][i])\n",
    "    for batch_id, m in enumerate(merged_iou_map):\n",
    "        true_labels = []\n",
    "        for i, sorted_id in enumerate(sorted_ids[batch_id]):\n",
    "            pred_label = pred_labels[batch_id, sorted_id]\n",
    "            if pred_label == 0:\n",
    "                continue\n",
    "\n",
    "            iou = merged_iou_map[batch_id, sorted_id]\n",
    "            gt_id = max_indices_each_gt[batch_id, sorted_id]\n",
    "            gt_label = int(gt_labels[batch_id, gt_id])\n",
    "            pred_label = int(pred_label)\n",
    "            score = pred_scores[batch_id, sorted_id]\n",
    "            stats[pred_label][\"scores\"].append(score)\n",
    "            stats[pred_label][\"tp\"].append(0)\n",
    "            stats[pred_label][\"fp\"].append(0)\n",
    "            if iou >= 0.5 and pred_label == gt_label and gt_id not in true_labels:\n",
    "                stats[pred_label][\"tp\"][-1] = 1\n",
    "                true_labels.append(gt_id)\n",
    "            else:\n",
    "                stats[pred_label][\"fp\"][-1] = 1\n",
    "    return stats\n",
    "\n",
    "def calculate_ap(recall, precision):\n",
    "    \"\"\"Calculate Average Precision (AP).\n",
    "    \"\"\"\n",
    "    ap = 0\n",
    "    for r in np.arange(0, 1.1, 0.1):\n",
    "        prec_rec = precision[recall >= r]\n",
    "        if len(prec_rec) > 0:\n",
    "            ap += np.amax(prec_rec)\n",
    "    # By definition AP = sum(max(precision whose recall is above r))/11\n",
    "    ap /= 11\n",
    "    return ap\n",
    "\n",
    "def calculate_mAP(stats):\n",
    "    aps = []\n",
    "    for label in stats:\n",
    "        label_stats = stats[label]\n",
    "        tp = np.array(label_stats[\"tp\"])\n",
    "        fp = np.array(label_stats[\"fp\"])\n",
    "        scores = np.array(label_stats[\"scores\"])\n",
    "        ids = np.argsort(-scores)\n",
    "        total = label_stats[\"total\"]\n",
    "        accumulated_tp = np.cumsum(tp[ids])\n",
    "        accumulated_fp = np.cumsum(fp[ids])\n",
    "        recall = accumulated_tp / total\n",
    "        precision = accumulated_tp / (accumulated_fp + accumulated_tp)\n",
    "        ap = calculate_ap(recall, precision)\n",
    "        stats[label][\"recall\"] = recall\n",
    "        stats[label][\"precision\"] = precision\n",
    "        stats[label][\"AP\"] = ap\n",
    "        aps.append(ap)\n",
    "    mAP = np.mean(aps)\n",
    "    return stats, mAP\n",
    "\n",
    "def evaluate_predictions(dataset, pred_bboxes, pred_labels, pred_scores, labels, batch_size):\n",
    "    stats = init_stats(labels)\n",
    "    for batch_id, image_data in enumerate(dataset):\n",
    "        imgs, gt_boxes, gt_labels = image_data\n",
    "        # try:\n",
    "        #     imgs, gt_boxes, gt_labels = image_data\n",
    "        # except:\n",
    "        #     imgs, gt_boxes, gt_labels = image_data[0], image_data[1][0], image_data[1][1]\n",
    "        start = batch_id * batch_size\n",
    "        end = start + batch_size\n",
    "        batch_bboxes, batch_labels, batch_scores = pred_bboxes[start:end], pred_labels[start:end], pred_scores[start:end]\n",
    "        stats = update_stats(batch_bboxes, batch_labels, batch_scores, gt_boxes, gt_labels, stats)\n",
    "    stats, mAP = calculate_mAP(stats)\n",
    "    print(\"mAP: {}\".format(float(mAP)))\n",
    "    return stats, mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41b19a1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:05:24.758580Z",
     "iopub.status.busy": "2024-02-26T02:05:24.758209Z",
     "iopub.status.idle": "2024-02-26T02:05:24.770196Z",
     "shell.execute_reply": "2024-02-26T02:05:24.769269Z"
    },
    "id": "T2QH8nntIUUq",
    "papermill": {
     "duration": 0.069025,
     "end_time": "2024-02-26T02:05:24.771971",
     "exception": false,
     "start_time": "2024-02-26T02:05:24.702946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MeanAveragePrecisionCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"Calculate Mean Average Precision (mAP) at the end of every epoch.\n",
    "    Early stop and saves model with best mAP.\n",
    "    \"\"\"\n",
    "    def __init__(self, val_data, val_steps, labels, prior_boxes, hyper_params, batch_size, patience, model_save_path, **kwargs):\n",
    "        super(MeanAveragePrecisionCallback, self).__init__(**kwargs)\n",
    "        self.val_data = val_data\n",
    "        self.val_steps = val_steps\n",
    "        self.labels = labels\n",
    "        self.prior_boxes = prior_boxes\n",
    "        self.hyper_params = hyper_params\n",
    "        self.batch_size = batch_size\n",
    "        self.best_mAP = 0.0\n",
    "        self.mAP_values = []  # To store mAP values at each epoch\n",
    "        self.patience = patience\n",
    "        self.wait = 0\n",
    "        self.model_save_path = model_save_path\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        ssd_decoder_model = get_decoder_model(self.model, self.prior_boxes, self.hyper_params)\n",
    "        pred_bboxes, pred_labels, pred_scores = ssd_decoder_model.predict(self.val_data, steps=self.val_steps, verbose=1)\n",
    "        stats, mAP = evaluate_predictions(self.val_data, pred_bboxes, pred_labels, pred_scores, self.labels, self.batch_size)\n",
    "        self.mAP_values.append(mAP)\n",
    "\n",
    "        if mAP > self.best_mAP:\n",
    "            self.wait = 0\n",
    "            self.best_mAP = mAP\n",
    "            self.model.save_weights(self.model_save_path)\n",
    "        else:\n",
    "            self.wait += 1\n",
    "\n",
    "        if self.wait >= self.patience:\n",
    "            print(f\"Early stopping at epoch {epoch + 1} due to lack of improvement.\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "    def on_train_begin(self, epoch, logs=None):\n",
    "        self.best_mAP = 0.0\n",
    "        self.wait = 0\n",
    "        self.mAP_values = []\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        print(f'\\nBest Mean Average Precision: {self.best_mAP}\\n')\n",
    "\n",
    "    def get_mAP_values(self):\n",
    "        return self.mAP_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd4af20",
   "metadata": {
    "id": "BnvrtbMJGcah",
    "papermill": {
     "duration": 0.05382,
     "end_time": "2024-02-26T02:05:24.879757",
     "exception": false,
     "start_time": "2024-02-26T02:05:24.825937",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba36612f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:05:24.988345Z",
     "iopub.status.busy": "2024-02-26T02:05:24.987987Z",
     "iopub.status.idle": "2024-02-26T02:05:25.000863Z",
     "shell.execute_reply": "2024-02-26T02:05:24.999963Z"
    },
    "id": "eLt0sLKBGYj-",
    "papermill": {
     "duration": 0.069794,
     "end_time": "2024-02-26T02:05:25.002759",
     "exception": false,
     "start_time": "2024-02-26T02:05:24.932965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, Input, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "class SSDDecoder(Layer):\n",
    "    \"\"\"Generating bounding boxes and labels from ssd predictions.\n",
    "    First calculating the boxes from predicted deltas and label probs.\n",
    "    Then applied non max suppression and selecting top_n boxes by scores.\n",
    "    inputs:\n",
    "        pred_deltas = (batch_size, total_prior_boxes, [delta_y, delta_x, delta_h, delta_w])\n",
    "        pred_label_probs = (batch_size, total_prior_boxes, [0,0,...,0])\n",
    "    outputs:\n",
    "        pred_bboxes = (batch_size, top_n, [y1, x1, y2, x2])\n",
    "        pred_labels = (batch_size, top_n)\n",
    "            1 to total label number\n",
    "        pred_scores = (batch_size, top_n)\n",
    "    \"\"\"\n",
    "    def __init__(self, prior_boxes, variances, max_total_size=200, score_threshold=0.5, **kwargs):\n",
    "        super(SSDDecoder, self).__init__(**kwargs)\n",
    "        self.prior_boxes = prior_boxes\n",
    "        self.variances = variances\n",
    "        self.max_total_size = max_total_size\n",
    "        self.score_threshold = score_threshold\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(SSDDecoder, self).get_config()\n",
    "        config.update({\n",
    "            \"prior_boxes\": self.prior_boxes.numpy(),\n",
    "            \"variances\": self.variances,\n",
    "            \"max_total_size\": self.max_total_size,\n",
    "            \"score_threshold\": self.score_threshold\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs):\n",
    "        pred_deltas = inputs[0]\n",
    "        pred_label_probs = inputs[1]\n",
    "        batch_size = tf.shape(pred_deltas)[0]\n",
    "\n",
    "        pred_deltas *= self.variances\n",
    "        pred_bboxes = get_bboxes_from_deltas(self.prior_boxes, pred_deltas)\n",
    "\n",
    "        pred_labels_map = tf.expand_dims(tf.argmax(pred_label_probs, -1), -1)\n",
    "        pred_labels = tf.where(tf.not_equal(pred_labels_map, 0), pred_label_probs, tf.zeros_like(pred_label_probs))\n",
    "        # Reshape bboxes for non max suppression\n",
    "        pred_bboxes = tf.reshape(pred_bboxes, (batch_size, -1, 1, 4))\n",
    "\n",
    "        final_bboxes, final_scores, final_labels, _ = non_max_suppression(\n",
    "                                                                    pred_bboxes, pred_labels,\n",
    "                                                                    max_output_size_per_class=self.max_total_size,\n",
    "                                                                    max_total_size=self.max_total_size,\n",
    "                                                                    score_threshold=self.score_threshold)\n",
    "        return final_bboxes, final_labels, final_scores\n",
    "\n",
    "def get_decoder_model(base_model, prior_boxes, hyper_params):\n",
    "    \"\"\"Decoding ssd predictions to valid bounding boxes and labels.\n",
    "    inputs:\n",
    "        base_model = tf.keras.model, base ssd model\n",
    "        prior_boxes = (total_prior_boxes, [y1, x1, y2, x2])\n",
    "            these values in normalized format between [0, 1]\n",
    "        hyper_params = dictionary\n",
    "\n",
    "    outputs:\n",
    "        ssd_decoder_model = tf.keras.model\n",
    "    \"\"\"\n",
    "    bboxes, classes, scores = SSDDecoder(prior_boxes, hyper_params[\"variances\"])(base_model.output)\n",
    "    return Model(inputs=base_model.input, outputs=[bboxes, classes, scores])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48ec42c",
   "metadata": {
    "id": "mEFNZpWUGoyx",
    "papermill": {
     "duration": 0.053977,
     "end_time": "2024-02-26T02:05:25.110009",
     "exception": false,
     "start_time": "2024-02-26T02:05:25.056032",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60b6d990",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:05:25.217773Z",
     "iopub.status.busy": "2024-02-26T02:05:25.217126Z",
     "iopub.status.idle": "2024-02-26T02:05:25.229999Z",
     "shell.execute_reply": "2024-02-26T02:05:25.229065Z"
    },
    "id": "c0N10FKZGnBk",
    "papermill": {
     "duration": 0.068613,
     "end_time": "2024-02-26T02:05:25.232059",
     "exception": false,
     "start_time": "2024-02-26T02:05:25.163446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, Input, Conv2D, MaxPool2D, Activation\n",
    "\n",
    "class HeadWrapper(Layer):\n",
    "    \"\"\"Merging all feature maps for detections.\n",
    "    inputs:\n",
    "        conv4_3 = (batch_size, (layer_shape x aspect_ratios), last_dimension)\n",
    "            ssd300 conv4_3 shape => (38 x 38 x 4) = 5776\n",
    "        conv7 = (batch_size, (layer_shape x aspect_ratios), last_dimension)\n",
    "            ssd300 conv7 shape => (19 x 19 x 6) = 2166\n",
    "        conv8_2 = (batch_size, (layer_shape x aspect_ratios), last_dimension)\n",
    "            ssd300 conv8_2 shape => (10 x 10 x 6) = 600\n",
    "        conv9_2 = (batch_size, (layer_shape x aspect_ratios), last_dimension)\n",
    "            ssd300 conv9_2 shape => (5 x 5 x 6) = 150\n",
    "        conv10_2 = (batch_size, (layer_shape x aspect_ratios), last_dimension)\n",
    "            ssd300 conv10_2 shape => (3 x 3 x 4) = 36\n",
    "        conv11_2 = (batch_size, (layer_shape x aspect_ratios), last_dimension)\n",
    "            ssd300 conv11_2 shape => (1 x 1 x 4) = 4\n",
    "                                           Total = 8732 default box\n",
    "\n",
    "    outputs:\n",
    "        merged_head = (batch_size, total_prior_boxes, last_dimension)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, last_dimension, **kwargs):\n",
    "        super(HeadWrapper, self).__init__(**kwargs)\n",
    "        self.last_dimension = last_dimension\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(HeadWrapper, self).get_config()\n",
    "        config.update({\"last_dimension\": self.last_dimension})\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs):\n",
    "        last_dimension = self.last_dimension\n",
    "        batch_size = tf.shape(inputs[0])[0]\n",
    "        outputs = []\n",
    "        for conv_layer in inputs:\n",
    "            outputs.append(tf.reshape(conv_layer, (batch_size, -1, last_dimension)))\n",
    "        return tf.concat(outputs, axis=1)\n",
    "\n",
    "def get_head_from_outputs(hyper_params, outputs):\n",
    "    \"\"\"Generating ssd bbox delta and label heads.\n",
    "    inputs:\n",
    "        hyper_params = dictionary\n",
    "        outputs = list of ssd layers output to be used for prediction\n",
    "\n",
    "    outputs:\n",
    "        pred_deltas = merged outputs for bbox delta head\n",
    "        pred_labels = merged outputs for bbox label head\n",
    "    \"\"\"\n",
    "    total_labels = hyper_params[\"total_labels\"]\n",
    "    # +1 for ratio 1\n",
    "    len_aspect_ratios = [len(x) + 1 for x in hyper_params[\"aspect_ratios\"]]\n",
    "    # print(len_aspect_ratios)\n",
    "    labels_head = []\n",
    "    boxes_head = []\n",
    "    for i, output in enumerate(outputs):\n",
    "        # print(i)\n",
    "        aspect_ratio = len_aspect_ratios[i]\n",
    "        labels_head.append(Conv2D(aspect_ratio * total_labels, (3, 3), padding=\"same\", name=\"{}_conv_label_output\".format(i+1))(output))\n",
    "        boxes_head.append(Conv2D(aspect_ratio * 4, (3, 3), padding=\"same\", name=\"{}_conv_boxes_output\".format(i+1))(output))\n",
    "\n",
    "    pred_labels = HeadWrapper(total_labels, name=\"labels_head\")(labels_head)\n",
    "    pred_labels = Activation(\"softmax\", name=\"conf\")(pred_labels)\n",
    "\n",
    "    pred_deltas = HeadWrapper(4, name=\"loc\")(boxes_head)\n",
    "    return pred_deltas, pred_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a9ca8b",
   "metadata": {
    "id": "gJANTXL-HBrD",
    "papermill": {
     "duration": 0.053548,
     "end_time": "2024-02-26T02:05:25.340241",
     "exception": false,
     "start_time": "2024-02-26T02:05:25.286693",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e57c3e",
   "metadata": {
    "id": "FaalWXrEH4PN",
    "papermill": {
     "duration": 0.053798,
     "end_time": "2024-02-26T02:05:25.447881",
     "exception": false,
     "start_time": "2024-02-26T02:05:25.394083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ssd_loss: cross-entropy/focal and huber loss\n",
    "\n",
    "Focal loss for classification task and Huber loss for regression task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8058d21d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:05:25.556122Z",
     "iopub.status.busy": "2024-02-26T02:05:25.555720Z",
     "iopub.status.idle": "2024-02-26T02:05:25.573615Z",
     "shell.execute_reply": "2024-02-26T02:05:25.572750Z"
    },
    "id": "no7DmauDH51C",
    "papermill": {
     "duration": 0.074285,
     "end_time": "2024-02-26T02:05:25.575587",
     "exception": false,
     "start_time": "2024-02-26T02:05:25.501302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomLoss(object):\n",
    "    \"\"\"Composition of Focal and Huber losses.\"\"\"\n",
    "\n",
    "    def __init__(self, neg_pos_ratio, loc_loss_alpha,\n",
    "                 alpha,\n",
    "                 gamma,\n",
    "                 use_focal=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            neg_pos_ratio: a float number representing the negative to positive ratio.\n",
    "            loc_loss_alpha: a float number representing the localization loss.\n",
    "            alpha, gamma: a float number for Focal loss formula.\n",
    "        \"\"\"\n",
    "        self.neg_pos_ratio = tf.constant(neg_pos_ratio, dtype=tf.float32)\n",
    "        self.loc_loss_alpha = tf.constant(loc_loss_alpha, dtype=tf.float32)\n",
    "        self.alpha = tf.constant(alpha, dtype=tf.float32)\n",
    "        self.gamma = tf.constant(gamma, dtype=tf.float32)\n",
    "        self.use_focal = use_focal\n",
    "\n",
    "    def loc_loss_fn(self, actual_deltas, pred_deltas):\n",
    "        \"\"\"Calculating SSD localization loss value for only positive samples.\n",
    "        inputs:\n",
    "            actual_deltas = (batch_size, total_prior_boxes, [delta_y, delta_x, delta_h, delta_w])\n",
    "            pred_deltas = (batch_size, total_prior_boxes, [delta_y, delta_x, delta_h, delta_w])\n",
    "\n",
    "        outputs:\n",
    "            loc_loss = localization / bbox / regression loss value\n",
    "        \"\"\"\n",
    "        # Localization / bbox / regression loss calculation for all bboxes\n",
    "        loc_loss_fn = tf.losses.Huber(reduction=tf.losses.Reduction.NONE) # delta=1.0\n",
    "        loc_loss_for_all = loc_loss_fn(actual_deltas, pred_deltas)\n",
    "\n",
    "        # After tf 2.2.0 version, the huber calculates mean over the last axis\n",
    "        loc_loss_for_all = tf.cond(tf.greater(tf.rank(loc_loss_for_all), tf.constant(2)),\n",
    "                                   lambda: tf.reduce_sum(loc_loss_for_all, axis=-1),\n",
    "                                   lambda: loc_loss_for_all * tf.cast(tf.shape(pred_deltas)[-1], dtype=tf.float32))\n",
    "\n",
    "        # Creating Positive Mask\n",
    "        pos_cond = tf.reduce_any(tf.not_equal(actual_deltas, tf.constant(0.0)), axis=2)\n",
    "        pos_mask = tf.cast(pos_cond, dtype=tf.float32)\n",
    "        # Counting Total Positive Bounding Boxes\n",
    "        total_pos_bboxes = tf.reduce_sum(pos_mask, axis=1)\n",
    "\n",
    "        # Calculating Localization Loss for Positive Bounding Boxes\n",
    "        loc_loss = tf.reduce_sum(pos_mask * loc_loss_for_all, axis=-1)\n",
    "        # Handling Cases with No Positive Bounding Boxes\n",
    "        total_pos_bboxes = tf.where(tf.equal(total_pos_bboxes, tf.constant(0.0)), tf.constant(1.0), total_pos_bboxes)\n",
    "        # Final Localization Loss Calculation\n",
    "        loc_loss = loc_loss / total_pos_bboxes\n",
    "        return loc_loss * self.loc_loss_alpha\n",
    "\n",
    "    def conf_loss_fn(self, actual_labels, pred_labels):\n",
    "        \"\"\"Calculating SSD confidence loss value with hard negative mining as mentioned in the paper.\n",
    "        Replaced CategoricalCrossentropy with CategoricalFocalCrossentropy.\n",
    "        inputs:\n",
    "            actual_labels = (batch_size, total_prior_boxes, total_labels)\n",
    "            pred_labels = (batch_size, total_prior_boxes, total_labels)\n",
    "\n",
    "        outputs:\n",
    "            conf_loss = confidence / class / label loss value\n",
    "        \"\"\"\n",
    "        # tf.print(actual_labels) # one-hot\n",
    "        # tf.print(pred_labels) # float32\n",
    "\n",
    "        # Confidence / Label loss calculation for all labels\n",
    "        if self.use_focal:\n",
    "            conf_loss_fn = tf.keras.losses.CategoricalFocalCrossentropy(alpha=self.alpha, gamma=self.gamma, reduction=tf.losses.Reduction.NONE)\n",
    "            conf_loss_for_all = conf_loss_fn(actual_labels, pred_labels)\n",
    "            # tf.print(\"Confidence Loss:\", conf_loss_for_all)\n",
    "        else:\n",
    "            conf_loss_fn = tf.losses.CategoricalCrossentropy(reduction=tf.losses.Reduction.NONE)\n",
    "            conf_loss_for_all = conf_loss_fn(actual_labels, pred_labels)\n",
    "            # tf.print(\"Confidence Loss:\", conf_loss_for_all)\n",
    "\n",
    "        # Creating Positive Mask for non-background class\n",
    "        pos_cond = tf.reduce_any(tf.not_equal(actual_labels[..., 1:], tf.constant(0.0)), axis=2)\n",
    "        pos_mask = tf.cast(pos_cond, dtype=tf.float32)\n",
    "        # Counting Total Positive Bounding Boxes\n",
    "        total_pos_bboxes = tf.reduce_sum(pos_mask, axis=1)\n",
    "\n",
    "        # Hard negative mining\n",
    "        total_neg_bboxes = tf.cast(total_pos_bboxes * self.neg_pos_ratio, tf.int32)\n",
    "\n",
    "        masked_loss = conf_loss_for_all * actual_labels[..., 0]\n",
    "        sorted_loss = tf.argsort(masked_loss, direction=\"DESCENDING\")\n",
    "        sorted_loss = tf.argsort(sorted_loss)\n",
    "        neg_cond = tf.less(sorted_loss, tf.expand_dims(total_neg_bboxes, axis=1))\n",
    "        neg_mask = tf.cast(neg_cond, dtype=tf.float32)\n",
    "\n",
    "        final_mask = pos_mask + neg_mask\n",
    "        conf_loss = tf.reduce_sum(final_mask * conf_loss_for_all, axis=-1)\n",
    "        total_pos_bboxes = tf.where(tf.equal(total_pos_bboxes, tf.constant(0.0)), tf.constant(1.0), total_pos_bboxes)\n",
    "        conf_loss = conf_loss / total_pos_bboxes\n",
    "\n",
    "        return conf_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840b6cd1",
   "metadata": {
    "id": "qpEJH16WFrWQ",
    "papermill": {
     "duration": 0.053342,
     "end_time": "2024-02-26T02:05:25.682257",
     "exception": false,
     "start_time": "2024-02-26T02:05:25.628915",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "569b5f87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:05:25.790305Z",
     "iopub.status.busy": "2024-02-26T02:05:25.789979Z",
     "iopub.status.idle": "2024-02-26T02:05:25.815790Z",
     "shell.execute_reply": "2024-02-26T02:05:25.814875Z"
    },
    "id": "1RSbUDlZFp-4",
    "papermill": {
     "duration": 0.082355,
     "end_time": "2024-02-26T02:05:25.817695",
     "exception": false,
     "start_time": "2024-02-26T02:05:25.735340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessing(image_data, final_height, final_width, augmentation_fn=None, evaluate=False):\n",
    "    \"\"\"Image resizing operation handled before batch operations.\n",
    "    inputs:\n",
    "        image_data = tensorflow dataset image_data\n",
    "        final_height = final image height after resizing\n",
    "        final_width = final image width after resizing\n",
    "\n",
    "    outputs:\n",
    "        img = (final_height, final_width, channels)\n",
    "        gt_boxes = (gt_box_size, [y1, x1, y2, x2])\n",
    "        gt_labels = (gt_box_size)\n",
    "    \"\"\"\n",
    "    img = image_data[\"image\"]\n",
    "    gt_boxes = image_data[\"objects\"][\"bbox\"]\n",
    "    gt_labels = tf.cast(image_data[\"objects\"][\"label\"] + 1, tf.int32)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(img, (final_height, final_width))\n",
    "    if evaluate:\n",
    "        not_diff = tf.logical_not(image_data[\"objects\"][\"is_difficult\"])\n",
    "        gt_boxes = gt_boxes[not_diff]\n",
    "        gt_labels = gt_labels[not_diff]\n",
    "    if augmentation_fn:\n",
    "        img, gt_boxes = augmentation_fn(img, gt_boxes)\n",
    "    return img, gt_boxes, gt_labels\n",
    "\n",
    "def tfr_preprocessing(image_data, final_height, final_width, augmentation_fn=None, evaluate=False):\n",
    "\n",
    "    img = image_data[\"image/encoded\"]\n",
    "    img = tf.io.decode_image(img, channels=3)\n",
    "    xmin = tf.sparse.to_dense(image_data['image/object/bbox/xmin'])\n",
    "    ymin = tf.sparse.to_dense(image_data['image/object/bbox/ymin'])\n",
    "    xmax = tf.sparse.to_dense(image_data['image/object/bbox/xmax'])\n",
    "    ymax = tf.sparse.to_dense(image_data['image/object/bbox/ymax'])\n",
    "    gt_boxes = tf.stack(\n",
    "        [ymin, xmin, ymax, xmax], axis=-1\n",
    "    )\n",
    "    gt_labels = tf.sparse.to_dense(image_data['image/object/class/label'])\n",
    "    # gt_labels +=1 # VOC has idx 0 but tfr does not\n",
    "    gt_labels = tf.cast(gt_labels, tf.int32)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img.set_shape([None,None,3])\n",
    "    img = tf.image.resize(img, (final_height, final_width))\n",
    "    if augmentation_fn:\n",
    "        img, gt_boxes = augmentation_fn(img, gt_boxes)\n",
    "\n",
    "    return img, gt_boxes, gt_labels\n",
    "\n",
    "def tfr_dataset(data_dir):\n",
    "\n",
    "    image_feature_description={\n",
    "      'image/encoded':tf.io.FixedLenFeature([],tf.string),\n",
    "      'image/object/bbox/xmin':tf.io.VarLenFeature(tf.float32),\n",
    "      'image/object/bbox/ymin':tf.io.VarLenFeature(tf.float32),\n",
    "      'image/object/bbox/xmax':tf.io.VarLenFeature(tf.float32),\n",
    "      'image/object/bbox/ymax':tf.io.VarLenFeature(tf.float32),\n",
    "      'image/object/class/label':tf.io.VarLenFeature(tf.int64),\n",
    "    }\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(filenames=data_dir)\n",
    "    count = 0\n",
    "    for record in dataset:\n",
    "        count += 1\n",
    "    parsed_dataset = dataset.map(lambda x: tf.io.parse_single_example(x, image_feature_description))\n",
    "\n",
    "    return parsed_dataset, count\n",
    "\n",
    "def get_dataset(name, split, data_dir=\"~/tensorflow_datasets\"):\n",
    "    \"\"\"Get tensorflow dataset split and info.\n",
    "    inputs:\n",
    "        name = name of the dataset, voc/2007, voc/2012, etc.\n",
    "        split = data split string, should be one of [\"train\", \"validation\", \"test\"]\n",
    "        data_dir = read/write path for tensorflow datasets\n",
    "\n",
    "    outputs:\n",
    "        dataset = tensorflow dataset split\n",
    "        info = tensorflow dataset info\n",
    "    \"\"\"\n",
    "    assert split in [\"train\", \"train+validation\", \"validation\", \"test\"]\n",
    "    dataset, info = tfds.load(name, split=split, data_dir=data_dir, with_info=True)\n",
    "    return dataset, info\n",
    "\n",
    "def get_total_item_size(info, split):\n",
    "    \"\"\"Get total item size for given split.\n",
    "    inputs:\n",
    "        info = tensorflow dataset info\n",
    "        split = data split string, should be one of [\"train\", \"validation\", \"test\"]\n",
    "\n",
    "    outputs:\n",
    "        total_item_size = number of total items\n",
    "    \"\"\"\n",
    "    assert split in [\"train\", \"train+validation\", \"validation\", \"test\"]\n",
    "    if split == \"train+validation\":\n",
    "        return info.splits[\"train\"].num_examples + info.splits[\"validation\"].num_examples\n",
    "    return info.splits[split].num_examples\n",
    "\n",
    "def tfr_labels(pbtxt_fname):\n",
    "\n",
    "    from object_detection.utils import label_map_util\n",
    "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
    "    categories = label_map_util.convert_label_map_to_categories(\n",
    "        label_map, max_num_classes=90, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "    print(categories)\n",
    "    labels = [item['name'] for item in categories]\n",
    "    return len(category_index.keys()), labels\n",
    "\n",
    "def get_labels(info):\n",
    "    \"\"\"Get label names list.\n",
    "    inputs:\n",
    "        info = tensorflow dataset info\n",
    "\n",
    "    outputs:\n",
    "        labels = [labels list]\n",
    "    \"\"\"\n",
    "    return info.features[\"labels\"].names\n",
    "\n",
    "def get_custom_imgs(custom_image_path):\n",
    "    \"\"\"Generating a list of images for given path.\n",
    "    inputs:\n",
    "        custom_image_path = folder of the custom images\n",
    "    outputs:\n",
    "        custom image list = [path1, path2]\n",
    "    \"\"\"\n",
    "    img_paths = []\n",
    "    for path, dir, filenames in os.walk(custom_image_path):\n",
    "        for filename in filenames:\n",
    "            img_paths.append(os.path.join(path, filename))\n",
    "        break\n",
    "    return img_paths\n",
    "\n",
    "def custom_data_generator(img_paths, final_height, final_width):\n",
    "    \"\"\"Yielding custom entities as dataset.\n",
    "    inputs:\n",
    "        img_paths = custom image paths\n",
    "        final_height = final image height after resizing\n",
    "        final_width = final image width after resizing\n",
    "    outputs:\n",
    "        img = (final_height, final_width, depth)\n",
    "        dummy_gt_boxes = (None, None)\n",
    "        dummy_gt_labels = (None, )\n",
    "    \"\"\"\n",
    "    for img_path in img_paths:\n",
    "        image = Image.open(img_path)\n",
    "        resized_image = image.resize((final_width, final_height), Image.LANCZOS)\n",
    "        img = np.array(resized_image)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "        yield img, tf.constant([[]], dtype=tf.float32), tf.constant([], dtype=tf.int32)\n",
    "\n",
    "def get_data_types():\n",
    "    \"\"\"Generating data types for tensorflow datasets.\n",
    "    outputs:\n",
    "        data types = output data types for (images, ground truth boxes, ground truth labels)\n",
    "    \"\"\"\n",
    "    return (tf.float32, tf.float32, tf.int32)\n",
    "\n",
    "def get_data_shapes():\n",
    "    \"\"\"Generating data shapes for tensorflow datasets.\n",
    "    outputs:\n",
    "        data shapes = output data shapes for (images, ground truth boxes, ground truth labels)\n",
    "    \"\"\"\n",
    "    return ([None, None, None], [None, None], [None,])\n",
    "\n",
    "def get_padding_values():\n",
    "    \"\"\"Generating padding values for missing values in batch for tensorflow datasets.\n",
    "    outputs:\n",
    "        padding values = padding values with dtypes for (images, ground truth boxes, ground truth labels)\n",
    "    \"\"\"\n",
    "    return (tf.constant(0, tf.float32), tf.constant(0, tf.float32), tf.constant(-1, tf.int32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed5e073",
   "metadata": {
    "id": "amJ3m8RBjPU1",
    "papermill": {
     "duration": 0.052425,
     "end_time": "2024-02-26T02:05:25.923094",
     "exception": false,
     "start_time": "2024-02-26T02:05:25.870669",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# process Roboflow TFRecord\n",
    "\n",
    "\n",
    "As of now, this only accepts TFR directly from Roboflow with apply removed from preprocessing.\n",
    "\n",
    "Issue: use_image_if_no_bounding_boxes=True leads to missing prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72f1f330",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:05:26.031021Z",
     "iopub.status.busy": "2024-02-26T02:05:26.030137Z",
     "iopub.status.idle": "2024-02-26T02:05:26.038075Z",
     "shell.execute_reply": "2024-02-26T02:05:26.037113Z"
    },
    "id": "Djg8OEQWCOxp",
    "papermill": {
     "duration": 0.06357,
     "end_time": "2024-02-26T02:05:26.040033",
     "exception": false,
     "start_time": "2024-02-26T02:05:25.976463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_for_nans(parsed_dataset, final_height, final_width):\n",
    "    for record in parsed_dataset:\n",
    "        img, gt_boxes, gt_labels = tfr_preprocessing(record, final_height, final_width)\n",
    "        gt_labels = tf.cast(gt_labels, tf.float32)\n",
    "\n",
    "        # Check for NaN values in the image tensor\n",
    "        img_has_nan = tf.reduce_any(tf.math.is_nan(img))\n",
    "\n",
    "        # Check for NaN values in the ground truth boxes tensor\n",
    "        gt_boxes_has_nan = tf.reduce_any(tf.math.is_nan(gt_boxes))\n",
    "\n",
    "        # Check for NaN values in the ground truth labels tensor\n",
    "        gt_labels_has_nan = tf.reduce_any(tf.math.is_nan(gt_labels))\n",
    "\n",
    "        # Print information if NaN values are found\n",
    "        if img_has_nan or gt_boxes_has_nan or gt_labels_has_nan:\n",
    "            print(\"NaN values found in the dataset!\")\n",
    "            print(\"Image has NaN values:\", img_has_nan.numpy())\n",
    "            print(\"Ground truth boxes have NaN values:\", gt_boxes_has_nan.numpy())\n",
    "            print(\"Ground truth labels have NaN values:\", gt_labels_has_nan.numpy())\n",
    "\n",
    "            # You can return or handle the information accordingly\n",
    "            return True\n",
    "\n",
    "    print(\"No NaN values found in the dataset.\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d39638b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:05:26.149290Z",
     "iopub.status.busy": "2024-02-26T02:05:26.148606Z",
     "iopub.status.idle": "2024-02-26T02:05:27.116842Z",
     "shell.execute_reply": "2024-02-26T02:05:27.115737Z"
    },
    "id": "3uobVEH9Lidp",
    "outputId": "fe13c28a-4e54-43c7-b6ba-d6b343a8da6d",
    "papermill": {
     "duration": 1.024916,
     "end_time": "2024-02-26T02:05:27.118887",
     "exception": false,
     "start_time": "2024-02-26T02:05:26.093971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 1, 'name': 'Hole'}, {'id': 2, 'name': 'Knot'}, {'id': 3, 'name': 'Line'}, {'id': 4, 'name': 'Stain'}]\n",
      "5724 225\n",
      "4 ['bg', 'Hole', 'Knot', 'Line', 'Stain']\n",
      "([None, None, None], [None, None], [None]) (<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=int32, numpy=-1>)\n"
     ]
    }
   ],
   "source": [
    "# Train Parameters\n",
    "batch_size = hyper_params[\"batch_size\"]\n",
    "epochs = hyper_params[\"epochs\"]\n",
    "img_size = hyper_params[\"img_size\"] # determined by the backbone\n",
    "\n",
    "if hyper_params[\"dataset\"] == 0:\n",
    "    # dut\n",
    "    train_files='/kaggle/working/Fabric-Defect-Capstone-1/train/defects.tfrecord'\n",
    "    val_files='/kaggle/working/Fabric-Defect-Capstone-1/valid/defects.tfrecord'\n",
    "    test_files='/kaggle/working/Fabric-Defect-Capstone-1/test/defects.tfrecord'\n",
    "    num_classes, labels = tfr_labels('/kaggle/working/Fabric-Defect-Capstone-1/train/defects_label_map.pbtxt')\n",
    "elif hyper_params[\"dataset\"] == 1:\n",
    "    # tilda\n",
    "    train_files='/kaggle/working/TILDA-Fabric-2/train/Fabric.tfrecord'\n",
    "    val_files='/kaggle/working/TILDA-Fabric-2/valid/Fabric.tfrecord'\n",
    "    test_files='/kaggle/working/TILDA-Fabric-2/test/Fabric.tfrecord'\n",
    "    num_classes, labels = tfr_labels('//kaggle/working/TILDA-Fabric-2/train/Fabric_label_map.pbtxt')\n",
    "elif hyper_params[\"dataset\"] == 2:\n",
    "    # daffodil\n",
    "    train_files='/kaggle/working/Fabric-Defect-Daffodil-1/train/defects.tfrecord'\n",
    "    val_files='/kaggle/working/Fabric-Defect-Daffodil-1/valid/defects.tfrecord'\n",
    "    test_files='/kaggle/working/Fabric-Defect-Daffodil-1/test/defects.tfrecord'\n",
    "    num_classes, labels = tfr_labels('/kaggle/working/Fabric-Defect-Daffodil-1/train/defects_label_map.pbtxt')\n",
    "elif hyper_params[\"dataset\"] == 3:\n",
    "    # thesis\n",
    "    train_files='/kaggle/working/Fabric-Defect-Thesis-1/train/defects.tfrecord'\n",
    "    val_files='/kaggle/working/Fabric-Defect-Thesis-1/valid/defects.tfrecord'\n",
    "    test_files='/kaggle/working/Fabric-Defect-Thesis-1/test/defects.tfrecord'\n",
    "    num_classes, labels = tfr_labels('/kaggle/working/Fabric-Defect-Thesis-1/train/defects_label_map.pbtxt')\n",
    "elif hyper_params[\"dataset\"] == 4:\n",
    "    pass\n",
    "\n",
    "train_data, train_total_items = tfr_dataset(train_files)\n",
    "val_data, val_total_items = tfr_dataset(val_files)\n",
    "\n",
    "# check_for_nans(train_data, img_size, img_size)\n",
    "# check_for_nans(val_data, img_size, img_size)\n",
    "\n",
    "labels = [\"bg\"] + labels\n",
    "hyper_params[\"total_labels\"] = len(labels)\n",
    "print(train_total_items, val_total_items)\n",
    "print(num_classes, labels)\n",
    "\n",
    "train_data = train_data.map(lambda x : tfr_preprocessing(x, img_size, img_size))\n",
    "val_data = val_data.map(lambda x : tfr_preprocessing(x, img_size, img_size))\n",
    "\n",
    "data_shapes = get_data_shapes()\n",
    "padding_values = get_padding_values()\n",
    "print(data_shapes, padding_values)\n",
    "train_data = train_data.shuffle(batch_size*4).padded_batch(batch_size, padded_shapes=data_shapes, padding_values=padding_values)\n",
    "val_data = val_data.padded_batch(batch_size, padded_shapes=data_shapes, padding_values=padding_values)\n",
    "\n",
    "def transform(dataset):\n",
    "    autotune = tf.data.experimental.AUTOTUNE\n",
    "    dataset = dataset.apply(tf.data.experimental.ignore_errors())\n",
    "    dataset = dataset.repeat(epochs)\n",
    "    dataset = dataset.prefetch(autotune)\n",
    "    return dataset\n",
    "\n",
    "train_data = transform(train_data)\n",
    "\n",
    "ssd_train_feed = generator(train_data, prior_boxes, hyper_params)\n",
    "ssd_val_feed = generator(val_data, prior_boxes, hyper_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3966f9a",
   "metadata": {
    "id": "Nj-9WLjVHLhN",
    "papermill": {
     "duration": 0.052587,
     "end_time": "2024-02-26T02:05:27.225221",
     "exception": false,
     "start_time": "2024-02-26T02:05:27.172634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd1de361",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T02:05:27.334708Z",
     "iopub.status.busy": "2024-02-26T02:05:27.333829Z",
     "iopub.status.idle": "2024-02-26T08:35:38.689811Z",
     "shell.execute_reply": "2024-02-26T08:35:38.688773Z"
    },
    "id": "tootxTnvHA3t",
    "outputId": "405e64fe-a3f1-4472-e81e-ff22fd7eefcd",
    "papermill": {
     "duration": 23417.004165,
     "end_time": "2024-02-26T08:35:44.283645",
     "exception": false,
     "start_time": "2024-02-26T02:05:27.279480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9406464/9406464 [==============================] - 1s 0us/step\n",
      "716 29\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1708913179.165366      68 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 6s 107ms/step\n",
      "mAP: 0.5002973921098537\n",
      "716/716 [==============================] - 347s 386ms/step - loss: 1.4694 - loc_loss: 0.4862 - conf_loss: 0.9832 - val_loss: 2.8143 - val_loc_loss: 0.8923 - val_conf_loss: 1.9221\n",
      "Epoch 2/200\n",
      "29/29 [==============================] - 6s 106ms/step\n",
      "mAP: 0.5317524207847505\n",
      "716/716 [==============================] - 268s 374ms/step - loss: 1.4644 - loc_loss: 0.4837 - conf_loss: 0.9807 - val_loss: 2.8183 - val_loc_loss: 0.8934 - val_conf_loss: 1.9249\n",
      "Epoch 3/200\n",
      "29/29 [==============================] - 6s 106ms/step\n",
      "mAP: 0.5243008973555027\n",
      "716/716 [==============================] - 267s 373ms/step - loss: 1.4582 - loc_loss: 0.4818 - conf_loss: 0.9764 - val_loss: 2.7581 - val_loc_loss: 0.8847 - val_conf_loss: 1.8734\n",
      "Epoch 4/200\n",
      "29/29 [==============================] - 6s 105ms/step\n",
      "mAP: 0.5160626937441394\n",
      "716/716 [==============================] - 267s 372ms/step - loss: 1.4588 - loc_loss: 0.4805 - conf_loss: 0.9783 - val_loss: 2.7820 - val_loc_loss: 0.8918 - val_conf_loss: 1.8901\n",
      "Epoch 5/200\n",
      "29/29 [==============================] - 6s 106ms/step\n",
      "mAP: 0.514183538891678\n",
      "716/716 [==============================] - 267s 372ms/step - loss: 1.4435 - loc_loss: 0.4752 - conf_loss: 0.9683 - val_loss: 2.7813 - val_loc_loss: 0.9088 - val_conf_loss: 1.8725\n",
      "Epoch 6/200\n",
      "29/29 [==============================] - 6s 108ms/step\n",
      "mAP: 0.5204276633406012\n",
      "716/716 [==============================] - 267s 372ms/step - loss: 1.4340 - loc_loss: 0.4730 - conf_loss: 0.9611 - val_loss: 2.7944 - val_loc_loss: 0.8945 - val_conf_loss: 1.8999\n",
      "Epoch 7/200\n",
      "29/29 [==============================] - 6s 108ms/step\n",
      "mAP: 0.5182908832037425\n",
      "716/716 [==============================] - 267s 373ms/step - loss: 1.4249 - loc_loss: 0.4687 - conf_loss: 0.9562 - val_loss: 2.7587 - val_loc_loss: 0.8821 - val_conf_loss: 1.8766\n",
      "Epoch 8/200\n",
      "29/29 [==============================] - 6s 107ms/step\n",
      "mAP: 0.485248577835921\n",
      "716/716 [==============================] - 268s 375ms/step - loss: 1.4195 - loc_loss: 0.4672 - conf_loss: 0.9523 - val_loss: 2.8264 - val_loc_loss: 0.8827 - val_conf_loss: 1.9438\n",
      "Epoch 9/200\n",
      "29/29 [==============================] - 7s 108ms/step\n",
      "mAP: 0.5012621452373061\n",
      "716/716 [==============================] - 268s 375ms/step - loss: 1.4083 - loc_loss: 0.4622 - conf_loss: 0.9461 - val_loss: 2.8025 - val_loc_loss: 0.8908 - val_conf_loss: 1.9117\n",
      "Epoch 10/200\n",
      "29/29 [==============================] - 6s 108ms/step\n",
      "mAP: 0.5101017088749402\n",
      "716/716 [==============================] - 267s 373ms/step - loss: 1.4083 - loc_loss: 0.4631 - conf_loss: 0.9452 - val_loss: 2.7599 - val_loc_loss: 0.8718 - val_conf_loss: 1.8881\n",
      "Epoch 11/200\n",
      "29/29 [==============================] - 6s 106ms/step\n",
      "mAP: 0.5214792042648492\n",
      "716/716 [==============================] - 267s 372ms/step - loss: 1.4020 - loc_loss: 0.4605 - conf_loss: 0.9415 - val_loss: 2.7685 - val_loc_loss: 0.8825 - val_conf_loss: 1.8861\n",
      "Epoch 12/200\n",
      "29/29 [==============================] - 6s 106ms/step\n",
      "mAP: 0.505054856212413\n",
      "716/716 [==============================] - 266s 372ms/step - loss: 1.3895 - loc_loss: 0.4577 - conf_loss: 0.9318 - val_loss: 2.7876 - val_loc_loss: 0.8830 - val_conf_loss: 1.9046\n",
      "Epoch 13/200\n",
      "29/29 [==============================] - 6s 106ms/step\n",
      "mAP: 0.5261457033333163\n",
      "716/716 [==============================] - 266s 371ms/step - loss: 1.3891 - loc_loss: 0.4565 - conf_loss: 0.9326 - val_loss: 2.7620 - val_loc_loss: 0.8737 - val_conf_loss: 1.8883\n",
      "Epoch 14/200\n",
      "29/29 [==============================] - 6s 106ms/step\n",
      "mAP: 0.5044804108571324\n",
      "716/716 [==============================] - 266s 371ms/step - loss: 1.3794 - loc_loss: 0.4531 - conf_loss: 0.9264 - val_loss: 2.7720 - val_loc_loss: 0.8846 - val_conf_loss: 1.8875\n",
      "Epoch 15/200\n",
      "29/29 [==============================] - 6s 105ms/step\n",
      "mAP: 0.5332384022458907\n",
      "716/716 [==============================] - 267s 372ms/step - loss: 1.3734 - loc_loss: 0.4509 - conf_loss: 0.9225 - val_loss: 2.7637 - val_loc_loss: 0.8682 - val_conf_loss: 1.8955\n",
      "Epoch 16/200\n",
      "29/29 [==============================] - 6s 106ms/step\n",
      "mAP: 0.5048598770740773\n",
      "716/716 [==============================] - 267s 373ms/step - loss: 1.3738 - loc_loss: 0.4505 - conf_loss: 0.9232 - val_loss: 2.8129 - val_loc_loss: 0.8846 - val_conf_loss: 1.9283\n",
      "Epoch 17/200\n",
      "29/29 [==============================] - 6s 105ms/step\n",
      "mAP: 0.5039698671186126\n",
      "716/716 [==============================] - 266s 372ms/step - loss: 1.3659 - loc_loss: 0.4476 - conf_loss: 0.9183 - val_loss: 2.8173 - val_loc_loss: 0.8750 - val_conf_loss: 1.9423\n",
      "Epoch 18/200\n",
      "29/29 [==============================] - 6s 107ms/step\n",
      "mAP: 0.5248764684304204\n",
      "716/716 [==============================] - 266s 371ms/step - loss: 1.3537 - loc_loss: 0.4436 - conf_loss: 0.9101 - val_loss: 2.7759 - val_loc_loss: 0.8700 - val_conf_loss: 1.9059\n",
      "Epoch 19/200\n",
      "29/29 [==============================] - 6s 110ms/step\n",
      "mAP: 0.5004766427332095\n",
      "716/716 [==============================] - 268s 374ms/step - loss: 1.3463 - loc_loss: 0.4407 - conf_loss: 0.9056 - val_loss: 2.7829 - val_loc_loss: 0.8644 - val_conf_loss: 1.9185\n",
      "Epoch 20/200\n",
      "29/29 [==============================] - 7s 107ms/step\n",
      "mAP: 0.5411350028965656\n",
      "716/716 [==============================] - 270s 377ms/step - loss: 1.3412 - loc_loss: 0.4374 - conf_loss: 0.9039 - val_loss: 2.8147 - val_loc_loss: 0.8838 - val_conf_loss: 1.9309\n",
      "Epoch 21/200\n",
      "29/29 [==============================] - 6s 105ms/step\n",
      "mAP: 0.5231055449596039\n",
      "716/716 [==============================] - 266s 372ms/step - loss: 1.3363 - loc_loss: 0.4365 - conf_loss: 0.8998 - val_loss: 2.7913 - val_loc_loss: 0.8604 - val_conf_loss: 1.9310\n",
      "Epoch 22/200\n",
      "29/29 [==============================] - 6s 104ms/step\n",
      "mAP: 0.524817250243718\n",
      "716/716 [==============================] - 267s 373ms/step - loss: 1.3298 - loc_loss: 0.4332 - conf_loss: 0.8966 - val_loss: 2.8353 - val_loc_loss: 0.8802 - val_conf_loss: 1.9551\n",
      "Epoch 23/200\n",
      "29/29 [==============================] - 6s 105ms/step\n",
      "mAP: 0.5402677729546834\n",
      "716/716 [==============================] - 268s 374ms/step - loss: 1.3237 - loc_loss: 0.4314 - conf_loss: 0.8924 - val_loss: 2.7546 - val_loc_loss: 0.8607 - val_conf_loss: 1.8938\n",
      "Epoch 24/200\n",
      "29/29 [==============================] - 6s 102ms/step\n",
      "mAP: 0.5125143136375956\n",
      "716/716 [==============================] - 266s 371ms/step - loss: 1.3194 - loc_loss: 0.4311 - conf_loss: 0.8884 - val_loss: 2.8169 - val_loc_loss: 0.8816 - val_conf_loss: 1.9353\n",
      "Epoch 25/200\n",
      "29/29 [==============================] - 6s 103ms/step\n",
      "mAP: 0.5261997042686927\n",
      "716/716 [==============================] - 267s 373ms/step - loss: 1.3162 - loc_loss: 0.4289 - conf_loss: 0.8873 - val_loss: 2.8079 - val_loc_loss: 0.8684 - val_conf_loss: 1.9394\n",
      "Epoch 26/200\n",
      "29/29 [==============================] - 6s 102ms/step\n",
      "mAP: 0.5092007155817091\n",
      "716/716 [==============================] - 265s 371ms/step - loss: 1.3079 - loc_loss: 0.4259 - conf_loss: 0.8820 - val_loss: 2.8563 - val_loc_loss: 0.8792 - val_conf_loss: 1.9771\n",
      "Epoch 27/200\n",
      "29/29 [==============================] - 6s 102ms/step\n",
      "mAP: 0.5014848724641959\n",
      "716/716 [==============================] - 266s 371ms/step - loss: 1.2996 - loc_loss: 0.4235 - conf_loss: 0.8761 - val_loss: 2.8279 - val_loc_loss: 0.8758 - val_conf_loss: 1.9521\n",
      "Epoch 28/200\n",
      "29/29 [==============================] - 6s 104ms/step\n",
      "mAP: 0.5167304971585869\n",
      "716/716 [==============================] - 266s 372ms/step - loss: 1.2989 - loc_loss: 0.4222 - conf_loss: 0.8767 - val_loss: 2.7586 - val_loc_loss: 0.8583 - val_conf_loss: 1.9003\n",
      "Epoch 29/200\n",
      "29/29 [==============================] - 6s 104ms/step\n",
      "mAP: 0.5583902797504622\n",
      "716/716 [==============================] - 266s 372ms/step - loss: 1.2866 - loc_loss: 0.4182 - conf_loss: 0.8683 - val_loss: 2.7776 - val_loc_loss: 0.8643 - val_conf_loss: 1.9132\n",
      "Epoch 30/200\n",
      "29/29 [==============================] - 6s 106ms/step\n",
      "mAP: 0.5176939778448616\n",
      "716/716 [==============================] - 267s 373ms/step - loss: 1.2888 - loc_loss: 0.4192 - conf_loss: 0.8697 - val_loss: 2.8101 - val_loc_loss: 0.8656 - val_conf_loss: 1.9445\n",
      "Epoch 31/200\n",
      "29/29 [==============================] - 6s 106ms/step\n",
      "mAP: 0.510516544140286\n",
      "716/716 [==============================] - 266s 371ms/step - loss: 1.2792 - loc_loss: 0.4156 - conf_loss: 0.8636 - val_loss: 2.7761 - val_loc_loss: 0.8641 - val_conf_loss: 1.9121\n",
      "Epoch 32/200\n",
      "29/29 [==============================] - 6s 107ms/step\n",
      "mAP: 0.5263991910236844\n",
      "716/716 [==============================] - 266s 372ms/step - loss: 1.2673 - loc_loss: 0.4106 - conf_loss: 0.8568 - val_loss: 2.8253 - val_loc_loss: 0.8679 - val_conf_loss: 1.9574\n",
      "Epoch 33/200\n",
      "29/29 [==============================] - 6s 103ms/step\n",
      "mAP: 0.5221633709974121\n",
      "716/716 [==============================] - 265s 370ms/step - loss: 1.2675 - loc_loss: 0.4115 - conf_loss: 0.8560 - val_loss: 2.8096 - val_loc_loss: 0.8768 - val_conf_loss: 1.9328\n",
      "Epoch 34/200\n",
      "29/29 [==============================] - 6s 106ms/step\n",
      "mAP: 0.5160593088199541\n",
      "716/716 [==============================] - 267s 372ms/step - loss: 1.2609 - loc_loss: 0.4094 - conf_loss: 0.8515 - val_loss: 2.7815 - val_loc_loss: 0.8699 - val_conf_loss: 1.9117\n",
      "Epoch 35/200\n",
      "29/29 [==============================] - 8s 107ms/step\n",
      "mAP: 0.5507584777148775\n",
      "716/716 [==============================] - 268s 374ms/step - loss: 1.2513 - loc_loss: 0.4041 - conf_loss: 0.8472 - val_loss: 2.8111 - val_loc_loss: 0.8733 - val_conf_loss: 1.9378\n",
      "Epoch 36/200\n",
      "29/29 [==============================] - 6s 105ms/step\n",
      "mAP: 0.5223729682715234\n",
      "716/716 [==============================] - 267s 373ms/step - loss: 1.2497 - loc_loss: 0.4034 - conf_loss: 0.8463 - val_loss: 2.8155 - val_loc_loss: 0.8619 - val_conf_loss: 1.9536\n",
      "Epoch 37/200\n",
      "29/29 [==============================] - 6s 107ms/step\n",
      "mAP: 0.5436165736326638\n",
      "716/716 [==============================] - 267s 373ms/step - loss: 1.2468 - loc_loss: 0.4029 - conf_loss: 0.8439 - val_loss: 2.7626 - val_loc_loss: 0.8484 - val_conf_loss: 1.9142\n",
      "Epoch 38/200\n",
      "29/29 [==============================] - 6s 107ms/step\n",
      "mAP: 0.5178895809542514\n",
      "716/716 [==============================] - 268s 374ms/step - loss: 1.2321 - loc_loss: 0.3986 - conf_loss: 0.8336 - val_loss: 2.8244 - val_loc_loss: 0.8662 - val_conf_loss: 1.9582\n",
      "Epoch 39/200\n",
      "29/29 [==============================] - 6s 107ms/step\n",
      "mAP: 0.5276355812025844\n",
      "716/716 [==============================] - 268s 374ms/step - loss: 1.2265 - loc_loss: 0.3965 - conf_loss: 0.8300 - val_loss: 2.7820 - val_loc_loss: 0.8476 - val_conf_loss: 1.9344\n",
      "Epoch 40/200\n",
      "29/29 [==============================] - 6s 106ms/step\n",
      "mAP: 0.5380897228410717\n",
      "716/716 [==============================] - 268s 375ms/step - loss: 1.2274 - loc_loss: 0.3982 - conf_loss: 0.8291 - val_loss: 2.8262 - val_loc_loss: 0.8738 - val_conf_loss: 1.9523\n",
      "Epoch 41/200\n",
      "29/29 [==============================] - 6s 107ms/step\n",
      "mAP: 0.5379841873384742\n",
      "716/716 [==============================] - 267s 373ms/step - loss: 1.2167 - loc_loss: 0.3928 - conf_loss: 0.8240 - val_loss: 2.7920 - val_loc_loss: 0.8609 - val_conf_loss: 1.9311\n",
      "Epoch 42/200\n",
      "29/29 [==============================] - 6s 105ms/step\n",
      "mAP: 0.5641873828768798\n",
      "716/716 [==============================] - 268s 374ms/step - loss: 1.2123 - loc_loss: 0.3924 - conf_loss: 0.8200 - val_loss: 2.8336 - val_loc_loss: 0.8673 - val_conf_loss: 1.9664\n",
      "Epoch 43/200\n",
      "29/29 [==============================] - 6s 107ms/step\n",
      "mAP: 0.5471174228292739\n",
      "716/716 [==============================] - 267s 374ms/step - loss: 1.2127 - loc_loss: 0.3923 - conf_loss: 0.8205 - val_loss: 2.7703 - val_loc_loss: 0.8540 - val_conf_loss: 1.9163\n",
      "Epoch 44/200\n",
      "29/29 [==============================] - 6s 106ms/step\n",
      "mAP: 0.5586856377110115\n",
      "716/716 [==============================] - 266s 372ms/step - loss: 1.2161 - loc_loss: 0.3922 - conf_loss: 0.8238 - val_loss: 2.7819 - val_loc_loss: 0.8533 - val_conf_loss: 1.9286\n",
      "Epoch 45/200\n",
      "29/29 [==============================] - 6s 104ms/step\n",
      "mAP: 0.5663165494892072\n",
      "716/716 [==============================] - 268s 374ms/step - loss: 1.2027 - loc_loss: 0.3882 - conf_loss: 0.8145 - val_loss: 2.8506 - val_loc_loss: 0.8723 - val_conf_loss: 1.9783\n",
      "Epoch 46/200\n",
      "29/29 [==============================] - 6s 104ms/step\n",
      "mAP: 0.5477152282422113\n",
      "716/716 [==============================] - 269s 376ms/step - loss: 1.1945 - loc_loss: 0.3845 - conf_loss: 0.8100 - val_loss: 2.8192 - val_loc_loss: 0.8513 - val_conf_loss: 1.9679\n",
      "Epoch 47/200\n",
      "29/29 [==============================] - 6s 104ms/step\n",
      "mAP: 0.550046496069187\n",
      "716/716 [==============================] - 267s 373ms/step - loss: 1.1939 - loc_loss: 0.3846 - conf_loss: 0.8093 - val_loss: 2.8226 - val_loc_loss: 0.8540 - val_conf_loss: 1.9687\n",
      "Epoch 48/200\n",
      "29/29 [==============================] - 6s 104ms/step\n",
      "mAP: 0.5342819313628181\n",
      "716/716 [==============================] - 267s 374ms/step - loss: 1.1808 - loc_loss: 0.3792 - conf_loss: 0.8016 - val_loss: 2.8046 - val_loc_loss: 0.8507 - val_conf_loss: 1.9539\n",
      "Epoch 49/200\n",
      "29/29 [==============================] - 6s 111ms/step\n",
      "mAP: 0.5465901970003179\n",
      "716/716 [==============================] - 267s 373ms/step - loss: 1.1774 - loc_loss: 0.3800 - conf_loss: 0.7974 - val_loss: 2.8417 - val_loc_loss: 0.8674 - val_conf_loss: 1.9743\n",
      "Epoch 50/200\n",
      "29/29 [==============================] - 6s 102ms/step\n",
      "mAP: 0.5479592061108233\n",
      "716/716 [==============================] - 266s 372ms/step - loss: 1.1833 - loc_loss: 0.3808 - conf_loss: 0.8026 - val_loss: 2.8049 - val_loc_loss: 0.8659 - val_conf_loss: 1.9390\n",
      "Epoch 51/200\n",
      "29/29 [==============================] - 6s 104ms/step\n",
      "mAP: 0.5299155022589145\n",
      "716/716 [==============================] - 268s 374ms/step - loss: 1.1738 - loc_loss: 0.3780 - conf_loss: 0.7958 - val_loss: 2.8037 - val_loc_loss: 0.8591 - val_conf_loss: 1.9446\n",
      "Epoch 52/200\n",
      "29/29 [==============================] - 8s 109ms/step\n",
      "mAP: 0.5316165234547587\n",
      "716/716 [==============================] - 269s 375ms/step - loss: 1.1669 - loc_loss: 0.3756 - conf_loss: 0.7912 - val_loss: 2.8350 - val_loc_loss: 0.8600 - val_conf_loss: 1.9750\n",
      "Epoch 53/200\n",
      "29/29 [==============================] - 6s 102ms/step\n",
      "mAP: 0.5696771172055874\n",
      "716/716 [==============================] - 271s 378ms/step - loss: 1.1635 - loc_loss: 0.3736 - conf_loss: 0.7900 - val_loss: 2.8231 - val_loc_loss: 0.8537 - val_conf_loss: 1.9694\n",
      "Epoch 54/200\n",
      "29/29 [==============================] - 6s 104ms/step\n",
      "mAP: 0.5264921034141088\n",
      "716/716 [==============================] - 267s 373ms/step - loss: 1.1622 - loc_loss: 0.3718 - conf_loss: 0.7904 - val_loss: 2.8175 - val_loc_loss: 0.8548 - val_conf_loss: 1.9627\n",
      "Epoch 55/200\n",
      "29/29 [==============================] - 6s 109ms/step\n",
      "mAP: 0.5523482937987586\n",
      "716/716 [==============================] - 268s 374ms/step - loss: 1.1538 - loc_loss: 0.3706 - conf_loss: 0.7832 - val_loss: 2.8662 - val_loc_loss: 0.8581 - val_conf_loss: 2.0082\n",
      "Epoch 56/200\n",
      "29/29 [==============================] - 6s 104ms/step\n",
      "mAP: 0.5477500780819413\n",
      "716/716 [==============================] - 267s 374ms/step - loss: 1.1430 - loc_loss: 0.3660 - conf_loss: 0.7770 - val_loss: 2.8297 - val_loc_loss: 0.8509 - val_conf_loss: 1.9788\n",
      "Epoch 57/200\n",
      "29/29 [==============================] - 6s 105ms/step\n",
      "mAP: 0.5515568632578587\n",
      "716/716 [==============================] - 268s 374ms/step - loss: 1.1526 - loc_loss: 0.3709 - conf_loss: 0.7817 - val_loss: 2.7938 - val_loc_loss: 0.8511 - val_conf_loss: 1.9427\n",
      "Epoch 58/200\n",
      "29/29 [==============================] - 6s 107ms/step\n",
      "mAP: 0.5410227157123007\n",
      "716/716 [==============================] - 269s 376ms/step - loss: 1.1443 - loc_loss: 0.3684 - conf_loss: 0.7759 - val_loss: 2.7993 - val_loc_loss: 0.8390 - val_conf_loss: 1.9603\n",
      "Epoch 59/200\n",
      "29/29 [==============================] - 6s 104ms/step\n",
      "mAP: 0.565684115289496\n",
      "716/716 [==============================] - 266s 372ms/step - loss: 1.1402 - loc_loss: 0.3653 - conf_loss: 0.7749 - val_loss: 2.8085 - val_loc_loss: 0.8476 - val_conf_loss: 1.9608\n",
      "Epoch 60/200\n",
      "29/29 [==============================] - 6s 109ms/step\n",
      "mAP: 0.576869985727324\n",
      "716/716 [==============================] - 267s 373ms/step - loss: 1.1293 - loc_loss: 0.3608 - conf_loss: 0.7685 - val_loss: 2.8772 - val_loc_loss: 0.8568 - val_conf_loss: 2.0204\n",
      "Epoch 61/200\n",
      "29/29 [==============================] - 6s 108ms/step\n",
      "mAP: 0.5702683516923942\n",
      "716/716 [==============================] - 268s 375ms/step - loss: 1.1344 - loc_loss: 0.3643 - conf_loss: 0.7701 - val_loss: 2.8129 - val_loc_loss: 0.8564 - val_conf_loss: 1.9565\n",
      "Epoch 62/200\n",
      "29/29 [==============================] - 6s 112ms/step\n",
      "mAP: 0.5412246294718333\n",
      "716/716 [==============================] - 268s 374ms/step - loss: 1.1258 - loc_loss: 0.3598 - conf_loss: 0.7660 - val_loss: 2.8244 - val_loc_loss: 0.8559 - val_conf_loss: 1.9685\n",
      "Epoch 63/200\n",
      "29/29 [==============================] - 6s 107ms/step\n",
      "mAP: 0.5625660566708998\n",
      "716/716 [==============================] - 267s 373ms/step - loss: 1.1201 - loc_loss: 0.3570 - conf_loss: 0.7632 - val_loss: 2.8426 - val_loc_loss: 0.8674 - val_conf_loss: 1.9752\n",
      "Epoch 64/200\n",
      "29/29 [==============================] - 6s 111ms/step\n",
      "mAP: 0.5659443312956873\n",
      "716/716 [==============================] - 268s 375ms/step - loss: 1.1157 - loc_loss: 0.3576 - conf_loss: 0.7581 - val_loss: 2.8520 - val_loc_loss: 0.8560 - val_conf_loss: 1.9960\n",
      "Epoch 65/200\n",
      "29/29 [==============================] - 6s 106ms/step\n",
      "mAP: 0.5875390459351533\n",
      "716/716 [==============================] - 269s 376ms/step - loss: 1.1128 - loc_loss: 0.3561 - conf_loss: 0.7567 - val_loss: 2.8708 - val_loc_loss: 0.8555 - val_conf_loss: 2.0153\n",
      "Epoch 66/200\n",
      "29/29 [==============================] - 6s 111ms/step\n",
      "mAP: 0.5787163473061502\n",
      "716/716 [==============================] - 268s 374ms/step - loss: 1.1021 - loc_loss: 0.3520 - conf_loss: 0.7501 - val_loss: 2.8867 - val_loc_loss: 0.8555 - val_conf_loss: 2.0312\n",
      "Epoch 67/200\n",
      "29/29 [==============================] - 6s 105ms/step\n",
      "mAP: 0.5892823923355339\n",
      "716/716 [==============================] - 268s 374ms/step - loss: 1.1009 - loc_loss: 0.3517 - conf_loss: 0.7492 - val_loss: 2.8463 - val_loc_loss: 0.8578 - val_conf_loss: 1.9885\n",
      "Epoch 68/200\n",
      "29/29 [==============================] - 6s 109ms/step\n",
      "mAP: 0.5494711325858227\n",
      "716/716 [==============================] - 268s 375ms/step - loss: 1.1010 - loc_loss: 0.3512 - conf_loss: 0.7498 - val_loss: 2.8783 - val_loc_loss: 0.8574 - val_conf_loss: 2.0209\n",
      "Epoch 69/200\n",
      "29/29 [==============================] - 6s 107ms/step\n",
      "mAP: 0.5572280175283019\n",
      "716/716 [==============================] - 269s 375ms/step - loss: 1.0996 - loc_loss: 0.3510 - conf_loss: 0.7486 - val_loss: 2.8273 - val_loc_loss: 0.8450 - val_conf_loss: 1.9823\n",
      "Epoch 70/200\n",
      "29/29 [==============================] - 6s 109ms/step\n",
      "mAP: 0.5470111470463586\n",
      "716/716 [==============================] - 268s 375ms/step - loss: 1.0907 - loc_loss: 0.3487 - conf_loss: 0.7420 - val_loss: 2.8282 - val_loc_loss: 0.8502 - val_conf_loss: 1.9780\n",
      "Epoch 71/200\n",
      "29/29 [==============================] - 6s 103ms/step\n",
      "mAP: 0.5665033565732132\n",
      "716/716 [==============================] - 268s 374ms/step - loss: 1.0861 - loc_loss: 0.3458 - conf_loss: 0.7403 - val_loss: 2.8020 - val_loc_loss: 0.8320 - val_conf_loss: 1.9700\n",
      "Epoch 72/200\n",
      "29/29 [==============================] - 6s 110ms/step\n",
      "mAP: 0.5651668898518458\n",
      "716/716 [==============================] - 321s 449ms/step - loss: 1.0861 - loc_loss: 0.3464 - conf_loss: 0.7397 - val_loss: 2.8517 - val_loc_loss: 0.8475 - val_conf_loss: 2.0042\n",
      "Epoch 73/200\n",
      "29/29 [==============================] - 9s 104ms/step\n",
      "mAP: 0.5889953277455828\n",
      "716/716 [==============================] - 270s 377ms/step - loss: 1.0738 - loc_loss: 0.3413 - conf_loss: 0.7325 - val_loss: 2.9258 - val_loc_loss: 0.8463 - val_conf_loss: 2.0795\n",
      "Epoch 74/200\n",
      "29/29 [==============================] - 7s 108ms/step\n",
      "mAP: 0.5496053649178586\n",
      "716/716 [==============================] - 268s 374ms/step - loss: 1.0739 - loc_loss: 0.3411 - conf_loss: 0.7329 - val_loss: 2.9110 - val_loc_loss: 0.8411 - val_conf_loss: 2.0699\n",
      "Epoch 75/200\n",
      "29/29 [==============================] - 6s 105ms/step\n",
      "mAP: 0.577495295104476\n",
      "716/716 [==============================] - 269s 375ms/step - loss: 1.0719 - loc_loss: 0.3393 - conf_loss: 0.7326 - val_loss: 2.8581 - val_loc_loss: 0.8325 - val_conf_loss: 2.0256\n",
      "Epoch 76/200\n",
      "29/29 [==============================] - 6s 108ms/step\n",
      "mAP: 0.5623980978300975\n",
      "716/716 [==============================] - 269s 375ms/step - loss: 1.0646 - loc_loss: 0.3397 - conf_loss: 0.7248 - val_loss: 2.8883 - val_loc_loss: 0.8376 - val_conf_loss: 2.0507\n",
      "Epoch 77/200\n",
      "29/29 [==============================] - 6s 107ms/step\n",
      "mAP: 0.5763933739216635\n",
      "716/716 [==============================] - 267s 373ms/step - loss: 1.0644 - loc_loss: 0.3381 - conf_loss: 0.7263 - val_loss: 2.8068 - val_loc_loss: 0.8209 - val_conf_loss: 1.9859\n",
      "Epoch 78/200\n",
      "29/29 [==============================] - 6s 106ms/step\n",
      "mAP: 0.5749210024201052\n",
      "716/716 [==============================] - 267s 372ms/step - loss: 1.0511 - loc_loss: 0.3337 - conf_loss: 0.7173 - val_loss: 2.8228 - val_loc_loss: 0.8262 - val_conf_loss: 1.9966\n",
      "Epoch 79/200\n",
      "29/29 [==============================] - 6s 104ms/step\n",
      "mAP: 0.5597350792481048\n",
      "716/716 [==============================] - 270s 376ms/step - loss: 1.0586 - loc_loss: 0.3370 - conf_loss: 0.7216 - val_loss: 2.8494 - val_loc_loss: 0.8251 - val_conf_loss: 2.0243\n",
      "Epoch 80/200\n",
      "29/29 [==============================] - 6s 105ms/step\n",
      "mAP: 0.5773209435414206\n",
      "716/716 [==============================] - 268s 374ms/step - loss: 1.0474 - loc_loss: 0.3332 - conf_loss: 0.7142 - val_loss: 2.8448 - val_loc_loss: 0.8305 - val_conf_loss: 2.0143\n",
      "Epoch 81/200\n",
      "29/29 [==============================] - 6s 104ms/step\n",
      "mAP: 0.5834954855477433\n",
      "716/716 [==============================] - 268s 374ms/step - loss: 1.0485 - loc_loss: 0.3324 - conf_loss: 0.7162 - val_loss: 2.8326 - val_loc_loss: 0.8334 - val_conf_loss: 1.9992\n",
      "Epoch 82/200\n",
      "29/29 [==============================] - 6s 104ms/step\n",
      "mAP: 0.5596062790920864\n",
      "716/716 [==============================] - 267s 373ms/step - loss: 1.0454 - loc_loss: 0.3307 - conf_loss: 0.7147 - val_loss: 2.8782 - val_loc_loss: 0.8425 - val_conf_loss: 2.0356\n",
      "Epoch 83/200\n",
      "29/29 [==============================] - 6s 104ms/step\n",
      "mAP: 0.582562369922432\n",
      "716/716 [==============================] - 269s 375ms/step - loss: 1.0370 - loc_loss: 0.3290 - conf_loss: 0.7080 - val_loss: 2.8398 - val_loc_loss: 0.8300 - val_conf_loss: 2.0099\n",
      "Epoch 84/200\n",
      "29/29 [==============================] - 6s 107ms/step\n",
      "mAP: 0.564510907105514\n",
      "716/716 [==============================] - 269s 376ms/step - loss: 1.0335 - loc_loss: 0.3279 - conf_loss: 0.7056 - val_loss: 2.8857 - val_loc_loss: 0.8267 - val_conf_loss: 2.0589\n",
      "Epoch 85/200\n",
      "29/29 [==============================] - 6s 102ms/step\n",
      "mAP: 0.5810786811752162\n",
      "716/716 [==============================] - 267s 372ms/step - loss: 1.0359 - loc_loss: 0.3281 - conf_loss: 0.7078 - val_loss: 2.9118 - val_loc_loss: 0.8421 - val_conf_loss: 2.0697\n",
      "Epoch 86/200\n",
      "29/29 [==============================] - 6s 103ms/step\n",
      "mAP: 0.5785643413344423\n",
      "716/716 [==============================] - 267s 373ms/step - loss: 1.0236 - loc_loss: 0.3241 - conf_loss: 0.6996 - val_loss: 2.8689 - val_loc_loss: 0.8324 - val_conf_loss: 2.0365\n",
      "Epoch 87/200\n",
      "29/29 [==============================] - 6s 105ms/step\n",
      "mAP: 0.5721519963133216\n",
      "Early stopping at epoch 87 due to lack of improvement.\n",
      "716/716 [==============================] - 269s 376ms/step - loss: 1.0276 - loc_loss: 0.3250 - conf_loss: 0.7026 - val_loss: 2.9107 - val_loc_loss: 0.8359 - val_conf_loss: 2.0748\n",
      "\n",
      "Best Mean Average Precision: 0.5892823923355339\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "ssd_custom_losses = CustomLoss(hyper_params[\"neg_pos_ratio\"], hyper_params[\"loc_loss_alpha\"], \n",
    "                               hyper_params[\"alpha\"], hyper_params[\"gamma\"], hyper_params[\"use_focal\"])\n",
    "\n",
    "if hyper_params[\"detection\"] is None:\n",
    "    ssd_model = get_model(hyper_params)\n",
    "elif hyper_params[\"detection\"] == \"FPN\":\n",
    "    ssd_model = get_fpnmodel(hyper_params)\n",
    "elif hyper_params[\"detection\"] == \"PAFPN\":\n",
    "    ssd_model = get_pafpnmodel(hyper_params)\n",
    "elif hyper_params[\"detection\"] == \"BiFPN\":\n",
    "    ssd_model = get_bifpnmodel(hyper_params)\n",
    "elif hyper_params[\"detection\"] == \"NASFPN\":\n",
    "    ssd_model = get_nasfpnmodel(hyper_params)\n",
    "    \n",
    "ssd_model.compile(optimizer=Adam(learning_rate=hyper_params[\"lr\"]),\n",
    "                  loss=[ssd_custom_losses.loc_loss_fn, ssd_custom_losses.conf_loss_fn])\n",
    "init_model(ssd_model, img_size)\n",
    "\n",
    "ssd_model_path = get_model_path(backbone)\n",
    "load_weights = True\n",
    "if load_weights:\n",
    "    ssd_model.load_weights(\"/kaggle/input/bifpn-ckpt/bifpn_ssd_mobilenet_v2_model_weights.h5\")\n",
    "ssd_log_path = get_log_path(backbone)\n",
    "\n",
    "# Moved under mAP_callback\n",
    "# checkpoint_callback = ModelCheckpoint(ssd_model_path, monitor=\"val_loss\", save_best_only=True, save_weights_only=True)\n",
    "# learning_rate_callback = LearningRateScheduler(scheduler, verbose=0)\n",
    "tensorboard_callback = TensorBoard(log_dir=ssd_log_path)\n",
    "step_size_train = get_step_size(train_total_items, batch_size)\n",
    "step_size_val = get_step_size(val_total_items, batch_size)\n",
    "print(step_size_train, step_size_val)\n",
    "# mAP_callback both early stopping and checkpoint\n",
    "mAP_callback = MeanAveragePrecisionCallback(val_data, step_size_val, labels, prior_boxes, hyper_params,\n",
    "                                            batch_size, hyper_params[\"patience\"], ssd_model_path)\n",
    "\n",
    "history = ssd_model.fit(ssd_train_feed,\n",
    "              steps_per_epoch=step_size_train,\n",
    "              validation_data=ssd_val_feed,\n",
    "              validation_steps=step_size_val,\n",
    "              epochs=epochs,\n",
    "              callbacks=[tensorboard_callback, mAP_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc3e8de3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T08:35:55.596306Z",
     "iopub.status.busy": "2024-02-26T08:35:55.595922Z",
     "iopub.status.idle": "2024-02-26T08:35:56.115076Z",
     "shell.execute_reply": "2024-02-26T08:35:56.114049Z"
    },
    "id": "r8bG8i6PPpkg",
    "outputId": "361903d5-2174-43d9-ff61-8fdcb48b49af",
    "papermill": {
     "duration": 6.393085,
     "end_time": "2024-02-26T08:35:56.220580",
     "exception": false,
     "start_time": "2024-02-26T08:35:49.827495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 640, 640, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)              (None, 320, 320, 32)         864       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalizati  (None, 320, 320, 32)         128       ['Conv1[0][0]']               \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)           (None, 320, 320, 32)         0         ['bn_Conv1[0][0]']            \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (D  (None, 320, 320, 32)         288       ['Conv1_relu[0][0]']          \n",
      " epthwiseConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN  (None, 320, 320, 32)         128       ['expanded_conv_depthwise[0][0\n",
      "  (BatchNormalization)                                              ]']                           \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_re  (None, 320, 320, 32)         0         ['expanded_conv_depthwise_BN[0\n",
      " lu (ReLU)                                                          ][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv_project (Con  (None, 320, 320, 16)         512       ['expanded_conv_depthwise_relu\n",
      " v2D)                                                               [0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (  (None, 320, 320, 16)         64        ['expanded_conv_project[0][0]'\n",
      " BatchNormalization)                                                ]                             \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)     (None, 320, 320, 96)         1536      ['expanded_conv_project_BN[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNo  (None, 320, 320, 96)         384       ['block_1_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)  (None, 320, 320, 96)         0         ['block_1_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D  (None, 321, 321, 96)         0         ['block_1_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_1_depthwise (Depthwi  (None, 160, 160, 96)         864       ['block_1_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (Batc  (None, 160, 160, 96)         384       ['block_1_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (Re  (None, 160, 160, 96)         0         ['block_1_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)    (None, 160, 160, 24)         2304      ['block_1_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchN  (None, 160, 160, 24)         96        ['block_1_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)     (None, 160, 160, 144)        3456      ['block_1_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNo  (None, 160, 160, 144)        576       ['block_2_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)  (None, 160, 160, 144)        0         ['block_2_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_depthwise (Depthwi  (None, 160, 160, 144)        1296      ['block_2_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (Batc  (None, 160, 160, 144)        576       ['block_2_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (Re  (None, 160, 160, 144)        0         ['block_2_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)    (None, 160, 160, 24)         3456      ['block_2_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchN  (None, 160, 160, 24)         96        ['block_2_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_2_add (Add)           (None, 160, 160, 24)         0         ['block_1_project_BN[0][0]',  \n",
      "                                                                     'block_2_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)     (None, 160, 160, 144)        3456      ['block_2_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNo  (None, 160, 160, 144)        576       ['block_3_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)  (None, 160, 160, 144)        0         ['block_3_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D  (None, 161, 161, 144)        0         ['block_3_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_3_depthwise (Depthwi  (None, 80, 80, 144)          1296      ['block_3_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (Batc  (None, 80, 80, 144)          576       ['block_3_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (Re  (None, 80, 80, 144)          0         ['block_3_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)    (None, 80, 80, 32)           4608      ['block_3_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchN  (None, 80, 80, 32)           128       ['block_3_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)     (None, 80, 80, 192)          6144      ['block_3_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNo  (None, 80, 80, 192)          768       ['block_4_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)  (None, 80, 80, 192)          0         ['block_4_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_depthwise (Depthwi  (None, 80, 80, 192)          1728      ['block_4_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (Batc  (None, 80, 80, 192)          768       ['block_4_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (Re  (None, 80, 80, 192)          0         ['block_4_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)    (None, 80, 80, 32)           6144      ['block_4_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchN  (None, 80, 80, 32)           128       ['block_4_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_4_add (Add)           (None, 80, 80, 32)           0         ['block_3_project_BN[0][0]',  \n",
      "                                                                     'block_4_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)     (None, 80, 80, 192)          6144      ['block_4_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNo  (None, 80, 80, 192)          768       ['block_5_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)  (None, 80, 80, 192)          0         ['block_5_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_depthwise (Depthwi  (None, 80, 80, 192)          1728      ['block_5_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (Batc  (None, 80, 80, 192)          768       ['block_5_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (Re  (None, 80, 80, 192)          0         ['block_5_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)    (None, 80, 80, 32)           6144      ['block_5_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchN  (None, 80, 80, 32)           128       ['block_5_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_5_add (Add)           (None, 80, 80, 32)           0         ['block_4_add[0][0]',         \n",
      "                                                                     'block_5_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)     (None, 80, 80, 192)          6144      ['block_5_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNo  (None, 80, 80, 192)          768       ['block_6_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)  (None, 80, 80, 192)          0         ['block_6_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D  (None, 81, 81, 192)          0         ['block_6_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_6_depthwise (Depthwi  (None, 40, 40, 192)          1728      ['block_6_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (Batc  (None, 40, 40, 192)          768       ['block_6_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (Re  (None, 40, 40, 192)          0         ['block_6_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)    (None, 40, 40, 64)           12288     ['block_6_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchN  (None, 40, 40, 64)           256       ['block_6_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)     (None, 40, 40, 384)          24576     ['block_6_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNo  (None, 40, 40, 384)          1536      ['block_7_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)  (None, 40, 40, 384)          0         ['block_7_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_depthwise (Depthwi  (None, 40, 40, 384)          3456      ['block_7_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (Batc  (None, 40, 40, 384)          1536      ['block_7_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (Re  (None, 40, 40, 384)          0         ['block_7_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)    (None, 40, 40, 64)           24576     ['block_7_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchN  (None, 40, 40, 64)           256       ['block_7_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_7_add (Add)           (None, 40, 40, 64)           0         ['block_6_project_BN[0][0]',  \n",
      "                                                                     'block_7_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)     (None, 40, 40, 384)          24576     ['block_7_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNo  (None, 40, 40, 384)          1536      ['block_8_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)  (None, 40, 40, 384)          0         ['block_8_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_depthwise (Depthwi  (None, 40, 40, 384)          3456      ['block_8_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (Batc  (None, 40, 40, 384)          1536      ['block_8_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (Re  (None, 40, 40, 384)          0         ['block_8_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)    (None, 40, 40, 64)           24576     ['block_8_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchN  (None, 40, 40, 64)           256       ['block_8_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_8_add (Add)           (None, 40, 40, 64)           0         ['block_7_add[0][0]',         \n",
      "                                                                     'block_8_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)     (None, 40, 40, 384)          24576     ['block_8_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNo  (None, 40, 40, 384)          1536      ['block_9_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)  (None, 40, 40, 384)          0         ['block_9_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_depthwise (Depthwi  (None, 40, 40, 384)          3456      ['block_9_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (Batc  (None, 40, 40, 384)          1536      ['block_9_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (Re  (None, 40, 40, 384)          0         ['block_9_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)    (None, 40, 40, 64)           24576     ['block_9_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchN  (None, 40, 40, 64)           256       ['block_9_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_9_add (Add)           (None, 40, 40, 64)           0         ['block_8_add[0][0]',         \n",
      "                                                                     'block_9_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)    (None, 40, 40, 384)          24576     ['block_9_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchN  (None, 40, 40, 384)          1536      ['block_10_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU  (None, 40, 40, 384)          0         ['block_10_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_10_depthwise (Depthw  (None, 40, 40, 384)          3456      ['block_10_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (Bat  (None, 40, 40, 384)          1536      ['block_10_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (R  (None, 40, 40, 384)          0         ['block_10_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)   (None, 40, 40, 96)           36864     ['block_10_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_10_project_BN (Batch  (None, 40, 40, 96)           384       ['block_10_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)    (None, 40, 40, 576)          55296     ['block_10_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchN  (None, 40, 40, 576)          2304      ['block_11_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU  (None, 40, 40, 576)          0         ['block_11_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_11_depthwise (Depthw  (None, 40, 40, 576)          5184      ['block_11_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (Bat  (None, 40, 40, 576)          2304      ['block_11_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (R  (None, 40, 40, 576)          0         ['block_11_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)   (None, 40, 40, 96)           55296     ['block_11_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_11_project_BN (Batch  (None, 40, 40, 96)           384       ['block_11_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_11_add (Add)          (None, 40, 40, 96)           0         ['block_10_project_BN[0][0]', \n",
      "                                                                     'block_11_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)    (None, 40, 40, 576)          55296     ['block_11_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchN  (None, 40, 40, 576)          2304      ['block_12_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU  (None, 40, 40, 576)          0         ['block_12_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_12_depthwise (Depthw  (None, 40, 40, 576)          5184      ['block_12_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (Bat  (None, 40, 40, 576)          2304      ['block_12_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (R  (None, 40, 40, 576)          0         ['block_12_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)   (None, 40, 40, 96)           55296     ['block_12_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_12_project_BN (Batch  (None, 40, 40, 96)           384       ['block_12_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_12_add (Add)          (None, 40, 40, 96)           0         ['block_11_add[0][0]',        \n",
      "                                                                     'block_12_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)    (None, 40, 40, 576)          55296     ['block_12_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchN  (None, 40, 40, 576)          2304      ['block_13_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU  (None, 40, 40, 576)          0         ['block_13_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2  (None, 41, 41, 576)          0         ['block_13_expand_relu[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block_13_depthwise (Depthw  (None, 20, 20, 576)          5184      ['block_13_pad[0][0]']        \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (Bat  (None, 20, 20, 576)          2304      ['block_13_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (R  (None, 20, 20, 576)          0         ['block_13_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)   (None, 20, 20, 160)          92160     ['block_13_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_13_project_BN (Batch  (None, 20, 20, 160)          640       ['block_13_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)    (None, 20, 20, 960)          153600    ['block_13_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchN  (None, 20, 20, 960)          3840      ['block_14_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU  (None, 20, 20, 960)          0         ['block_14_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_14_depthwise (Depthw  (None, 20, 20, 960)          8640      ['block_14_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (Bat  (None, 20, 20, 960)          3840      ['block_14_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (R  (None, 20, 20, 960)          0         ['block_14_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)   (None, 20, 20, 160)          153600    ['block_14_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_14_project_BN (Batch  (None, 20, 20, 160)          640       ['block_14_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_14_add (Add)          (None, 20, 20, 160)          0         ['block_13_project_BN[0][0]', \n",
      "                                                                     'block_14_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)    (None, 20, 20, 960)          153600    ['block_14_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchN  (None, 20, 20, 960)          3840      ['block_15_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU  (None, 20, 20, 960)          0         ['block_15_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_15_depthwise (Depthw  (None, 20, 20, 960)          8640      ['block_15_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (Bat  (None, 20, 20, 960)          3840      ['block_15_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (R  (None, 20, 20, 960)          0         ['block_15_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)   (None, 20, 20, 160)          153600    ['block_15_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_15_project_BN (Batch  (None, 20, 20, 160)          640       ['block_15_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_15_add (Add)          (None, 20, 20, 160)          0         ['block_14_add[0][0]',        \n",
      "                                                                     'block_15_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)    (None, 20, 20, 960)          153600    ['block_15_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchN  (None, 20, 20, 960)          3840      ['block_16_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU  (None, 20, 20, 960)          0         ['block_16_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_16_depthwise (Depthw  (None, 20, 20, 960)          8640      ['block_16_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (Bat  (None, 20, 20, 960)          3840      ['block_16_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (R  (None, 20, 20, 960)          0         ['block_16_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)   (None, 20, 20, 320)          307200    ['block_16_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_16_project_BN (Batch  (None, 20, 20, 320)          1280      ['block_16_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)             (None, 20, 20, 1280)         409600    ['block_16_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalizat  (None, 20, 20, 1280)         5120      ['Conv_1[0][0]']              \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " out_relu (ReLU)             (None, 20, 20, 1280)         0         ['Conv_1_bn[0][0]']           \n",
      "                                                                                                  \n",
      " extra1_1 (Conv2D)           (None, 20, 20, 256)          327936    ['out_relu[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 20, 20, 256)          1024      ['extra1_1[0][0]']            \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                (None, 20, 20, 256)          0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " extra1_2 (Conv2D)           (None, 10, 10, 512)          1180160   ['re_lu[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 10, 10, 512)          2048      ['extra1_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)              (None, 10, 10, 512)          0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " extra2_1 (Conv2D)           (None, 10, 10, 128)          65664     ['re_lu_1[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 10, 10, 128)          512       ['extra2_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)              (None, 10, 10, 128)          0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " extra2_2 (Conv2D)           (None, 5, 5, 256)            295168    ['re_lu_2[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 5, 5, 256)            1024      ['extra2_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)              (None, 5, 5, 256)            0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " extra3_1 (Conv2D)           (None, 5, 5, 128)            32896     ['re_lu_3[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 5, 5, 128)            512       ['extra3_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)              (None, 5, 5, 128)            0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " extra3_2 (Conv2D)           (None, 3, 3, 256)            295168    ['re_lu_4[0][0]']             \n",
      "                                                                                                  \n",
      " average_pooling2d (Average  (None, 10, 10, 1280)         0         ['out_relu[0][0]']            \n",
      " Pooling2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 3, 3, 256)            1024      ['extra3_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " BiFPN (BiFPN)               [(None, 160, 160, 64),       347264    ['block_3_expand_relu[0][0]', \n",
      "                              (None, 80, 80, 64),                    'block_6_expand_relu[0][0]', \n",
      "                              (None, 40, 40, 64),                    'block_13_expand_relu[0][0]',\n",
      "                              (None, 20, 20, 64),                    'out_relu[0][0]',            \n",
      "                              (None, 10, 10, 64)]                    'average_pooling2d[0][0]']   \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)              (None, 3, 3, 256)            0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " 1_conv_label_output (Conv2  (None, 160, 160, 30)         17310     ['BiFPN[0][0]']               \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " 2_conv_label_output (Conv2  (None, 80, 80, 30)           17310     ['BiFPN[0][1]']               \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " 3_conv_label_output (Conv2  (None, 40, 40, 30)           17310     ['BiFPN[0][2]']               \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " 4_conv_label_output (Conv2  (None, 20, 20, 30)           17310     ['BiFPN[0][3]']               \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " 5_conv_label_output (Conv2  (None, 10, 10, 30)           138270    ['re_lu_1[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " 6_conv_label_output (Conv2  (None, 5, 5, 30)             69150     ['re_lu_3[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " 7_conv_label_output (Conv2  (None, 3, 3, 30)             69150     ['re_lu_5[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " 1_conv_boxes_output (Conv2  (None, 160, 160, 24)         13848     ['BiFPN[0][0]']               \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " 2_conv_boxes_output (Conv2  (None, 80, 80, 24)           13848     ['BiFPN[0][1]']               \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " 3_conv_boxes_output (Conv2  (None, 40, 40, 24)           13848     ['BiFPN[0][2]']               \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " 4_conv_boxes_output (Conv2  (None, 20, 20, 24)           13848     ['BiFPN[0][3]']               \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " 5_conv_boxes_output (Conv2  (None, 10, 10, 24)           110616    ['re_lu_1[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " 6_conv_boxes_output (Conv2  (None, 5, 5, 24)             55320     ['re_lu_3[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " 7_conv_boxes_output (Conv2  (None, 3, 3, 24)             55320     ['re_lu_5[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " labels_head (HeadWrapper)   (None, None, 5)              0         ['1_conv_label_output[0][0]', \n",
      "                                                                     '2_conv_label_output[0][0]', \n",
      "                                                                     '3_conv_label_output[0][0]', \n",
      "                                                                     '4_conv_label_output[0][0]', \n",
      "                                                                     '5_conv_label_output[0][0]', \n",
      "                                                                     '6_conv_label_output[0][0]', \n",
      "                                                                     '7_conv_label_output[0][0]'] \n",
      "                                                                                                  \n",
      " loc (HeadWrapper)           (None, None, 4)              0         ['1_conv_boxes_output[0][0]', \n",
      "                                                                     '2_conv_boxes_output[0][0]', \n",
      "                                                                     '3_conv_boxes_output[0][0]', \n",
      "                                                                     '4_conv_boxes_output[0][0]', \n",
      "                                                                     '5_conv_boxes_output[0][0]', \n",
      "                                                                     '6_conv_boxes_output[0][0]', \n",
      "                                                                     '7_conv_boxes_output[0][0]'] \n",
      "                                                                                                  \n",
      " conf (Activation)           (None, None, 5)              0         ['labels_head[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5430842 (20.72 MB)\n",
      "Trainable params: 5389946 (20.56 MB)\n",
      "Non-trainable params: 40896 (159.75 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ssd_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d1b8c6",
   "metadata": {
    "id": "nVPhU6-xkSF5",
    "papermill": {
     "duration": 5.575671,
     "end_time": "2024-02-26T08:36:07.422296",
     "exception": false,
     "start_time": "2024-02-26T08:36:01.846625",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f4cd9ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T08:36:18.638412Z",
     "iopub.status.busy": "2024-02-26T08:36:18.637804Z",
     "iopub.status.idle": "2024-02-26T08:36:19.453615Z",
     "shell.execute_reply": "2024-02-26T08:36:19.452563Z"
    },
    "id": "i4HPimys1Wfv",
    "outputId": "8a3f1181-dab6-4ba3-cc33-8ba831fcbcd5",
    "papermill": {
     "duration": 6.395793,
     "end_time": "2024-02-26T08:36:19.455915",
     "exception": false,
     "start_time": "2024-02-26T08:36:13.060122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ad425f42fb0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(history.history['loc_loss'])\n",
    "plt.plot(history.history['val_loc_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loc loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "\n",
    "plt.figure(3)\n",
    "plt.plot(history.history['conf_loss'])\n",
    "plt.plot(history.history['val_conf_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('conf loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9004340d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T08:36:30.579364Z",
     "iopub.status.busy": "2024-02-26T08:36:30.578442Z",
     "iopub.status.idle": "2024-02-26T08:36:30.794555Z",
     "shell.execute_reply": "2024-02-26T08:36:30.793622Z"
    },
    "id": "-YoXADJikWs6",
    "outputId": "1e1b16d9-d778-4723-c4f5-0019c3ca2b05",
    "papermill": {
     "duration": 5.759195,
     "end_time": "2024-02-26T08:36:30.796490",
     "exception": false,
     "start_time": "2024-02-26T08:36:25.037295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epoch')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mAP_values = mAP_callback.get_mAP_values()\n",
    "plt.plot(mAP_values)\n",
    "plt.title('mAP')\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b150e466",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T08:36:42.174746Z",
     "iopub.status.busy": "2024-02-26T08:36:42.173870Z",
     "iopub.status.idle": "2024-02-26T08:36:42.180653Z",
     "shell.execute_reply": "2024-02-26T08:36:42.179692Z"
    },
    "id": "KDTcajkTw4DG",
    "outputId": "030daf33-17d5-476d-be7c-b700530746b0",
    "papermill": {
     "duration": 5.818066,
     "end_time": "2024-02-26T08:36:42.183055",
     "exception": false,
     "start_time": "2024-02-26T08:36:36.364989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/logs/mobilenet_v2/20240226-020535\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "logs = os.listdir(f\"/kaggle/working/logs/{backbone}/\")\n",
    "logs.sort()\n",
    "log_path = f\"/kaggle/working/logs/{backbone}/{logs[-1]}\"\n",
    "print(log_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "10b78c82",
   "metadata": {
    "id": "hk0iUI8PreZR",
    "papermill": {
     "duration": 5.645816,
     "end_time": "2024-02-26T08:36:53.406259",
     "exception": false,
     "start_time": "2024-02-26T08:36:47.760443",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir \"/content/logs/mobilenet_v2/20240129-090642\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9ab4b0",
   "metadata": {
    "id": "yNKy8TbeM4AA",
    "papermill": {
     "duration": 5.558319,
     "end_time": "2024-02-26T08:37:04.562631",
     "exception": false,
     "start_time": "2024-02-26T08:36:59.004312",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# predictor (test mAP + FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3b0f968",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T08:37:15.920269Z",
     "iopub.status.busy": "2024-02-26T08:37:15.919415Z",
     "iopub.status.idle": "2024-02-26T08:37:16.025637Z",
     "shell.execute_reply": "2024-02-26T08:37:16.024617Z"
    },
    "id": "h9sYYPOeNoy0",
    "outputId": "edd51b01-3a04-4ae0-f34f-a299341fe279",
    "papermill": {
     "duration": 5.928197,
     "end_time": "2024-02-26T08:37:16.027790",
     "exception": false,
     "start_time": "2024-02-26T08:37:10.099593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n"
     ]
    }
   ],
   "source": [
    "evaluate = True\n",
    "use_custom_images = False\n",
    "custom_image_path = \"data/images/\"\n",
    "\n",
    "test_data, total_items = tfr_dataset(test_files)\n",
    "print(total_items)\n",
    "\n",
    "data_types = get_data_types()\n",
    "data_shapes = get_data_shapes()\n",
    "padding_values = get_padding_values()\n",
    "\n",
    "if use_custom_images:\n",
    "    img_paths = get_custom_imgs(custom_image_path)\n",
    "    total_items = len(img_paths)\n",
    "    test_data = tf.data.Dataset.from_generator(lambda: custom_data_generator(\n",
    "                                               img_paths, img_size, img_size), data_types, data_shapes)\n",
    "else:\n",
    "    test_data = test_data.map(lambda x : tfr_preprocessing(x, img_size, img_size))\n",
    "\n",
    "test_data = test_data.padded_batch(batch_size, padded_shapes=data_shapes, padding_values=padding_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23b454f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T08:37:27.208865Z",
     "iopub.status.busy": "2024-02-26T08:37:27.207772Z",
     "iopub.status.idle": "2024-02-26T08:37:43.536326Z",
     "shell.execute_reply": "2024-02-26T08:37:43.535199Z"
    },
    "id": "LGcBVI4Gn_Mz",
    "outputId": "b16156c7-b28a-4f39-d45b-e43c77a29911",
    "papermill": {
     "duration": 21.932778,
     "end_time": "2024-02-26T08:37:43.538393",
     "exception": false,
     "start_time": "2024-02-26T08:37:21.605615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 4s 105ms/step\n",
      "Total time taken: 4.50487756729126 seconds\n",
      "Frames Per Second (FPS): 25.74986739756164\n",
      "mAP: 0.6392083559132242\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "if hyper_params[\"detection\"] is None:\n",
    "    ssd_model = get_model(hyper_params)\n",
    "elif hyper_params[\"detection\"] == \"FPN\":\n",
    "    ssd_model = get_fpnmodel(hyper_params)\n",
    "elif hyper_params[\"detection\"] == \"PAFPN\":\n",
    "    ssd_model = get_pafpnmodel(hyper_params)\n",
    "elif hyper_params[\"detection\"] == \"BiFPN\":\n",
    "    ssd_model = get_bifpnmodel(hyper_params)\n",
    "elif hyper_params[\"detection\"] == \"NASFPN\":\n",
    "    ssd_model = get_nasfpnmodel(hyper_params)\n",
    "ssd_model_path = get_model_path(backbone)\n",
    "ssd_model.load_weights(ssd_model_path)\n",
    "ssd_decoder_model = get_decoder_model(ssd_model, prior_boxes, hyper_params)\n",
    "\n",
    "step_size = get_step_size(total_items, batch_size)\n",
    "\n",
    "start_time = time.time()\n",
    "pred_bboxes, pred_labels, pred_scores = ssd_decoder_model.predict(test_data, steps=step_size, verbose=1)\n",
    "end_time = time.time()\n",
    "total_time_taken = end_time - start_time\n",
    "\n",
    "# Calculate Frames Per Second (FPS)\n",
    "fps = total_items / total_time_taken\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total time taken: {total_time_taken} seconds\")\n",
    "print(f\"Frames Per Second (FPS): {fps}\")\n",
    "\n",
    "if evaluate:\n",
    "    stats, mAP = evaluate_predictions(test_data, pred_bboxes, pred_labels, pred_scores, labels, batch_size)\n",
    "else:\n",
    "    draw_predictions(test_data, pred_bboxes, pred_labels, pred_scores, labels, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78ea11be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T08:37:54.797139Z",
     "iopub.status.busy": "2024-02-26T08:37:54.796098Z",
     "iopub.status.idle": "2024-02-26T08:37:54.802608Z",
     "shell.execute_reply": "2024-02-26T08:37:54.801600Z"
    },
    "id": "nn03Kvkm3UlW",
    "outputId": "ac17429f-b376-46f3-c914-e8f61d998170",
    "papermill": {
     "duration": 5.627475,
     "end_time": "2024-02-26T08:37:54.804620",
     "exception": false,
     "start_time": "2024-02-26T08:37:49.177145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hole\n",
      "Total: 47\n",
      "Total Predictions 53\n",
      "Correct Predictions: 39\n",
      "Knot\n",
      "Total: 25\n",
      "Total Predictions 23\n",
      "Correct Predictions: 17\n",
      "Line\n",
      "Total: 36\n",
      "Total Predictions 58\n",
      "Correct Predictions: 16\n",
      "Stain\n",
      "Total: 46\n",
      "Total Predictions 56\n",
      "Correct Predictions: 40\n"
     ]
    }
   ],
   "source": [
    "for i in stats:\n",
    "    print(stats[i]['label'])\n",
    "    print('Total:', stats[i]['total'])\n",
    "    print('Total Predictions', len(stats[i]['tp']))\n",
    "    print('Correct Predictions:', stats[i]['tp'].count(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63fbb0f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T08:38:06.049359Z",
     "iopub.status.busy": "2024-02-26T08:38:06.048996Z",
     "iopub.status.idle": "2024-02-26T08:38:06.073525Z",
     "shell.execute_reply": "2024-02-26T08:38:06.072650Z"
    },
    "papermill": {
     "duration": 5.663344,
     "end_time": "2024-02-26T08:38:06.075519",
     "exception": false,
     "start_time": "2024-02-26T08:38:00.412175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'label': 'Hole',\n",
       "  'total': 47,\n",
       "  'tp': [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1],\n",
       "  'fp': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0],\n",
       "  'scores': [0.99995744,\n",
       "   0.999767,\n",
       "   0.9882686,\n",
       "   0.99979526,\n",
       "   0.9999989,\n",
       "   0.9999968,\n",
       "   0.99472034,\n",
       "   0.9916706,\n",
       "   0.9584435,\n",
       "   1.0,\n",
       "   0.93679684,\n",
       "   0.6885081,\n",
       "   0.9910555,\n",
       "   1.0,\n",
       "   0.9774795,\n",
       "   0.99866176,\n",
       "   0.51758283,\n",
       "   0.99999213,\n",
       "   0.9992735,\n",
       "   0.99987674,\n",
       "   0.67806274,\n",
       "   0.5230586,\n",
       "   0.9315467,\n",
       "   0.99987924,\n",
       "   0.99741817,\n",
       "   0.8978349,\n",
       "   0.99964094,\n",
       "   0.9864624,\n",
       "   0.9827456,\n",
       "   0.9952348,\n",
       "   0.9999094,\n",
       "   0.9948507,\n",
       "   0.99621934,\n",
       "   0.999992,\n",
       "   0.99974066,\n",
       "   0.9999932,\n",
       "   0.9919167,\n",
       "   1.0,\n",
       "   0.97026753,\n",
       "   0.7906063,\n",
       "   0.972689,\n",
       "   0.80189437,\n",
       "   0.89722216,\n",
       "   0.90166086,\n",
       "   0.90811217,\n",
       "   0.9998895,\n",
       "   0.99989617,\n",
       "   0.99994934,\n",
       "   0.99935406,\n",
       "   0.78856874,\n",
       "   0.52077997,\n",
       "   0.5598671,\n",
       "   0.99980885],\n",
       "  'recall': array([0.0212766 , 0.04255319, 0.06382979, 0.08510638, 0.10638298,\n",
       "         0.12765957, 0.14893617, 0.17021277, 0.19148936, 0.21276596,\n",
       "         0.23404255, 0.25531915, 0.27659574, 0.29787234, 0.31914894,\n",
       "         0.34042553, 0.36170213, 0.38297872, 0.40425532, 0.42553191,\n",
       "         0.44680851, 0.46808511, 0.4893617 , 0.5106383 , 0.53191489,\n",
       "         0.55319149, 0.57446809, 0.59574468, 0.61702128, 0.61702128,\n",
       "         0.63829787, 0.65957447, 0.68085106, 0.70212766, 0.70212766,\n",
       "         0.70212766, 0.70212766, 0.70212766, 0.72340426, 0.74468085,\n",
       "         0.76595745, 0.76595745, 0.78723404, 0.78723404, 0.78723404,\n",
       "         0.78723404, 0.78723404, 0.80851064, 0.82978723, 0.82978723,\n",
       "         0.82978723, 0.82978723, 0.82978723]),\n",
       "  'precision': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 0.96666667,\n",
       "         0.96774194, 0.96875   , 0.96969697, 0.97058824, 0.94285714,\n",
       "         0.91666667, 0.89189189, 0.86842105, 0.87179487, 0.875     ,\n",
       "         0.87804878, 0.85714286, 0.86046512, 0.84090909, 0.82222222,\n",
       "         0.80434783, 0.78723404, 0.79166667, 0.79591837, 0.78      ,\n",
       "         0.76470588, 0.75      , 0.73584906]),\n",
       "  'AP': 0.7969551456946415},\n",
       " 2: {'label': 'Knot',\n",
       "  'total': 25,\n",
       "  'tp': [1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1],\n",
       "  'fp': [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       "  'scores': [0.99972934,\n",
       "   0.89959747,\n",
       "   0.5587824,\n",
       "   0.9999517,\n",
       "   0.9944351,\n",
       "   0.99981445,\n",
       "   0.99999905,\n",
       "   0.99990976,\n",
       "   0.96807486,\n",
       "   0.99999654,\n",
       "   0.6015956,\n",
       "   0.93045187,\n",
       "   0.99995625,\n",
       "   0.9998709,\n",
       "   0.7888831,\n",
       "   0.58504957,\n",
       "   0.99997365,\n",
       "   0.99951506,\n",
       "   0.9947678,\n",
       "   0.97158694,\n",
       "   0.9756724,\n",
       "   0.9999924,\n",
       "   0.99330467],\n",
       "  'recall': array([0.04, 0.08, 0.12, 0.16, 0.2 , 0.24, 0.28, 0.32, 0.36, 0.4 , 0.44,\n",
       "         0.44, 0.48, 0.52, 0.56, 0.6 , 0.64, 0.68, 0.68, 0.68, 0.68, 0.68,\n",
       "         0.68]),\n",
       "  'precision': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 0.91666667, 0.92307692, 0.92857143, 0.93333333,\n",
       "         0.9375    , 0.94117647, 0.94444444, 0.89473684, 0.85      ,\n",
       "         0.80952381, 0.77272727, 0.73913043]),\n",
       "  'AP': 0.6262626262626263},\n",
       " 3: {'label': 'Line',\n",
       "  'total': 36,\n",
       "  'tp': [1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0],\n",
       "  'fp': [0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1],\n",
       "  'scores': [0.9999558,\n",
       "   0.5369137,\n",
       "   0.8371979,\n",
       "   0.8212322,\n",
       "   0.7898737,\n",
       "   0.50697273,\n",
       "   0.5783196,\n",
       "   0.9999893,\n",
       "   0.9148644,\n",
       "   0.5958369,\n",
       "   0.9687377,\n",
       "   0.96412313,\n",
       "   0.5789133,\n",
       "   0.81812006,\n",
       "   0.9993575,\n",
       "   0.5891317,\n",
       "   0.5122469,\n",
       "   0.809652,\n",
       "   0.86977863,\n",
       "   0.513535,\n",
       "   0.98534435,\n",
       "   0.7065982,\n",
       "   0.6730744,\n",
       "   0.9750725,\n",
       "   0.86329836,\n",
       "   0.99983704,\n",
       "   0.70817673,\n",
       "   0.6187508,\n",
       "   0.9671888,\n",
       "   0.9900927,\n",
       "   0.99999917,\n",
       "   0.75774544,\n",
       "   0.65002406,\n",
       "   0.57751817,\n",
       "   0.6988144,\n",
       "   0.99450463,\n",
       "   0.6633693,\n",
       "   0.80571395,\n",
       "   0.8543511,\n",
       "   0.9535011,\n",
       "   0.50694144,\n",
       "   0.96216667,\n",
       "   0.88184834,\n",
       "   0.8447972,\n",
       "   0.9999403,\n",
       "   0.9793952,\n",
       "   0.9384595,\n",
       "   0.8673216,\n",
       "   0.87568337,\n",
       "   0.82101625,\n",
       "   0.9994429,\n",
       "   0.9643312,\n",
       "   0.97392726,\n",
       "   0.6436092,\n",
       "   0.99991477,\n",
       "   0.9999418,\n",
       "   0.9321328,\n",
       "   0.9149884],\n",
       "  'recall': array([0.02777778, 0.05555556, 0.08333333, 0.11111111, 0.13888889,\n",
       "         0.16666667, 0.19444444, 0.22222222, 0.25      , 0.25      ,\n",
       "         0.25      , 0.25      , 0.25      , 0.25      , 0.25      ,\n",
       "         0.25      , 0.25      , 0.25      , 0.25      , 0.25      ,\n",
       "         0.27777778, 0.30555556, 0.30555556, 0.30555556, 0.30555556,\n",
       "         0.30555556, 0.33333333, 0.33333333, 0.33333333, 0.36111111,\n",
       "         0.38888889, 0.38888889, 0.38888889, 0.38888889, 0.38888889,\n",
       "         0.38888889, 0.38888889, 0.38888889, 0.38888889, 0.38888889,\n",
       "         0.38888889, 0.38888889, 0.41666667, 0.41666667, 0.41666667,\n",
       "         0.41666667, 0.41666667, 0.44444444, 0.44444444, 0.44444444,\n",
       "         0.44444444, 0.44444444, 0.44444444, 0.44444444, 0.44444444,\n",
       "         0.44444444, 0.44444444, 0.44444444]),\n",
       "  'precision': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 0.9       ,\n",
       "         0.81818182, 0.75      , 0.69230769, 0.64285714, 0.6       ,\n",
       "         0.5625    , 0.52941176, 0.5       , 0.47368421, 0.45      ,\n",
       "         0.47619048, 0.5       , 0.47826087, 0.45833333, 0.44      ,\n",
       "         0.42307692, 0.44444444, 0.42857143, 0.4137931 , 0.43333333,\n",
       "         0.4516129 , 0.4375    , 0.42424242, 0.41176471, 0.4       ,\n",
       "         0.38888889, 0.37837838, 0.36842105, 0.35897436, 0.35      ,\n",
       "         0.34146341, 0.33333333, 0.34883721, 0.34090909, 0.33333333,\n",
       "         0.32608696, 0.31914894, 0.33333333, 0.32653061, 0.32      ,\n",
       "         0.31372549, 0.30769231, 0.30188679, 0.2962963 , 0.29090909,\n",
       "         0.28571429, 0.28070175, 0.27586207]),\n",
       "  'AP': 0.3498942917547569},\n",
       " 4: {'label': 'Stain',\n",
       "  'total': 46,\n",
       "  'tp': [1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1],\n",
       "  'fp': [0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0],\n",
       "  'scores': [0.9999696,\n",
       "   0.91308063,\n",
       "   0.99996376,\n",
       "   0.9999875,\n",
       "   0.99998343,\n",
       "   0.99950516,\n",
       "   0.9998567,\n",
       "   0.9996075,\n",
       "   0.62423676,\n",
       "   0.9999496,\n",
       "   0.99973065,\n",
       "   0.95670617,\n",
       "   0.6680597,\n",
       "   0.9993498,\n",
       "   0.9865154,\n",
       "   0.6788345,\n",
       "   0.9970565,\n",
       "   0.8646477,\n",
       "   0.9997929,\n",
       "   0.9986576,\n",
       "   0.9998093,\n",
       "   0.54612374,\n",
       "   0.8583427,\n",
       "   0.98169965,\n",
       "   0.999818,\n",
       "   0.9947772,\n",
       "   0.8777674,\n",
       "   0.9192995,\n",
       "   0.85424125,\n",
       "   0.99997044,\n",
       "   0.9997067,\n",
       "   0.99993193,\n",
       "   0.9864842,\n",
       "   0.99937207,\n",
       "   0.871311,\n",
       "   0.9998845,\n",
       "   0.9996406,\n",
       "   0.9656614,\n",
       "   0.99587387,\n",
       "   0.76796883,\n",
       "   0.99945587,\n",
       "   0.9942656,\n",
       "   0.9999099,\n",
       "   0.81508154,\n",
       "   0.9999647,\n",
       "   0.9986676,\n",
       "   0.93999285,\n",
       "   0.6857252,\n",
       "   0.9981799,\n",
       "   0.9995679,\n",
       "   0.99997044,\n",
       "   0.6268474,\n",
       "   0.9944543,\n",
       "   0.99003917,\n",
       "   0.71147144,\n",
       "   0.99992347],\n",
       "  'recall': array([0.02173913, 0.04347826, 0.06521739, 0.08695652, 0.10869565,\n",
       "         0.13043478, 0.15217391, 0.17391304, 0.19565217, 0.2173913 ,\n",
       "         0.23913043, 0.26086957, 0.2826087 , 0.30434783, 0.32608696,\n",
       "         0.34782609, 0.36956522, 0.39130435, 0.41304348, 0.43478261,\n",
       "         0.45652174, 0.47826087, 0.5       , 0.52173913, 0.54347826,\n",
       "         0.56521739, 0.58695652, 0.60869565, 0.63043478, 0.63043478,\n",
       "         0.65217391, 0.67391304, 0.69565217, 0.69565217, 0.69565217,\n",
       "         0.69565217, 0.69565217, 0.69565217, 0.69565217, 0.7173913 ,\n",
       "         0.73913043, 0.73913043, 0.76086957, 0.76086957, 0.7826087 ,\n",
       "         0.7826087 , 0.80434783, 0.82608696, 0.82608696, 0.82608696,\n",
       "         0.84782609, 0.84782609, 0.84782609, 0.84782609, 0.84782609,\n",
       "         0.86956522]),\n",
       "  'precision': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 0.96666667,\n",
       "         0.96774194, 0.96875   , 0.96969697, 0.94117647, 0.91428571,\n",
       "         0.88888889, 0.86486486, 0.84210526, 0.82051282, 0.825     ,\n",
       "         0.82926829, 0.80952381, 0.81395349, 0.79545455, 0.8       ,\n",
       "         0.7826087 , 0.78723404, 0.79166667, 0.7755102 , 0.76      ,\n",
       "         0.76470588, 0.75      , 0.73584906, 0.72222222, 0.70909091,\n",
       "         0.71428571]),\n",
       "  'AP': 0.7837213599408721}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "223390ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T08:38:17.410812Z",
     "iopub.status.busy": "2024-02-26T08:38:17.410429Z",
     "iopub.status.idle": "2024-02-26T08:38:17.414732Z",
     "shell.execute_reply": "2024-02-26T08:38:17.413802Z"
    },
    "id": "itzp-sJcSswM",
    "papermill": {
     "duration": 5.596828,
     "end_time": "2024-02-26T08:38:17.416610",
     "exception": false,
     "start_time": "2024-02-26T08:38:11.819782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# draw_predictions(test_data, pred_bboxes, pred_labels, pred_scores, labels, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d316d9",
   "metadata": {
    "id": "fWtZLX68Zx4-",
    "papermill": {
     "duration": 5.539477,
     "end_time": "2024-02-26T08:38:28.581925",
     "exception": false,
     "start_time": "2024-02-26T08:38:23.042448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4495464,
     "sourceId": 7701237,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23733.774241,
   "end_time": "2024-02-26T08:38:37.324988",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-26T02:03:03.550747",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
